{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())) + \"\\\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from data import *\n",
    "from metrics import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "from spatial import *\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_seed(args, random_state, model_folder_name=None):\n",
    "    \"\"\"\n",
    "    Train model with a single random seed and return comprehensive results\n",
    "    \"\"\"\n",
    "    # Get args\n",
    "    dataset = args.dataset\n",
    "    model_name = args.model_name\n",
    "    path = args.path\n",
    "    train_size = args.train_size\n",
    "    val_size = args.val_size\n",
    "    test_size = 1 - (args.train_size + args.val_size)\n",
    "    batched_training = args.batched_training\n",
    "    batch_size = args.batch_size\n",
    "    max_epochs = args.max_epochs\n",
    "    patience_limit = args.patience_limit\n",
    "    min_improvement = args.min_improvement\n",
    "    train_crit = args.train_crit\n",
    "    lr = args.lr\n",
    "    gnn_hidden_dim = args.gnn_hidden_dim\n",
    "    gnn_emb_dim = args.gnn_emb_dim\n",
    "    pe_hidden_dim = args.pe_hidden_dim\n",
    "    pe_emb_dim = args.pe_emb_dim\n",
    "    k = args.k\n",
    "    p_dropout = args.p_dropout\n",
    "    MAT = args.mat\n",
    "    uw = args.uw\n",
    "    lamb = args.lamb\n",
    "    save_freq = args.save_freq\n",
    "    print_progress = args.print_progress\n",
    "\n",
    "    # Set random seed\n",
    "    set_seed(random_state)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Access and process data\n",
    "    if dataset == \"california_housing\":\n",
    "        x, y, c = get_california_housing_data()\n",
    "\n",
    "    # Split data\n",
    "    n = x.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    _, _, _, _, idx_train, idx_val_test = train_test_split(\n",
    "        x, y, indices, test_size=(1 - train_size), random_state=random_state\n",
    "    )\n",
    "    idx_val, idx_test = train_test_split(\n",
    "        idx_val_test,\n",
    "        test_size=(1 - train_size - val_size) / (1 - train_size),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Separate x, y and c objects\n",
    "    train_x, val_x, test_x = x[idx_train], x[idx_val], x[idx_test]\n",
    "    train_y, val_y, test_y = y[idx_train], y[idx_val], y[idx_test]\n",
    "    train_c, val_c, test_c = c[idx_train], c[idx_val], c[idx_test]\n",
    "\n",
    "    # Create MyDataset objects\n",
    "    train_dataset, val_dataset, test_dataset = (\n",
    "        MyDataset(train_x, train_y, train_c),\n",
    "        MyDataset(val_x, val_y, val_c),\n",
    "        MyDataset(test_x, test_y, test_c),\n",
    "    )\n",
    "\n",
    "    # Define train loader\n",
    "    if batched_training == False:\n",
    "        batch_size = len(idx_train)\n",
    "        train_edge_index = knn_graph(train_c, k=k).to(device)\n",
    "        train_edge_weight = makeEdgeWeight(train_c, train_edge_index).to(device)\n",
    "        val_edge_index = knn_graph(val_c, k=k).to(device)\n",
    "        val_edge_weight = makeEdgeWeight(val_c, val_edge_index).to(device)\n",
    "        test_edge_index = knn_graph(test_c, k=k).to(device)\n",
    "        test_edge_weight = makeEdgeWeight(test_c, test_edge_index).to(device)\n",
    "        train_moran_weight_matrix = knn_to_adj(train_edge_index, batch_size)\n",
    "        with torch.enable_grad():\n",
    "            train_y_moran = lw_tensor_local_moran(\n",
    "                train_y, sparse.csr_matrix(train_moran_weight_matrix)\n",
    "            ).to(device)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    "        )\n",
    "    else:\n",
    "        train_edge_index = False\n",
    "        train_edge_weight = False\n",
    "        val_edge_index = False\n",
    "        val_edge_weight = False\n",
    "        test_edge_index = False\n",
    "        test_edge_weight = False\n",
    "        train_y_moran = False\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    # Make model\n",
    "    if model_name == \"pegcn\":\n",
    "        model = PEGCN(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    elif model_name == \"pegat\":\n",
    "        model = PEGAT(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    elif model_name == \"pegsage\":\n",
    "        model = PEGSAGE(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    model = model.float()\n",
    "\n",
    "    # Number of tasks\n",
    "    if MAT:\n",
    "        task_num = 2\n",
    "    else:\n",
    "        task_num = 1\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    loss_wrapper = LossWrapperPEGNN(\n",
    "        model,\n",
    "        loss=train_crit,\n",
    "        k=k,\n",
    "        batch_size=batch_size,\n",
    "        task_num=task_num,\n",
    "        uw=uw,\n",
    "        lamb=lamb,\n",
    "    ).to(device)\n",
    "    optimizer = Adam(loss_wrapper.parameters(), lr=lr)\n",
    "    score1 = nn.MSELoss()\n",
    "    score2 = nn.L1Loss()\n",
    "\n",
    "    # Create model folder name if not provided\n",
    "    if model_folder_name is None:\n",
    "        test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "        test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "        test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "        test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "        test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "        if MAT:\n",
    "            if uw:\n",
    "                test_ = test_ + \"_mat-uw\"\n",
    "            else:\n",
    "                test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "        if batched_training == True:\n",
    "            test_ = test_ + \"_bs\" + str(batch_size)\n",
    "        else:\n",
    "            test_ = test_ + \"_bsn\"\n",
    "\n",
    "        now = datetime.now()\n",
    "        saved_file = \"{}_{}{}-{}h{}m{}s\".format(\n",
    "            test_,\n",
    "            now.strftime(\"%h\"),\n",
    "            now.strftime(\"%d\"),\n",
    "            now.strftime(\"%H\"),\n",
    "            now.strftime(\"%M\"),\n",
    "            now.strftime(\"%S\"),\n",
    "        )\n",
    "    else:\n",
    "        saved_file = model_folder_name\n",
    "        # Create test_ variable for logging purposes\n",
    "        test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "        test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "        test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "        test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "        test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "        if MAT:\n",
    "            if uw:\n",
    "                test_ = test_ + \"_mat-uw\"\n",
    "            else:\n",
    "                test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "        if batched_training == True:\n",
    "            test_ = test_ + \"_bs\" + str(batch_size)\n",
    "        else:\n",
    "            test_ = test_ + \"_bsn\"\n",
    "\n",
    "    log_dir = path + \"//trained//{}//log\".format(saved_file)\n",
    "\n",
    "    if not os.path.exists(path + \"//trained//{}//data\".format(saved_file)):\n",
    "        os.makedirs(path + \"//trained//{}//data\".format(saved_file))\n",
    "    if not os.path.exists(path + \"//trained//{}//images\".format(saved_file)):\n",
    "        os.makedirs(path + \"//trained//{}//images\".format(saved_file))\n",
    "    with open(path + \"//trained//{}//train_notes.txt\".format(saved_file), \"w\") as f:\n",
    "        f.write(\"Experiment notes: PE-GAT for California Housing dataset \\n\\n\")\n",
    "        f.write(\"MODEL_DATA: {}\\n\".format(test_))\n",
    "        f.write(\"DATASET: {}\\n\".format(dataset))\n",
    "        f.write(\"RANDOM_STATE: {}\\n\".format(random_state))\n",
    "        f.write(\n",
    "            \"[TRAIN_SIZE, VAL_SIZE, TEST_SIZE]: [{}, {}, {}]\\n\".format(\n",
    "                train_size, val_size, test_size\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"BATCH_SIZE: {}\\nTRAIN_CRIT: {}\\nLEARNING_RATE: {}\\n\".format(\n",
    "                batch_size, train_crit, lr\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"MAX_EPOCHS: {}\\nPATIENCE_LIMIT: {}\\nMIN_IMPROVEMENT: {}\\n\".format(\n",
    "                max_epochs, patience_limit, min_improvement\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"GNN_HIDDEN_DIM: {}\\nGNN_EMB_DIM: {}\\n\".format(gnn_hidden_dim, gnn_emb_dim)\n",
    "        )\n",
    "        f.write(\"PE_HIDDEN_DIM: {}\\nPE_EMB_DIM: {}\\n\".format(pe_hidden_dim, pe_emb_dim))\n",
    "        f.write(\"K: {}\\nP_DROPOUT: {}\\n\".format(k, p_dropout))\n",
    "        f.write(\"MAT: {}\\nUW: {}\\nLAMBDA: {}\\n\".format(MAT, uw, lamb))\n",
    "\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    it_counts = 0\n",
    "    best_val_mse = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    found = False\n",
    "    final_epoch = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            it_counts += 1\n",
    "            x = batch[0].to(device).float()\n",
    "            y = batch[1].to(device).float()\n",
    "            c = batch[2].to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if MAT == True & uw == True:\n",
    "                loss, log_vars = loss_wrapper(\n",
    "                    x, y, c, train_edge_index, train_edge_weight, train_y_moran\n",
    "                )\n",
    "            else:\n",
    "                loss = loss_wrapper(\n",
    "                    x, y, c, train_edge_index, train_edge_weight, train_y_moran\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Eval\n",
    "            if it_counts % save_freq == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    if MAT:\n",
    "                        pred_val, _ = model(\n",
    "                            val_dataset.features.clone().detach().to(device),\n",
    "                            val_dataset.coords.clone().detach().to(device),\n",
    "                            val_edge_index,\n",
    "                            val_edge_weight,\n",
    "                        )\n",
    "                    else:\n",
    "                        pred_val = model(\n",
    "                            val_dataset.features.clone().detach().to(device),\n",
    "                            val_dataset.coords.clone().detach().to(device),\n",
    "                            val_edge_index,\n",
    "                            val_edge_weight,\n",
    "                        )\n",
    "                val_score1 = score1(\n",
    "                    val_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "                    pred_val.reshape(-1),\n",
    "                )\n",
    "                val_score2 = score2(\n",
    "                    val_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "                    pred_val.reshape(-1),\n",
    "                )\n",
    "\n",
    "                # Check for improvement\n",
    "                if best_val_mse > val_score1.item() * (1 + min_improvement):\n",
    "                    best_val_mse = val_score1.item()\n",
    "                    best_epoch = epoch\n",
    "                    patience_counter = 0  # Reset patience\n",
    "                else:\n",
    "                    patience_counter += 1  # Increment patience\n",
    "\n",
    "                # Early stopping check\n",
    "                if patience_counter > patience_limit:\n",
    "                    if print_progress:\n",
    "                        print(\n",
    "                            f\"Stopping early at epoch {epoch}. Best validation MSE: {best_val_mse} at epoch {best_epoch}.\"\n",
    "                        )\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "                if print_progress:\n",
    "                    print(\n",
    "                        \"Epoch [%d/%d] - Loss: %f - Valid. (MSE): %f - Valid. (MAE): %f\"\n",
    "                        % (\n",
    "                            epoch,\n",
    "                            max_epochs,\n",
    "                            loss.item(),\n",
    "                            val_score1.item(),\n",
    "                            val_score2.item(),\n",
    "                        )\n",
    "                    )\n",
    "                save_path = path + \"//trained//{}//ckpts\".format(saved_file)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                torch.save(model.state_dict(), save_path + \"//\" + \"model_state.pt\")\n",
    "                writer.add_scalar(\"Validation (MSE)\", val_score1.item(), it_counts)\n",
    "                writer.add_scalar(\"Validation (MAE)\", val_score2.item(), it_counts)\n",
    "            writer.add_scalar(\"Training loss\", loss.item(), it_counts)\n",
    "            writer.flush()\n",
    "        final_epoch = epoch\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Test eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if MAT:\n",
    "            pred_test, _ = model(\n",
    "                test_dataset.features.clone().detach().to(device),\n",
    "                test_dataset.coords.clone().detach().to(device),\n",
    "                test_edge_index,\n",
    "                test_edge_weight,\n",
    "            )\n",
    "        else:\n",
    "            pred_test = model(\n",
    "                test_dataset.features.clone().detach().to(device),\n",
    "                test_dataset.coords.clone().detach().to(device),\n",
    "                test_edge_index,\n",
    "                test_edge_weight,\n",
    "            )\n",
    "    test_mse = score1(\n",
    "        test_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "        pred_test.reshape(-1),\n",
    "    )\n",
    "    test_mae = score2(\n",
    "        test_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "        pred_test.reshape(-1),\n",
    "    )\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    pred_val = pred_val.reshape(-1)\n",
    "    pred_test = pred_test.reshape(-1)\n",
    "\n",
    "    residuals = val_y - pred_val\n",
    "    variance = torch.var(residuals).item()\n",
    "\n",
    "    test_y_np = test_y.numpy()\n",
    "    pred_test_np = pred_test.numpy()\n",
    "\n",
    "    # Calculate MPE - ensure all inputs are PyTorch tensors\n",
    "    try:\n",
    "        mpe_value = mpe(test_y, pred_test, var_pred=variance)\n",
    "    except Exception as e:\n",
    "        print(f\"MPE calculation error: {e}\")\n",
    "        mpe_value = float(\"inf\")\n",
    "\n",
    "    # Calculate calibration metrics\n",
    "    try:\n",
    "        taus = np.round(np.arange(0.01, 1, 0.01), 2)\n",
    "        means = np.repeat(pred_test_np[:, np.newaxis], len(taus), axis=1)\n",
    "        std_devs = np.sqrt(variance)\n",
    "        quantiles = norm.ppf(taus, loc=means, scale=std_devs)\n",
    "\n",
    "        comparison = (test_y_np[:, np.newaxis] <= quantiles).astype(int)\n",
    "        comparison_mean = pd.DataFrame(comparison, columns=taus).mean().reset_index()\n",
    "\n",
    "        calibration = np.sum((comparison_mean[\"index\"] - comparison_mean[0]) ** 2)\n",
    "        madecp = np.mean(np.abs(comparison_mean[\"index\"] - comparison_mean[0]))\n",
    "\n",
    "        # Calculate 95% prediction interval coverage\n",
    "        tau_lower, tau_upper = 0.025, 0.975\n",
    "        q_lower = norm.ppf(tau_lower, loc=pred_test_np, scale=std_devs)\n",
    "        q_upper = norm.ppf(tau_upper, loc=pred_test_np, scale=std_devs)\n",
    "        coverage_95 = np.mean((test_y_np >= q_lower) & (test_y_np <= q_upper))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Calibration metrics calculation error: {e}\")\n",
    "        calibration = float(\"inf\")\n",
    "        madecp = float(\"inf\")\n",
    "        coverage_95 = 0.0\n",
    "\n",
    "    # Return comprehensive results\n",
    "    results = {\n",
    "        \"random_state\": random_state,\n",
    "        \"model_folder\": saved_file,\n",
    "        \"final_epoch\": final_epoch,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"training_time\": training_time,\n",
    "        \"test_mse\": test_mse.item(),\n",
    "        \"test_mae\": test_mae.item(),\n",
    "        \"val_mse\": best_val_mse,\n",
    "        \"mpe\": mpe_value,\n",
    "        \"calibration\": calibration,\n",
    "        \"madecp\": madecp,\n",
    "        \"coverage_95\": coverage_95,\n",
    "        \"variance\": variance,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_seeds(args, seeds=None, num_seeds=10):\n",
    "    \"\"\"\n",
    "    Train model with multiple random seeds and return aggregated results\n",
    "    \"\"\"\n",
    "    if seeds is None:\n",
    "        seeds = list(range(42, 42 + num_seeds))\n",
    "\n",
    "    all_results = []\n",
    "    base_model_name = None\n",
    "\n",
    "    print(f\"Starting training with {len(seeds)} different random seeds: {seeds}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, seed in enumerate(seeds):\n",
    "        print(f\"\\n--- Training with seed {seed} ({i+1}/{len(seeds)}) ---\")\n",
    "\n",
    "        # Create a consistent model folder name for the first run\n",
    "        if i == 0:\n",
    "            # Generate base model name\n",
    "            dataset = args.dataset\n",
    "            model_name = args.model_name\n",
    "            k = args.k\n",
    "            gnn_hidden_dim = args.gnn_hidden_dim\n",
    "            gnn_emb_dim = args.gnn_emb_dim\n",
    "            pe_hidden_dim = args.pe_hidden_dim\n",
    "            pe_emb_dim = args.pe_emb_dim\n",
    "            MAT = args.mat\n",
    "            uw = args.uw\n",
    "            lamb = args.lamb\n",
    "            batched_training = args.batched_training\n",
    "            batch_size = args.batch_size\n",
    "\n",
    "            test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "            test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "            test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "            test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "            test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "            if MAT:\n",
    "                if uw:\n",
    "                    test_ = test_ + \"_mat-uw\"\n",
    "                else:\n",
    "                    test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "            if batched_training == True:\n",
    "                test_ = test_ + \"_bs\" + str(batch_size)\n",
    "            else:\n",
    "                test_ = test_ + \"_bsn\"\n",
    "\n",
    "            now = datetime.now()\n",
    "            base_model_name = \"{}_{}{}-{}h{}m{}s\".format(\n",
    "                test_,\n",
    "                now.strftime(\"%h\"),\n",
    "                now.strftime(\"%d\"),\n",
    "                now.strftime(\"%H\"),\n",
    "                now.strftime(\"%M\"),\n",
    "                now.strftime(\"%S\"),\n",
    "            )\n",
    "\n",
    "        # Train with current seed with timeout protection\n",
    "        try:\n",
    "            print(f\"Starting training for seed {seed}...\")\n",
    "            results = train_single_seed(\n",
    "                args, seed, model_folder_name=f\"{base_model_name}_seed{seed}\"\n",
    "            )\n",
    "            all_results.append(results)\n",
    "\n",
    "            print(f\"Seed {seed} completed:\")\n",
    "            print(f\"  - Final epoch: {results['final_epoch']}\")\n",
    "            print(f\"  - Best epoch: {results['best_epoch']}\")\n",
    "            print(f\"  - Training time: {results['training_time']:.2f}s\")\n",
    "            print(f\"  - Test MSE: {results['test_mse']:.6f}\")\n",
    "            print(f\"  - Test MAE: {results['test_mae']:.6f}\")\n",
    "            print(f\"  - MPE: {results['mpe']:.6f}\")\n",
    "            print(f\"  - Coverage 95%: {results['coverage_95']:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training seed {seed}: {e}\")\n",
    "            # Create a dummy result to maintain consistency\n",
    "            dummy_result = {\n",
    "                \"random_state\": seed,\n",
    "                \"model_folder\": f\"{base_model_name}_seed{seed}\",\n",
    "                \"final_epoch\": 0,\n",
    "                \"best_epoch\": 0,\n",
    "                \"training_time\": 0.0,\n",
    "                \"test_mse\": float(\"inf\"),\n",
    "                \"test_mae\": float(\"inf\"),\n",
    "                \"val_mse\": float(\"inf\"),\n",
    "                \"mpe\": float(\"inf\"),\n",
    "                \"calibration\": float(\"inf\"),\n",
    "                \"madecp\": float(\"inf\"),\n",
    "                \"coverage_95\": 0.0,\n",
    "                \"variance\": 0.0,\n",
    "            }\n",
    "            all_results.append(dummy_result)\n",
    "            print(f\"Added dummy result for failed seed {seed}\")\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aggregated_results(all_results):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation for all metrics across seeds\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract all metrics\n",
    "    metrics = [\n",
    "        \"final_epoch\",\n",
    "        \"best_epoch\",\n",
    "        \"training_time\",\n",
    "        \"test_mse\",\n",
    "        \"test_mae\",\n",
    "        \"val_mse\",\n",
    "        \"mpe\",\n",
    "        \"calibration\",\n",
    "        \"madecp\",\n",
    "        \"coverage_95\",\n",
    "        \"variance\",\n",
    "    ]\n",
    "\n",
    "    results_dict = {}\n",
    "    for metric in metrics:\n",
    "        values = [result[metric] for result in all_results]\n",
    "        results_dict[metric] = {\n",
    "            \"mean\": np.mean(values),\n",
    "            \"std\": np.std(values),\n",
    "            \"min\": np.min(values),\n",
    "            \"max\": np.max(values),\n",
    "        }\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def print_aggregated_results(all_results, results_dict):\n",
    "    \"\"\"\n",
    "    Print comprehensive results summary\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    print(f\"\\nNumber of seeds: {len(all_results)}\")\n",
    "    print(f\"Seeds used: {[r['random_state'] for r in all_results]}\")\n",
    "\n",
    "    print(f\"\\nBase model folder: {all_results[0]['model_folder'].split('_seed')[0]}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"TRAINING METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Training metrics\n",
    "    print(f\"Final Epochs:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['final_epoch']['mean']:.1f} ± {results_dict['final_epoch']['std']:.1f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['final_epoch']['min']:.0f}, {results_dict['final_epoch']['max']:.0f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest Epochs:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['best_epoch']['mean']:.1f} ± {results_dict['best_epoch']['std']:.1f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['best_epoch']['min']:.0f}, {results_dict['best_epoch']['max']:.0f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining Time (seconds):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['training_time']['mean']:.2f} ± {results_dict['training_time']['std']:.2f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['training_time']['min']:.2f}, {results_dict['training_time']['max']:.2f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Performance metrics\n",
    "    print(f\"Test MSE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['test_mse']['mean']:.6f} ± {results_dict['test_mse']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['test_mse']['min']:.6f}, {results_dict['test_mse']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest MAE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['test_mae']['mean']:.6f} ± {results_dict['test_mae']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['test_mae']['min']:.6f}, {results_dict['test_mae']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nValidation MSE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['val_mse']['mean']:.6f} ± {results_dict['val_mse']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['val_mse']['min']:.6f}, {results_dict['val_mse']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"UNCERTAINTY QUANTIFICATION METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Uncertainty metrics\n",
    "    print(f\"MPE (Mean Prediction Error):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['mpe']['mean']:.6f} ± {results_dict['mpe']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['mpe']['min']:.6f}, {results_dict['mpe']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n95% Prediction Interval Coverage:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['coverage_95']['mean']:.4f} ± {results_dict['coverage_95']['std']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['coverage_95']['min']:.4f}, {results_dict['coverage_95']['max']:.4f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nCalibration Score:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['calibration']['mean']:.6f} ± {results_dict['calibration']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['calibration']['min']:.6f}, {results_dict['calibration']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nMADECP (Mean Absolute Deviation from Expected Coverage Probability):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['madecp']['mean']:.6f} ± {results_dict['madecp']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['madecp']['min']:.6f}, {results_dict['madecp']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPrediction Variance:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['variance']['mean']:.6f} ± {results_dict['variance']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['variance']['min']:.6f}, {results_dict['variance']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"INDIVIDUAL SEED RESULTS\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    # Individual results table\n",
    "    print(\n",
    "        f\"\\n{'Seed':<6} {'Epochs':<8} {'Time(s)':<10} {'Test MSE':<12} {'Test MAE':<12} {'MPE':<12} {'Coverage':<10}\"\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "    for result in all_results:\n",
    "        print(\n",
    "            f\"{result['random_state']:<6} {result['final_epoch']:<8} {result['training_time']:<10.2f} \"\n",
    "            f\"{result['test_mse']:<12.6f} {result['test_mae']:<12.6f} {result['mpe']:<12.6f} \"\n",
    "            f\"{result['coverage_95']:<10.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/1000] - Loss: 0.270863 - Valid. (MSE): 0.157131 - Valid. (MAE): 0.320205\n",
      "Epoch [1/1000] - Loss: 0.217188 - Valid. (MSE): 0.066379 - Valid. (MAE): 0.184584\n",
      "Epoch [1/1000] - Loss: 0.183786 - Valid. (MSE): 0.076511 - Valid. (MAE): 0.197506\n",
      "Epoch [2/1000] - Loss: 0.143692 - Valid. (MSE): 0.069298 - Valid. (MAE): 0.187365\n",
      "Epoch [3/1000] - Loss: 0.120976 - Valid. (MSE): 0.058961 - Valid. (MAE): 0.174067\n",
      "Epoch [3/1000] - Loss: 0.110780 - Valid. (MSE): 0.059312 - Valid. (MAE): 0.172805\n",
      "Epoch [4/1000] - Loss: 0.102248 - Valid. (MSE): 0.055653 - Valid. (MAE): 0.167396\n",
      "Epoch [4/1000] - Loss: 0.100228 - Valid. (MSE): 0.052915 - Valid. (MAE): 0.163252\n",
      "Epoch [5/1000] - Loss: 0.090029 - Valid. (MSE): 0.051014 - Valid. (MAE): 0.160048\n",
      "Epoch [6/1000] - Loss: 0.084835 - Valid. (MSE): 0.047555 - Valid. (MAE): 0.156129\n",
      "Epoch [6/1000] - Loss: 0.076053 - Valid. (MSE): 0.045330 - Valid. (MAE): 0.153239\n",
      "Epoch [7/1000] - Loss: 0.078199 - Valid. (MSE): 0.043835 - Valid. (MAE): 0.150603\n",
      "Epoch [8/1000] - Loss: 0.082718 - Valid. (MSE): 0.043972 - Valid. (MAE): 0.148669\n",
      "Epoch [8/1000] - Loss: 0.081178 - Valid. (MSE): 0.041344 - Valid. (MAE): 0.145465\n",
      "Epoch [9/1000] - Loss: 0.075071 - Valid. (MSE): 0.039172 - Valid. (MAE): 0.142721\n",
      "Epoch [9/1000] - Loss: 0.074410 - Valid. (MSE): 0.038748 - Valid. (MAE): 0.139899\n",
      "Epoch [10/1000] - Loss: 0.067898 - Valid. (MSE): 0.039914 - Valid. (MAE): 0.138255\n",
      "Epoch [11/1000] - Loss: 0.070633 - Valid. (MSE): 0.034643 - Valid. (MAE): 0.134606\n",
      "Epoch [11/1000] - Loss: 0.065529 - Valid. (MSE): 0.034674 - Valid. (MAE): 0.131083\n",
      "Epoch [12/1000] - Loss: 0.063904 - Valid. (MSE): 0.035957 - Valid. (MAE): 0.130472\n",
      "Epoch [13/1000] - Loss: 0.065914 - Valid. (MSE): 0.032530 - Valid. (MAE): 0.126943\n",
      "Epoch [13/1000] - Loss: 0.064348 - Valid. (MSE): 0.031776 - Valid. (MAE): 0.124719\n",
      "Epoch [14/1000] - Loss: 0.059486 - Valid. (MSE): 0.033091 - Valid. (MAE): 0.124277\n",
      "Epoch [14/1000] - Loss: 0.061418 - Valid. (MSE): 0.032171 - Valid. (MAE): 0.122366\n",
      "Epoch [15/1000] - Loss: 0.054969 - Valid. (MSE): 0.033635 - Valid. (MAE): 0.124015\n",
      "Epoch [16/1000] - Loss: 0.050685 - Valid. (MSE): 0.029714 - Valid. (MAE): 0.119160\n",
      "Epoch [16/1000] - Loss: 0.059628 - Valid. (MSE): 0.028277 - Valid. (MAE): 0.118666\n",
      "Epoch [17/1000] - Loss: 0.053854 - Valid. (MSE): 0.026260 - Valid. (MAE): 0.117535\n",
      "Epoch [18/1000] - Loss: 0.050808 - Valid. (MSE): 0.031602 - Valid. (MAE): 0.120759\n",
      "Epoch [18/1000] - Loss: 0.052661 - Valid. (MSE): 0.029640 - Valid. (MAE): 0.117457\n",
      "Epoch [19/1000] - Loss: 0.051502 - Valid. (MSE): 0.027032 - Valid. (MAE): 0.114703\n",
      "Epoch [19/1000] - Loss: 0.050053 - Valid. (MSE): 0.026111 - Valid. (MAE): 0.114115\n",
      "Epoch [20/1000] - Loss: 0.052732 - Valid. (MSE): 0.027335 - Valid. (MAE): 0.114046\n",
      "Epoch [21/1000] - Loss: 0.050012 - Valid. (MSE): 0.026353 - Valid. (MAE): 0.112205\n",
      "Epoch [21/1000] - Loss: 0.050810 - Valid. (MSE): 0.025801 - Valid. (MAE): 0.111143\n",
      "Epoch [22/1000] - Loss: 0.048569 - Valid. (MSE): 0.027047 - Valid. (MAE): 0.112280\n",
      "Epoch [23/1000] - Loss: 0.045218 - Valid. (MSE): 0.024773 - Valid. (MAE): 0.108985\n",
      "Epoch [23/1000] - Loss: 0.048502 - Valid. (MSE): 0.025113 - Valid. (MAE): 0.109262\n",
      "Epoch [24/1000] - Loss: 0.045286 - Valid. (MSE): 0.025125 - Valid. (MAE): 0.109238\n",
      "Epoch [24/1000] - Loss: 0.043645 - Valid. (MSE): 0.022176 - Valid. (MAE): 0.107572\n",
      "Epoch [25/1000] - Loss: 0.045512 - Valid. (MSE): 0.024200 - Valid. (MAE): 0.108406\n",
      "Epoch [26/1000] - Loss: 0.046144 - Valid. (MSE): 0.026088 - Valid. (MAE): 0.110394\n",
      "Epoch [26/1000] - Loss: 0.048774 - Valid. (MSE): 0.021908 - Valid. (MAE): 0.105596\n",
      "Epoch [27/1000] - Loss: 0.042841 - Valid. (MSE): 0.021845 - Valid. (MAE): 0.106116\n",
      "Epoch [28/1000] - Loss: 0.046058 - Valid. (MSE): 0.022715 - Valid. (MAE): 0.105034\n",
      "Epoch [28/1000] - Loss: 0.045732 - Valid. (MSE): 0.025085 - Valid. (MAE): 0.107465\n",
      "Epoch [29/1000] - Loss: 0.038760 - Valid. (MSE): 0.023842 - Valid. (MAE): 0.105551\n",
      "Epoch [29/1000] - Loss: 0.045959 - Valid. (MSE): 0.023327 - Valid. (MAE): 0.104851\n",
      "Epoch [30/1000] - Loss: 0.040521 - Valid. (MSE): 0.022027 - Valid. (MAE): 0.103096\n",
      "Epoch [31/1000] - Loss: 0.037883 - Valid. (MSE): 0.021596 - Valid. (MAE): 0.102862\n",
      "Epoch [31/1000] - Loss: 0.040768 - Valid. (MSE): 0.022700 - Valid. (MAE): 0.104019\n",
      "Epoch [32/1000] - Loss: 0.041268 - Valid. (MSE): 0.024442 - Valid. (MAE): 0.106091\n",
      "Epoch [33/1000] - Loss: 0.038319 - Valid. (MSE): 0.020706 - Valid. (MAE): 0.100378\n",
      "Epoch [33/1000] - Loss: 0.039209 - Valid. (MSE): 0.021204 - Valid. (MAE): 0.100328\n",
      "Epoch [34/1000] - Loss: 0.038493 - Valid. (MSE): 0.022224 - Valid. (MAE): 0.101535\n",
      "Epoch [34/1000] - Loss: 0.041474 - Valid. (MSE): 0.020985 - Valid. (MAE): 0.099409\n",
      "Epoch [35/1000] - Loss: 0.039862 - Valid. (MSE): 0.021132 - Valid. (MAE): 0.099923\n",
      "Epoch [36/1000] - Loss: 0.038954 - Valid. (MSE): 0.021134 - Valid. (MAE): 0.100354\n",
      "Epoch [36/1000] - Loss: 0.040029 - Valid. (MSE): 0.021402 - Valid. (MAE): 0.099966\n",
      "Epoch [37/1000] - Loss: 0.036681 - Valid. (MSE): 0.020056 - Valid. (MAE): 0.097742\n",
      "Epoch [38/1000] - Loss: 0.036487 - Valid. (MSE): 0.019975 - Valid. (MAE): 0.098245\n",
      "Epoch [38/1000] - Loss: 0.034014 - Valid. (MSE): 0.020808 - Valid. (MAE): 0.098470\n",
      "Epoch [39/1000] - Loss: 0.038722 - Valid. (MSE): 0.021606 - Valid. (MAE): 0.099527\n",
      "Epoch [39/1000] - Loss: 0.036174 - Valid. (MSE): 0.020331 - Valid. (MAE): 0.098326\n",
      "Epoch [40/1000] - Loss: 0.038320 - Valid. (MSE): 0.019610 - Valid. (MAE): 0.097564\n",
      "Epoch [41/1000] - Loss: 0.037436 - Valid. (MSE): 0.019998 - Valid. (MAE): 0.096741\n",
      "Epoch [41/1000] - Loss: 0.037489 - Valid. (MSE): 0.020047 - Valid. (MAE): 0.096433\n",
      "Epoch [42/1000] - Loss: 0.035245 - Valid. (MSE): 0.019868 - Valid. (MAE): 0.095804\n",
      "Epoch [43/1000] - Loss: 0.035442 - Valid. (MSE): 0.020170 - Valid. (MAE): 0.096780\n",
      "Epoch [43/1000] - Loss: 0.037555 - Valid. (MSE): 0.018489 - Valid. (MAE): 0.095253\n",
      "Epoch [44/1000] - Loss: 0.033499 - Valid. (MSE): 0.018673 - Valid. (MAE): 0.093749\n",
      "Epoch [44/1000] - Loss: 0.034966 - Valid. (MSE): 0.020796 - Valid. (MAE): 0.096983\n",
      "Epoch [45/1000] - Loss: 0.034441 - Valid. (MSE): 0.019037 - Valid. (MAE): 0.094139\n",
      "Epoch [46/1000] - Loss: 0.035416 - Valid. (MSE): 0.018227 - Valid. (MAE): 0.092871\n",
      "Epoch [46/1000] - Loss: 0.034443 - Valid. (MSE): 0.019011 - Valid. (MAE): 0.093721\n",
      "Epoch [47/1000] - Loss: 0.032077 - Valid. (MSE): 0.018238 - Valid. (MAE): 0.093086\n",
      "Epoch [48/1000] - Loss: 0.034035 - Valid. (MSE): 0.018541 - Valid. (MAE): 0.092777\n",
      "Epoch [48/1000] - Loss: 0.034449 - Valid. (MSE): 0.018107 - Valid. (MAE): 0.092447\n",
      "Epoch [49/1000] - Loss: 0.033860 - Valid. (MSE): 0.019850 - Valid. (MAE): 0.094523\n",
      "Epoch [49/1000] - Loss: 0.032990 - Valid. (MSE): 0.018626 - Valid. (MAE): 0.092868\n",
      "Epoch [50/1000] - Loss: 0.036699 - Valid. (MSE): 0.017543 - Valid. (MAE): 0.092168\n",
      "Epoch [51/1000] - Loss: 0.034687 - Valid. (MSE): 0.018734 - Valid. (MAE): 0.092783\n",
      "Epoch [51/1000] - Loss: 0.031770 - Valid. (MSE): 0.018663 - Valid. (MAE): 0.092325\n",
      "Epoch [52/1000] - Loss: 0.030684 - Valid. (MSE): 0.018712 - Valid. (MAE): 0.092544\n",
      "Epoch [53/1000] - Loss: 0.033386 - Valid. (MSE): 0.017592 - Valid. (MAE): 0.091361\n",
      "Epoch [53/1000] - Loss: 0.032878 - Valid. (MSE): 0.018176 - Valid. (MAE): 0.091392\n",
      "Epoch [54/1000] - Loss: 0.030194 - Valid. (MSE): 0.018906 - Valid. (MAE): 0.092867\n",
      "Epoch [54/1000] - Loss: 0.032440 - Valid. (MSE): 0.017477 - Valid. (MAE): 0.090889\n",
      "Epoch [55/1000] - Loss: 0.033074 - Valid. (MSE): 0.017278 - Valid. (MAE): 0.089960\n",
      "Epoch [56/1000] - Loss: 0.031044 - Valid. (MSE): 0.017835 - Valid. (MAE): 0.091182\n",
      "Epoch [56/1000] - Loss: 0.033052 - Valid. (MSE): 0.018796 - Valid. (MAE): 0.092015\n",
      "Epoch [57/1000] - Loss: 0.031995 - Valid. (MSE): 0.017905 - Valid. (MAE): 0.090939\n",
      "Epoch [58/1000] - Loss: 0.031031 - Valid. (MSE): 0.017462 - Valid. (MAE): 0.093058\n",
      "Epoch [58/1000] - Loss: 0.032395 - Valid. (MSE): 0.019409 - Valid. (MAE): 0.093480\n",
      "Epoch [59/1000] - Loss: 0.031496 - Valid. (MSE): 0.018515 - Valid. (MAE): 0.091629\n",
      "Epoch [59/1000] - Loss: 0.033313 - Valid. (MSE): 0.017065 - Valid. (MAE): 0.092252\n",
      "Epoch [60/1000] - Loss: 0.031895 - Valid. (MSE): 0.019087 - Valid. (MAE): 0.092528\n",
      "Epoch [61/1000] - Loss: 0.030836 - Valid. (MSE): 0.017532 - Valid. (MAE): 0.089609\n",
      "Epoch [61/1000] - Loss: 0.033271 - Valid. (MSE): 0.016842 - Valid. (MAE): 0.091916\n",
      "Epoch [62/1000] - Loss: 0.030239 - Valid. (MSE): 0.019257 - Valid. (MAE): 0.093156\n",
      "Epoch [63/1000] - Loss: 0.032639 - Valid. (MSE): 0.018021 - Valid. (MAE): 0.091278\n",
      "Epoch [63/1000] - Loss: 0.031959 - Valid. (MSE): 0.017044 - Valid. (MAE): 0.090434\n",
      "Epoch [64/1000] - Loss: 0.029884 - Valid. (MSE): 0.019019 - Valid. (MAE): 0.092307\n",
      "Epoch [64/1000] - Loss: 0.029826 - Valid. (MSE): 0.018077 - Valid. (MAE): 0.090824\n",
      "Epoch [65/1000] - Loss: 0.031573 - Valid. (MSE): 0.017417 - Valid. (MAE): 0.091501\n",
      "Epoch [66/1000] - Loss: 0.029118 - Valid. (MSE): 0.018165 - Valid. (MAE): 0.090873\n",
      "Epoch [66/1000] - Loss: 0.029361 - Valid. (MSE): 0.017113 - Valid. (MAE): 0.089620\n",
      "Epoch [67/1000] - Loss: 0.027854 - Valid. (MSE): 0.018094 - Valid. (MAE): 0.090453\n",
      "Epoch [68/1000] - Loss: 0.029526 - Valid. (MSE): 0.017017 - Valid. (MAE): 0.089959\n",
      "Epoch [68/1000] - Loss: 0.028552 - Valid. (MSE): 0.017049 - Valid. (MAE): 0.089120\n",
      "Epoch [69/1000] - Loss: 0.029732 - Valid. (MSE): 0.017612 - Valid. (MAE): 0.090004\n",
      "Epoch [69/1000] - Loss: 0.026816 - Valid. (MSE): 0.017156 - Valid. (MAE): 0.089820\n",
      "Epoch [70/1000] - Loss: 0.027427 - Valid. (MSE): 0.017458 - Valid. (MAE): 0.089158\n",
      "Epoch [71/1000] - Loss: 0.029671 - Valid. (MSE): 0.017262 - Valid. (MAE): 0.090269\n",
      "Epoch [71/1000] - Loss: 0.029189 - Valid. (MSE): 0.017920 - Valid. (MAE): 0.090110\n",
      "Epoch [72/1000] - Loss: 0.029754 - Valid. (MSE): 0.016822 - Valid. (MAE): 0.088813\n",
      "Epoch [73/1000] - Loss: 0.030666 - Valid. (MSE): 0.017392 - Valid. (MAE): 0.090640\n",
      "Epoch [73/1000] - Loss: 0.027707 - Valid. (MSE): 0.018453 - Valid. (MAE): 0.091166\n",
      "Epoch [74/1000] - Loss: 0.027889 - Valid. (MSE): 0.016939 - Valid. (MAE): 0.090752\n",
      "Epoch [74/1000] - Loss: 0.028530 - Valid. (MSE): 0.017440 - Valid. (MAE): 0.089442\n",
      "Epoch [75/1000] - Loss: 0.026503 - Valid. (MSE): 0.017513 - Valid. (MAE): 0.089586\n",
      "Epoch [76/1000] - Loss: 0.029251 - Valid. (MSE): 0.016810 - Valid. (MAE): 0.090199\n",
      "Epoch [76/1000] - Loss: 0.029727 - Valid. (MSE): 0.018022 - Valid. (MAE): 0.090579\n",
      "Epoch [77/1000] - Loss: 0.028178 - Valid. (MSE): 0.016358 - Valid. (MAE): 0.088968\n",
      "Epoch [78/1000] - Loss: 0.029032 - Valid. (MSE): 0.016408 - Valid. (MAE): 0.089205\n",
      "Epoch [78/1000] - Loss: 0.028078 - Valid. (MSE): 0.017547 - Valid. (MAE): 0.089809\n",
      "Epoch [79/1000] - Loss: 0.027692 - Valid. (MSE): 0.016711 - Valid. (MAE): 0.088730\n",
      "Epoch [79/1000] - Loss: 0.027488 - Valid. (MSE): 0.017398 - Valid. (MAE): 0.088885\n",
      "Epoch [80/1000] - Loss: 0.028777 - Valid. (MSE): 0.017432 - Valid. (MAE): 0.089844\n",
      "Epoch [81/1000] - Loss: 0.028379 - Valid. (MSE): 0.016514 - Valid. (MAE): 0.087921\n",
      "Epoch [81/1000] - Loss: 0.026182 - Valid. (MSE): 0.017737 - Valid. (MAE): 0.089902\n",
      "Epoch [82/1000] - Loss: 0.028532 - Valid. (MSE): 0.016999 - Valid. (MAE): 0.089663\n",
      "Epoch [83/1000] - Loss: 0.027903 - Valid. (MSE): 0.017084 - Valid. (MAE): 0.088500\n",
      "Epoch [83/1000] - Loss: 0.027505 - Valid. (MSE): 0.016667 - Valid. (MAE): 0.088200\n",
      "Epoch [84/1000] - Loss: 0.027001 - Valid. (MSE): 0.016544 - Valid. (MAE): 0.088665\n",
      "Epoch [84/1000] - Loss: 0.026594 - Valid. (MSE): 0.016530 - Valid. (MAE): 0.088446\n",
      "Epoch [85/1000] - Loss: 0.027240 - Valid. (MSE): 0.016866 - Valid. (MAE): 0.088005\n",
      "Epoch [86/1000] - Loss: 0.028345 - Valid. (MSE): 0.017117 - Valid. (MAE): 0.089177\n",
      "Epoch [86/1000] - Loss: 0.026744 - Valid. (MSE): 0.016221 - Valid. (MAE): 0.088756\n",
      "Epoch [87/1000] - Loss: 0.028986 - Valid. (MSE): 0.016585 - Valid. (MAE): 0.088704\n",
      "Epoch [88/1000] - Loss: 0.025698 - Valid. (MSE): 0.018361 - Valid. (MAE): 0.091235\n",
      "Epoch [88/1000] - Loss: 0.026283 - Valid. (MSE): 0.016064 - Valid. (MAE): 0.089148\n",
      "Epoch [89/1000] - Loss: 0.028263 - Valid. (MSE): 0.017431 - Valid. (MAE): 0.088835\n",
      "Epoch [89/1000] - Loss: 0.028345 - Valid. (MSE): 0.016688 - Valid. (MAE): 0.088324\n",
      "Epoch [90/1000] - Loss: 0.027885 - Valid. (MSE): 0.016354 - Valid. (MAE): 0.087977\n",
      "Epoch [91/1000] - Loss: 0.029926 - Valid. (MSE): 0.017802 - Valid. (MAE): 0.089699\n",
      "Epoch [91/1000] - Loss: 0.028879 - Valid. (MSE): 0.016394 - Valid. (MAE): 0.089742\n",
      "Epoch [92/1000] - Loss: 0.025679 - Valid. (MSE): 0.016822 - Valid. (MAE): 0.088234\n",
      "Epoch [93/1000] - Loss: 0.025108 - Valid. (MSE): 0.016644 - Valid. (MAE): 0.088617\n",
      "Epoch [93/1000] - Loss: 0.027410 - Valid. (MSE): 0.016869 - Valid. (MAE): 0.088803\n",
      "Epoch [94/1000] - Loss: 0.024681 - Valid. (MSE): 0.016961 - Valid. (MAE): 0.088241\n",
      "Epoch [94/1000] - Loss: 0.026098 - Valid. (MSE): 0.016235 - Valid. (MAE): 0.089027\n",
      "Epoch [95/1000] - Loss: 0.027006 - Valid. (MSE): 0.016881 - Valid. (MAE): 0.088277\n",
      "Epoch [96/1000] - Loss: 0.028808 - Valid. (MSE): 0.016975 - Valid. (MAE): 0.089190\n",
      "Epoch [96/1000] - Loss: 0.025637 - Valid. (MSE): 0.016357 - Valid. (MAE): 0.087860\n",
      "Epoch [97/1000] - Loss: 0.025023 - Valid. (MSE): 0.016329 - Valid. (MAE): 0.088447\n",
      "Epoch [98/1000] - Loss: 0.027098 - Valid. (MSE): 0.017054 - Valid. (MAE): 0.088808\n",
      "Epoch [98/1000] - Loss: 0.026218 - Valid. (MSE): 0.016288 - Valid. (MAE): 0.088076\n",
      "Epoch [99/1000] - Loss: 0.024448 - Valid. (MSE): 0.016267 - Valid. (MAE): 0.087304\n",
      "Epoch [99/1000] - Loss: 0.026357 - Valid. (MSE): 0.016594 - Valid. (MAE): 0.088000\n",
      "Epoch [100/1000] - Loss: 0.023939 - Valid. (MSE): 0.016597 - Valid. (MAE): 0.090188\n",
      "Epoch [101/1000] - Loss: 0.025194 - Valid. (MSE): 0.016767 - Valid. (MAE): 0.087858\n",
      "Epoch [101/1000] - Loss: 0.024925 - Valid. (MSE): 0.016482 - Valid. (MAE): 0.088486\n",
      "Epoch [102/1000] - Loss: 0.026212 - Valid. (MSE): 0.016528 - Valid. (MAE): 0.088923\n",
      "Epoch [103/1000] - Loss: 0.025162 - Valid. (MSE): 0.016646 - Valid. (MAE): 0.087562\n",
      "Epoch [103/1000] - Loss: 0.023696 - Valid. (MSE): 0.016772 - Valid. (MAE): 0.089611\n",
      "Epoch [104/1000] - Loss: 0.025832 - Valid. (MSE): 0.016536 - Valid. (MAE): 0.087775\n",
      "Epoch [104/1000] - Loss: 0.024962 - Valid. (MSE): 0.016329 - Valid. (MAE): 0.088864\n",
      "Epoch [105/1000] - Loss: 0.023192 - Valid. (MSE): 0.016233 - Valid. (MAE): 0.087797\n",
      "Epoch [106/1000] - Loss: 0.024979 - Valid. (MSE): 0.016787 - Valid. (MAE): 0.088895\n",
      "Epoch [106/1000] - Loss: 0.025392 - Valid. (MSE): 0.016856 - Valid. (MAE): 0.088841\n",
      "Epoch [107/1000] - Loss: 0.026363 - Valid. (MSE): 0.016321 - Valid. (MAE): 0.087156\n",
      "Epoch [108/1000] - Loss: 0.023884 - Valid. (MSE): 0.016760 - Valid. (MAE): 0.088336\n",
      "Epoch [108/1000] - Loss: 0.026319 - Valid. (MSE): 0.016430 - Valid. (MAE): 0.087956\n",
      "Epoch [109/1000] - Loss: 0.025647 - Valid. (MSE): 0.016869 - Valid. (MAE): 0.088057\n",
      "Epoch [109/1000] - Loss: 0.024603 - Valid. (MSE): 0.016197 - Valid. (MAE): 0.089179\n",
      "Epoch [110/1000] - Loss: 0.025766 - Valid. (MSE): 0.016125 - Valid. (MAE): 0.087638\n",
      "Epoch [111/1000] - Loss: 0.024038 - Valid. (MSE): 0.016779 - Valid. (MAE): 0.088377\n",
      "Epoch [111/1000] - Loss: 0.026603 - Valid. (MSE): 0.016411 - Valid. (MAE): 0.089071\n",
      "Epoch [112/1000] - Loss: 0.024781 - Valid. (MSE): 0.016388 - Valid. (MAE): 0.088389\n",
      "Epoch [113/1000] - Loss: 0.025496 - Valid. (MSE): 0.016212 - Valid. (MAE): 0.087787\n",
      "Epoch [113/1000] - Loss: 0.026445 - Valid. (MSE): 0.016401 - Valid. (MAE): 0.088381\n",
      "Epoch [114/1000] - Loss: 0.025638 - Valid. (MSE): 0.016460 - Valid. (MAE): 0.088611\n",
      "Epoch [114/1000] - Loss: 0.027064 - Valid. (MSE): 0.016395 - Valid. (MAE): 0.087432\n",
      "Epoch [115/1000] - Loss: 0.025041 - Valid. (MSE): 0.016371 - Valid. (MAE): 0.091566\n",
      "Epoch [116/1000] - Loss: 0.023920 - Valid. (MSE): 0.016753 - Valid. (MAE): 0.087693\n",
      "Epoch [116/1000] - Loss: 0.024321 - Valid. (MSE): 0.016098 - Valid. (MAE): 0.087500\n",
      "Epoch [117/1000] - Loss: 0.023687 - Valid. (MSE): 0.016191 - Valid. (MAE): 0.088325\n",
      "Epoch [118/1000] - Loss: 0.023324 - Valid. (MSE): 0.016044 - Valid. (MAE): 0.087725\n",
      "Epoch [118/1000] - Loss: 0.022569 - Valid. (MSE): 0.016003 - Valid. (MAE): 0.087168\n",
      "Epoch [119/1000] - Loss: 0.024445 - Valid. (MSE): 0.016272 - Valid. (MAE): 0.087991\n",
      "Epoch [119/1000] - Loss: 0.025179 - Valid. (MSE): 0.015945 - Valid. (MAE): 0.087726\n",
      "Stopping early at epoch 120. Best validation MSE: 0.016064137853940275 at epoch 88.\n",
      "Seed 42 completed:\n",
      "  - Final epoch: 120\n",
      "  - Best epoch: 88\n",
      "  - Training time: 1888.67s\n",
      "  - Test MSE: 0.018299\n",
      "  - Test MAE: 0.092930\n",
      "  - MPE: 0.036022\n",
      "  - Coverage 95%: 0.9167\n",
      "\n",
      "--- Training with seed 43 (2/10) ---\n",
      "Starting training for seed 43...\n",
      "Epoch [0/1000] - Loss: 0.173309 - Valid. (MSE): 0.106031 - Valid. (MAE): 0.241842\n",
      "Epoch [1/1000] - Loss: 0.122681 - Valid. (MSE): 0.052359 - Valid. (MAE): 0.184132\n",
      "Epoch [1/1000] - Loss: 0.115680 - Valid. (MSE): 0.052956 - Valid. (MAE): 0.174801\n",
      "Epoch [2/1000] - Loss: 0.094692 - Valid. (MSE): 0.062789 - Valid. (MAE): 0.178734\n",
      "Epoch [3/1000] - Loss: 0.091522 - Valid. (MSE): 0.054389 - Valid. (MAE): 0.170916\n",
      "Epoch [3/1000] - Loss: 0.086628 - Valid. (MSE): 0.049398 - Valid. (MAE): 0.171416\n",
      "Epoch [4/1000] - Loss: 0.088036 - Valid. (MSE): 0.052524 - Valid. (MAE): 0.167209\n",
      "Epoch [4/1000] - Loss: 0.082474 - Valid. (MSE): 0.050985 - Valid. (MAE): 0.165009\n",
      "Epoch [5/1000] - Loss: 0.075217 - Valid. (MSE): 0.045905 - Valid. (MAE): 0.163263\n",
      "Epoch [6/1000] - Loss: 0.078832 - Valid. (MSE): 0.046467 - Valid. (MAE): 0.158954\n",
      "Epoch [6/1000] - Loss: 0.071661 - Valid. (MSE): 0.043447 - Valid. (MAE): 0.156411\n",
      "Epoch [7/1000] - Loss: 0.074877 - Valid. (MSE): 0.043258 - Valid. (MAE): 0.152924\n",
      "Epoch [8/1000] - Loss: 0.069716 - Valid. (MSE): 0.040020 - Valid. (MAE): 0.151462\n",
      "Epoch [8/1000] - Loss: 0.067296 - Valid. (MSE): 0.040407 - Valid. (MAE): 0.147282\n",
      "Epoch [9/1000] - Loss: 0.063089 - Valid. (MSE): 0.038185 - Valid. (MAE): 0.145539\n",
      "Epoch [9/1000] - Loss: 0.067294 - Valid. (MSE): 0.038639 - Valid. (MAE): 0.142777\n",
      "Epoch [10/1000] - Loss: 0.065608 - Valid. (MSE): 0.036773 - Valid. (MAE): 0.140126\n",
      "Epoch [11/1000] - Loss: 0.062236 - Valid. (MSE): 0.034685 - Valid. (MAE): 0.138135\n",
      "Epoch [11/1000] - Loss: 0.059485 - Valid. (MSE): 0.035330 - Valid. (MAE): 0.134274\n",
      "Epoch [12/1000] - Loss: 0.060796 - Valid. (MSE): 0.032757 - Valid. (MAE): 0.132089\n",
      "Epoch [13/1000] - Loss: 0.060203 - Valid. (MSE): 0.031738 - Valid. (MAE): 0.127865\n",
      "Epoch [13/1000] - Loss: 0.049963 - Valid. (MSE): 0.029842 - Valid. (MAE): 0.124261\n",
      "Epoch [14/1000] - Loss: 0.052351 - Valid. (MSE): 0.028482 - Valid. (MAE): 0.122211\n",
      "Epoch [14/1000] - Loss: 0.049994 - Valid. (MSE): 0.027491 - Valid. (MAE): 0.122562\n",
      "Epoch [15/1000] - Loss: 0.054142 - Valid. (MSE): 0.028172 - Valid. (MAE): 0.119116\n",
      "Epoch [16/1000] - Loss: 0.049459 - Valid. (MSE): 0.029562 - Valid. (MAE): 0.119293\n",
      "Epoch [16/1000] - Loss: 0.050311 - Valid. (MSE): 0.026570 - Valid. (MAE): 0.116925\n",
      "Epoch [17/1000] - Loss: 0.048580 - Valid. (MSE): 0.025033 - Valid. (MAE): 0.117352\n",
      "Epoch [18/1000] - Loss: 0.048131 - Valid. (MSE): 0.025627 - Valid. (MAE): 0.114093\n",
      "Epoch [18/1000] - Loss: 0.047406 - Valid. (MSE): 0.029374 - Valid. (MAE): 0.117981\n",
      "Epoch [19/1000] - Loss: 0.051859 - Valid. (MSE): 0.023497 - Valid. (MAE): 0.112469\n",
      "Epoch [19/1000] - Loss: 0.046402 - Valid. (MSE): 0.024420 - Valid. (MAE): 0.111633\n",
      "Epoch [20/1000] - Loss: 0.042958 - Valid. (MSE): 0.024296 - Valid. (MAE): 0.110683\n",
      "Epoch [21/1000] - Loss: 0.044913 - Valid. (MSE): 0.022967 - Valid. (MAE): 0.109183\n",
      "Epoch [21/1000] - Loss: 0.044417 - Valid. (MSE): 0.023170 - Valid. (MAE): 0.109782\n",
      "Epoch [22/1000] - Loss: 0.044303 - Valid. (MSE): 0.023029 - Valid. (MAE): 0.108099\n",
      "Epoch [23/1000] - Loss: 0.041057 - Valid. (MSE): 0.021880 - Valid. (MAE): 0.105567\n",
      "Epoch [23/1000] - Loss: 0.042056 - Valid. (MSE): 0.025833 - Valid. (MAE): 0.110370\n",
      "Epoch [24/1000] - Loss: 0.041865 - Valid. (MSE): 0.022672 - Valid. (MAE): 0.107574\n",
      "Epoch [24/1000] - Loss: 0.041883 - Valid. (MSE): 0.021165 - Valid. (MAE): 0.104954\n",
      "Epoch [25/1000] - Loss: 0.040267 - Valid. (MSE): 0.021686 - Valid. (MAE): 0.103810\n",
      "Epoch [26/1000] - Loss: 0.037928 - Valid. (MSE): 0.023707 - Valid. (MAE): 0.106132\n",
      "Epoch [26/1000] - Loss: 0.040294 - Valid. (MSE): 0.020999 - Valid. (MAE): 0.102517\n",
      "Epoch [27/1000] - Loss: 0.040320 - Valid. (MSE): 0.020354 - Valid. (MAE): 0.102294\n",
      "Epoch [28/1000] - Loss: 0.038097 - Valid. (MSE): 0.022760 - Valid. (MAE): 0.104233\n",
      "Epoch [28/1000] - Loss: 0.038518 - Valid. (MSE): 0.022082 - Valid. (MAE): 0.103432\n",
      "Epoch [29/1000] - Loss: 0.033865 - Valid. (MSE): 0.020406 - Valid. (MAE): 0.099992\n",
      "Epoch [29/1000] - Loss: 0.038533 - Valid. (MSE): 0.020492 - Valid. (MAE): 0.099669\n",
      "Epoch [30/1000] - Loss: 0.041501 - Valid. (MSE): 0.021736 - Valid. (MAE): 0.101712\n",
      "Epoch [31/1000] - Loss: 0.035885 - Valid. (MSE): 0.020734 - Valid. (MAE): 0.099641\n",
      "Epoch [31/1000] - Loss: 0.039579 - Valid. (MSE): 0.019301 - Valid. (MAE): 0.097998\n",
      "Epoch [32/1000] - Loss: 0.036031 - Valid. (MSE): 0.019809 - Valid. (MAE): 0.100381\n",
      "Epoch [33/1000] - Loss: 0.035800 - Valid. (MSE): 0.022696 - Valid. (MAE): 0.102846\n",
      "Epoch [33/1000] - Loss: 0.037023 - Valid. (MSE): 0.020228 - Valid. (MAE): 0.097692\n",
      "Epoch [34/1000] - Loss: 0.036568 - Valid. (MSE): 0.018952 - Valid. (MAE): 0.099157\n",
      "Epoch [34/1000] - Loss: 0.033670 - Valid. (MSE): 0.019799 - Valid. (MAE): 0.097792\n",
      "Epoch [35/1000] - Loss: 0.037280 - Valid. (MSE): 0.019638 - Valid. (MAE): 0.097176\n",
      "Epoch [36/1000] - Loss: 0.034234 - Valid. (MSE): 0.019620 - Valid. (MAE): 0.097205\n",
      "Epoch [36/1000] - Loss: 0.036048 - Valid. (MSE): 0.019787 - Valid. (MAE): 0.097558\n",
      "Epoch [37/1000] - Loss: 0.035863 - Valid. (MSE): 0.018720 - Valid. (MAE): 0.097118\n",
      "Epoch [38/1000] - Loss: 0.035177 - Valid. (MSE): 0.019273 - Valid. (MAE): 0.096056\n",
      "Epoch [38/1000] - Loss: 0.033423 - Valid. (MSE): 0.019828 - Valid. (MAE): 0.097073\n",
      "Epoch [39/1000] - Loss: 0.034077 - Valid. (MSE): 0.019049 - Valid. (MAE): 0.096454\n",
      "Epoch [39/1000] - Loss: 0.033286 - Valid. (MSE): 0.018417 - Valid. (MAE): 0.095116\n",
      "Epoch [40/1000] - Loss: 0.031444 - Valid. (MSE): 0.018786 - Valid. (MAE): 0.094811\n",
      "Epoch [41/1000] - Loss: 0.033012 - Valid. (MSE): 0.019290 - Valid. (MAE): 0.095360\n",
      "Epoch [41/1000] - Loss: 0.035902 - Valid. (MSE): 0.019165 - Valid. (MAE): 0.095932\n",
      "Epoch [42/1000] - Loss: 0.033725 - Valid. (MSE): 0.019743 - Valid. (MAE): 0.096362\n",
      "Epoch [43/1000] - Loss: 0.034801 - Valid. (MSE): 0.018574 - Valid. (MAE): 0.094421\n",
      "Epoch [43/1000] - Loss: 0.033192 - Valid. (MSE): 0.017910 - Valid. (MAE): 0.095399\n",
      "Epoch [44/1000] - Loss: 0.031289 - Valid. (MSE): 0.019059 - Valid. (MAE): 0.094701\n",
      "Epoch [44/1000] - Loss: 0.030353 - Valid. (MSE): 0.020859 - Valid. (MAE): 0.097994\n",
      "Epoch [45/1000] - Loss: 0.033335 - Valid. (MSE): 0.018200 - Valid. (MAE): 0.095181\n",
      "Epoch [46/1000] - Loss: 0.033574 - Valid. (MSE): 0.017992 - Valid. (MAE): 0.093733\n",
      "Epoch [46/1000] - Loss: 0.031011 - Valid. (MSE): 0.019180 - Valid. (MAE): 0.095054\n",
      "Epoch [47/1000] - Loss: 0.029728 - Valid. (MSE): 0.019626 - Valid. (MAE): 0.095635\n",
      "Epoch [48/1000] - Loss: 0.035058 - Valid. (MSE): 0.017592 - Valid. (MAE): 0.093922\n",
      "Epoch [48/1000] - Loss: 0.031597 - Valid. (MSE): 0.018569 - Valid. (MAE): 0.094045\n",
      "Epoch [49/1000] - Loss: 0.029802 - Valid. (MSE): 0.018451 - Valid. (MAE): 0.093676\n",
      "Epoch [49/1000] - Loss: 0.030410 - Valid. (MSE): 0.017663 - Valid. (MAE): 0.093841\n",
      "Epoch [50/1000] - Loss: 0.028993 - Valid. (MSE): 0.018479 - Valid. (MAE): 0.093268\n",
      "Epoch [51/1000] - Loss: 0.030346 - Valid. (MSE): 0.018387 - Valid. (MAE): 0.093039\n",
      "Epoch [51/1000] - Loss: 0.029590 - Valid. (MSE): 0.018317 - Valid. (MAE): 0.092864\n",
      "Epoch [52/1000] - Loss: 0.027470 - Valid. (MSE): 0.017407 - Valid. (MAE): 0.093300\n",
      "Epoch [53/1000] - Loss: 0.028612 - Valid. (MSE): 0.017875 - Valid. (MAE): 0.092073\n",
      "Epoch [53/1000] - Loss: 0.030148 - Valid. (MSE): 0.017753 - Valid. (MAE): 0.092758\n",
      "Epoch [54/1000] - Loss: 0.030930 - Valid. (MSE): 0.017571 - Valid. (MAE): 0.093335\n",
      "Epoch [54/1000] - Loss: 0.031015 - Valid. (MSE): 0.017793 - Valid. (MAE): 0.092103\n",
      "Epoch [55/1000] - Loss: 0.030289 - Valid. (MSE): 0.017672 - Valid. (MAE): 0.091494\n",
      "Epoch [56/1000] - Loss: 0.029907 - Valid. (MSE): 0.017643 - Valid. (MAE): 0.092469\n",
      "Epoch [56/1000] - Loss: 0.031340 - Valid. (MSE): 0.018034 - Valid. (MAE): 0.093019\n",
      "Epoch [57/1000] - Loss: 0.031671 - Valid. (MSE): 0.018309 - Valid. (MAE): 0.093106\n",
      "Epoch [58/1000] - Loss: 0.030323 - Valid. (MSE): 0.017368 - Valid. (MAE): 0.092545\n",
      "Epoch [58/1000] - Loss: 0.028391 - Valid. (MSE): 0.017605 - Valid. (MAE): 0.092022\n",
      "Epoch [59/1000] - Loss: 0.028652 - Valid. (MSE): 0.017510 - Valid. (MAE): 0.093097\n",
      "Epoch [59/1000] - Loss: 0.028203 - Valid. (MSE): 0.017740 - Valid. (MAE): 0.091649\n",
      "Epoch [60/1000] - Loss: 0.030043 - Valid. (MSE): 0.017952 - Valid. (MAE): 0.092480\n",
      "Epoch [61/1000] - Loss: 0.029041 - Valid. (MSE): 0.017362 - Valid. (MAE): 0.091470\n",
      "Epoch [61/1000] - Loss: 0.029306 - Valid. (MSE): 0.017767 - Valid. (MAE): 0.092249\n",
      "Epoch [62/1000] - Loss: 0.028486 - Valid. (MSE): 0.018252 - Valid. (MAE): 0.092141\n",
      "Epoch [63/1000] - Loss: 0.029749 - Valid. (MSE): 0.017116 - Valid. (MAE): 0.092621\n",
      "Epoch [63/1000] - Loss: 0.029276 - Valid. (MSE): 0.017157 - Valid. (MAE): 0.091176\n",
      "Epoch [64/1000] - Loss: 0.027375 - Valid. (MSE): 0.019058 - Valid. (MAE): 0.094129\n",
      "Epoch [64/1000] - Loss: 0.027290 - Valid. (MSE): 0.017194 - Valid. (MAE): 0.093787\n",
      "Epoch [65/1000] - Loss: 0.026559 - Valid. (MSE): 0.017120 - Valid. (MAE): 0.092709\n",
      "Epoch [66/1000] - Loss: 0.027998 - Valid. (MSE): 0.019140 - Valid. (MAE): 0.094302\n",
      "Epoch [66/1000] - Loss: 0.029027 - Valid. (MSE): 0.017099 - Valid. (MAE): 0.093038\n",
      "Epoch [67/1000] - Loss: 0.030356 - Valid. (MSE): 0.017383 - Valid. (MAE): 0.091001\n",
      "Epoch [68/1000] - Loss: 0.029880 - Valid. (MSE): 0.017343 - Valid. (MAE): 0.091959\n",
      "Epoch [68/1000] - Loss: 0.026086 - Valid. (MSE): 0.017855 - Valid. (MAE): 0.091420\n",
      "Epoch [69/1000] - Loss: 0.025634 - Valid. (MSE): 0.016948 - Valid. (MAE): 0.090887\n",
      "Epoch [69/1000] - Loss: 0.029038 - Valid. (MSE): 0.017266 - Valid. (MAE): 0.092272\n",
      "Epoch [70/1000] - Loss: 0.026325 - Valid. (MSE): 0.017061 - Valid. (MAE): 0.091008\n",
      "Epoch [71/1000] - Loss: 0.028367 - Valid. (MSE): 0.016852 - Valid. (MAE): 0.090178\n",
      "Epoch [71/1000] - Loss: 0.027943 - Valid. (MSE): 0.017419 - Valid. (MAE): 0.093182\n",
      "Epoch [72/1000] - Loss: 0.029373 - Valid. (MSE): 0.017401 - Valid. (MAE): 0.091152\n",
      "Epoch [73/1000] - Loss: 0.027257 - Valid. (MSE): 0.017861 - Valid. (MAE): 0.091188\n",
      "Epoch [73/1000] - Loss: 0.027388 - Valid. (MSE): 0.017894 - Valid. (MAE): 0.092476\n",
      "Epoch [74/1000] - Loss: 0.028158 - Valid. (MSE): 0.016852 - Valid. (MAE): 0.092595\n",
      "Epoch [74/1000] - Loss: 0.028864 - Valid. (MSE): 0.017509 - Valid. (MAE): 0.091087\n",
      "Epoch [75/1000] - Loss: 0.028378 - Valid. (MSE): 0.018726 - Valid. (MAE): 0.093292\n",
      "Epoch [76/1000] - Loss: 0.027157 - Valid. (MSE): 0.016827 - Valid. (MAE): 0.093217\n",
      "Epoch [76/1000] - Loss: 0.026418 - Valid. (MSE): 0.017717 - Valid. (MAE): 0.091431\n",
      "Epoch [77/1000] - Loss: 0.028400 - Valid. (MSE): 0.017331 - Valid. (MAE): 0.090065\n",
      "Epoch [78/1000] - Loss: 0.027691 - Valid. (MSE): 0.016751 - Valid. (MAE): 0.089928\n",
      "Epoch [78/1000] - Loss: 0.030257 - Valid. (MSE): 0.018193 - Valid. (MAE): 0.093129\n",
      "Epoch [79/1000] - Loss: 0.025562 - Valid. (MSE): 0.017215 - Valid. (MAE): 0.090202\n",
      "Epoch [79/1000] - Loss: 0.025654 - Valid. (MSE): 0.016888 - Valid. (MAE): 0.089762\n",
      "Epoch [80/1000] - Loss: 0.029290 - Valid. (MSE): 0.017047 - Valid. (MAE): 0.091480\n",
      "Epoch [81/1000] - Loss: 0.028519 - Valid. (MSE): 0.017447 - Valid. (MAE): 0.090186\n",
      "Epoch [81/1000] - Loss: 0.025781 - Valid. (MSE): 0.017087 - Valid. (MAE): 0.092210\n",
      "Epoch [82/1000] - Loss: 0.026650 - Valid. (MSE): 0.016884 - Valid. (MAE): 0.091082\n",
      "Epoch [83/1000] - Loss: 0.026712 - Valid. (MSE): 0.017733 - Valid. (MAE): 0.090698\n",
      "Epoch [83/1000] - Loss: 0.026814 - Valid. (MSE): 0.017052 - Valid. (MAE): 0.091894\n",
      "Epoch [84/1000] - Loss: 0.024971 - Valid. (MSE): 0.017115 - Valid. (MAE): 0.090835\n",
      "Epoch [84/1000] - Loss: 0.026788 - Valid. (MSE): 0.016944 - Valid. (MAE): 0.089800\n",
      "Epoch [85/1000] - Loss: 0.026847 - Valid. (MSE): 0.016980 - Valid. (MAE): 0.092313\n",
      "Epoch [86/1000] - Loss: 0.027006 - Valid. (MSE): 0.017160 - Valid. (MAE): 0.090503\n",
      "Epoch [86/1000] - Loss: 0.026183 - Valid. (MSE): 0.017044 - Valid. (MAE): 0.091234\n",
      "Epoch [87/1000] - Loss: 0.024833 - Valid. (MSE): 0.016770 - Valid. (MAE): 0.090671\n",
      "Epoch [88/1000] - Loss: 0.025790 - Valid. (MSE): 0.017563 - Valid. (MAE): 0.090948\n",
      "Epoch [88/1000] - Loss: 0.026271 - Valid. (MSE): 0.016892 - Valid. (MAE): 0.090392\n",
      "Epoch [89/1000] - Loss: 0.024754 - Valid. (MSE): 0.016807 - Valid. (MAE): 0.090550\n",
      "Epoch [89/1000] - Loss: 0.026072 - Valid. (MSE): 0.016776 - Valid. (MAE): 0.091149\n",
      "Epoch [90/1000] - Loss: 0.026023 - Valid. (MSE): 0.016964 - Valid. (MAE): 0.090630\n",
      "Epoch [91/1000] - Loss: 0.027034 - Valid. (MSE): 0.017528 - Valid. (MAE): 0.090986\n",
      "Epoch [91/1000] - Loss: 0.024504 - Valid. (MSE): 0.016816 - Valid. (MAE): 0.092234\n",
      "Epoch [92/1000] - Loss: 0.025203 - Valid. (MSE): 0.016650 - Valid. (MAE): 0.089812\n",
      "Epoch [93/1000] - Loss: 0.026666 - Valid. (MSE): 0.017110 - Valid. (MAE): 0.092123\n",
      "Epoch [93/1000] - Loss: 0.029732 - Valid. (MSE): 0.016784 - Valid. (MAE): 0.090125\n",
      "Epoch [94/1000] - Loss: 0.024094 - Valid. (MSE): 0.016581 - Valid. (MAE): 0.090551\n",
      "Epoch [94/1000] - Loss: 0.026050 - Valid. (MSE): 0.017195 - Valid. (MAE): 0.091406\n",
      "Epoch [95/1000] - Loss: 0.024767 - Valid. (MSE): 0.016954 - Valid. (MAE): 0.090086\n",
      "Epoch [96/1000] - Loss: 0.024750 - Valid. (MSE): 0.016706 - Valid. (MAE): 0.089990\n",
      "Epoch [96/1000] - Loss: 0.025468 - Valid. (MSE): 0.017095 - Valid. (MAE): 0.091150\n",
      "Epoch [97/1000] - Loss: 0.024605 - Valid. (MSE): 0.016759 - Valid. (MAE): 0.089463\n",
      "Epoch [98/1000] - Loss: 0.023807 - Valid. (MSE): 0.016808 - Valid. (MAE): 0.091873\n",
      "Epoch [98/1000] - Loss: 0.024739 - Valid. (MSE): 0.016806 - Valid. (MAE): 0.090510\n",
      "Epoch [99/1000] - Loss: 0.026642 - Valid. (MSE): 0.017079 - Valid. (MAE): 0.090284\n",
      "Epoch [99/1000] - Loss: 0.023827 - Valid. (MSE): 0.017638 - Valid. (MAE): 0.091464\n",
      "Epoch [100/1000] - Loss: 0.025169 - Valid. (MSE): 0.016927 - Valid. (MAE): 0.092798\n",
      "Epoch [101/1000] - Loss: 0.023504 - Valid. (MSE): 0.016823 - Valid. (MAE): 0.090049\n",
      "Epoch [101/1000] - Loss: 0.024047 - Valid. (MSE): 0.017937 - Valid. (MAE): 0.091751\n",
      "Epoch [102/1000] - Loss: 0.027004 - Valid. (MSE): 0.016726 - Valid. (MAE): 0.093025\n",
      "Epoch [103/1000] - Loss: 0.025321 - Valid. (MSE): 0.017292 - Valid. (MAE): 0.090970\n",
      "Epoch [103/1000] - Loss: 0.025811 - Valid. (MSE): 0.016972 - Valid. (MAE): 0.090216\n",
      "Epoch [104/1000] - Loss: 0.028539 - Valid. (MSE): 0.016644 - Valid. (MAE): 0.090794\n",
      "Epoch [104/1000] - Loss: 0.024475 - Valid. (MSE): 0.017153 - Valid. (MAE): 0.090690\n",
      "Epoch [105/1000] - Loss: 0.026510 - Valid. (MSE): 0.017190 - Valid. (MAE): 0.090362\n",
      "Epoch [106/1000] - Loss: 0.025395 - Valid. (MSE): 0.016957 - Valid. (MAE): 0.092513\n",
      "Epoch [106/1000] - Loss: 0.024894 - Valid. (MSE): 0.017480 - Valid. (MAE): 0.091090\n",
      "Epoch [107/1000] - Loss: 0.025317 - Valid. (MSE): 0.016505 - Valid. (MAE): 0.091303\n",
      "Epoch [108/1000] - Loss: 0.025158 - Valid. (MSE): 0.017253 - Valid. (MAE): 0.091462\n",
      "Epoch [108/1000] - Loss: 0.023305 - Valid. (MSE): 0.016899 - Valid. (MAE): 0.089871\n",
      "Epoch [109/1000] - Loss: 0.025865 - Valid. (MSE): 0.016392 - Valid. (MAE): 0.090042\n",
      "Epoch [109/1000] - Loss: 0.023467 - Valid. (MSE): 0.016799 - Valid. (MAE): 0.090980\n",
      "Epoch [110/1000] - Loss: 0.023812 - Valid. (MSE): 0.016804 - Valid. (MAE): 0.090242\n",
      "Epoch [111/1000] - Loss: 0.025165 - Valid. (MSE): 0.016793 - Valid. (MAE): 0.091655\n",
      "Epoch [111/1000] - Loss: 0.023921 - Valid. (MSE): 0.016607 - Valid. (MAE): 0.090324\n",
      "Epoch [112/1000] - Loss: 0.026833 - Valid. (MSE): 0.017222 - Valid. (MAE): 0.091100\n",
      "Epoch [113/1000] - Loss: 0.024011 - Valid. (MSE): 0.016455 - Valid. (MAE): 0.090188\n",
      "Epoch [113/1000] - Loss: 0.027346 - Valid. (MSE): 0.016846 - Valid. (MAE): 0.090814\n",
      "Epoch [114/1000] - Loss: 0.025423 - Valid. (MSE): 0.016871 - Valid. (MAE): 0.090237\n",
      "Epoch [114/1000] - Loss: 0.024156 - Valid. (MSE): 0.016807 - Valid. (MAE): 0.090585\n",
      "Epoch [115/1000] - Loss: 0.025661 - Valid. (MSE): 0.017113 - Valid. (MAE): 0.092720\n",
      "Epoch [116/1000] - Loss: 0.024997 - Valid. (MSE): 0.016505 - Valid. (MAE): 0.090501\n",
      "Epoch [116/1000] - Loss: 0.026070 - Valid. (MSE): 0.016504 - Valid. (MAE): 0.090199\n",
      "Epoch [117/1000] - Loss: 0.024242 - Valid. (MSE): 0.016885 - Valid. (MAE): 0.092105\n",
      "Epoch [118/1000] - Loss: 0.022193 - Valid. (MSE): 0.017416 - Valid. (MAE): 0.090880\n",
      "Epoch [118/1000] - Loss: 0.025799 - Valid. (MSE): 0.016731 - Valid. (MAE): 0.091700\n",
      "Epoch [119/1000] - Loss: 0.023982 - Valid. (MSE): 0.016566 - Valid. (MAE): 0.090265\n",
      "Epoch [119/1000] - Loss: 0.023537 - Valid. (MSE): 0.016622 - Valid. (MAE): 0.089860\n",
      "Epoch [120/1000] - Loss: 0.024068 - Valid. (MSE): 0.016498 - Valid. (MAE): 0.089803\n",
      "Epoch [121/1000] - Loss: 0.023856 - Valid. (MSE): 0.016616 - Valid. (MAE): 0.090516\n",
      "Epoch [121/1000] - Loss: 0.025551 - Valid. (MSE): 0.016785 - Valid. (MAE): 0.090595\n",
      "Epoch [122/1000] - Loss: 0.025482 - Valid. (MSE): 0.016590 - Valid. (MAE): 0.089729\n",
      "Epoch [123/1000] - Loss: 0.022382 - Valid. (MSE): 0.016802 - Valid. (MAE): 0.090992\n",
      "Epoch [123/1000] - Loss: 0.026418 - Valid. (MSE): 0.016415 - Valid. (MAE): 0.090984\n",
      "Epoch [124/1000] - Loss: 0.025002 - Valid. (MSE): 0.016687 - Valid. (MAE): 0.091243\n",
      "Epoch [124/1000] - Loss: 0.023952 - Valid. (MSE): 0.017150 - Valid. (MAE): 0.090868\n",
      "Epoch [125/1000] - Loss: 0.022954 - Valid. (MSE): 0.016493 - Valid. (MAE): 0.092506\n",
      "Epoch [126/1000] - Loss: 0.024700 - Valid. (MSE): 0.017121 - Valid. (MAE): 0.090483\n",
      "Epoch [126/1000] - Loss: 0.024116 - Valid. (MSE): 0.016631 - Valid. (MAE): 0.091770\n",
      "Epoch [127/1000] - Loss: 0.022485 - Valid. (MSE): 0.017048 - Valid. (MAE): 0.090417\n",
      "Epoch [128/1000] - Loss: 0.023935 - Valid. (MSE): 0.016490 - Valid. (MAE): 0.089674\n",
      "Epoch [128/1000] - Loss: 0.024848 - Valid. (MSE): 0.016422 - Valid. (MAE): 0.090582\n",
      "Epoch [129/1000] - Loss: 0.023137 - Valid. (MSE): 0.016997 - Valid. (MAE): 0.090408\n",
      "Epoch [129/1000] - Loss: 0.022826 - Valid. (MSE): 0.016533 - Valid. (MAE): 0.090354\n",
      "Epoch [130/1000] - Loss: 0.024258 - Valid. (MSE): 0.016380 - Valid. (MAE): 0.090425\n",
      "Epoch [131/1000] - Loss: 0.023464 - Valid. (MSE): 0.017226 - Valid. (MAE): 0.091313\n",
      "Epoch [131/1000] - Loss: 0.023723 - Valid. (MSE): 0.016569 - Valid. (MAE): 0.090939\n",
      "Epoch [132/1000] - Loss: 0.024310 - Valid. (MSE): 0.016642 - Valid. (MAE): 0.090203\n",
      "Epoch [133/1000] - Loss: 0.024714 - Valid. (MSE): 0.016674 - Valid. (MAE): 0.091776\n",
      "Epoch [133/1000] - Loss: 0.025171 - Valid. (MSE): 0.016711 - Valid. (MAE): 0.089546\n",
      "Epoch [134/1000] - Loss: 0.024261 - Valid. (MSE): 0.016449 - Valid. (MAE): 0.090000\n",
      "Epoch [134/1000] - Loss: 0.025964 - Valid. (MSE): 0.016617 - Valid. (MAE): 0.090922\n",
      "Epoch [135/1000] - Loss: 0.023190 - Valid. (MSE): 0.016364 - Valid. (MAE): 0.090340\n",
      "Epoch [136/1000] - Loss: 0.023230 - Valid. (MSE): 0.016957 - Valid. (MAE): 0.091508\n",
      "Epoch [136/1000] - Loss: 0.022971 - Valid. (MSE): 0.016356 - Valid. (MAE): 0.091310\n",
      "Epoch [137/1000] - Loss: 0.021439 - Valid. (MSE): 0.016913 - Valid. (MAE): 0.090196\n",
      "Epoch [138/1000] - Loss: 0.023314 - Valid. (MSE): 0.016615 - Valid. (MAE): 0.091974\n",
      "Epoch [138/1000] - Loss: 0.022533 - Valid. (MSE): 0.016264 - Valid. (MAE): 0.090516\n",
      "Epoch [139/1000] - Loss: 0.023102 - Valid. (MSE): 0.017400 - Valid. (MAE): 0.092158\n",
      "Epoch [139/1000] - Loss: 0.024103 - Valid. (MSE): 0.016397 - Valid. (MAE): 0.090516\n",
      "Epoch [140/1000] - Loss: 0.020229 - Valid. (MSE): 0.016633 - Valid. (MAE): 0.090171\n",
      "Stopping early at epoch 141. Best validation MSE: 0.016392489696313153 at epoch 109.\n",
      "Seed 43 completed:\n",
      "  - Final epoch: 141\n",
      "  - Best epoch: 109\n",
      "  - Training time: 1539.05s\n",
      "  - Test MSE: 0.017188\n",
      "  - Test MAE: 0.091918\n",
      "  - MPE: 0.034055\n",
      "  - Coverage 95%: 0.9268\n",
      "\n",
      "--- Training with seed 44 (3/10) ---\n",
      "Starting training for seed 44...\n",
      "Epoch [0/1000] - Loss: 0.159038 - Valid. (MSE): 0.090791 - Valid. (MAE): 0.216395\n",
      "Epoch [1/1000] - Loss: 0.129218 - Valid. (MSE): 0.059783 - Valid. (MAE): 0.194025\n",
      "Epoch [1/1000] - Loss: 0.103075 - Valid. (MSE): 0.070843 - Valid. (MAE): 0.190472\n",
      "Epoch [2/1000] - Loss: 0.093201 - Valid. (MSE): 0.059904 - Valid. (MAE): 0.180619\n",
      "Epoch [3/1000] - Loss: 0.092713 - Valid. (MSE): 0.055690 - Valid. (MAE): 0.177862\n",
      "Epoch [3/1000] - Loss: 0.084680 - Valid. (MSE): 0.054769 - Valid. (MAE): 0.172711\n",
      "Epoch [4/1000] - Loss: 0.083065 - Valid. (MSE): 0.050145 - Valid. (MAE): 0.171789\n",
      "Epoch [4/1000] - Loss: 0.076978 - Valid. (MSE): 0.050885 - Valid. (MAE): 0.165429\n",
      "Epoch [5/1000] - Loss: 0.077243 - Valid. (MSE): 0.046118 - Valid. (MAE): 0.164831\n",
      "Epoch [6/1000] - Loss: 0.075314 - Valid. (MSE): 0.046934 - Valid. (MAE): 0.158306\n",
      "Epoch [6/1000] - Loss: 0.074293 - Valid. (MSE): 0.042560 - Valid. (MAE): 0.160708\n",
      "Epoch [7/1000] - Loss: 0.064924 - Valid. (MSE): 0.043125 - Valid. (MAE): 0.151900\n",
      "Epoch [8/1000] - Loss: 0.069079 - Valid. (MSE): 0.040890 - Valid. (MAE): 0.150965\n",
      "Epoch [8/1000] - Loss: 0.064814 - Valid. (MSE): 0.039652 - Valid. (MAE): 0.148493\n",
      "Epoch [9/1000] - Loss: 0.066520 - Valid. (MSE): 0.040882 - Valid. (MAE): 0.144363\n",
      "Epoch [9/1000] - Loss: 0.063208 - Valid. (MSE): 0.036842 - Valid. (MAE): 0.145413\n",
      "Epoch [10/1000] - Loss: 0.054608 - Valid. (MSE): 0.035660 - Valid. (MAE): 0.142084\n",
      "Epoch [11/1000] - Loss: 0.058952 - Valid. (MSE): 0.036725 - Valid. (MAE): 0.136345\n",
      "Epoch [11/1000] - Loss: 0.056073 - Valid. (MSE): 0.034352 - Valid. (MAE): 0.134292\n",
      "Epoch [12/1000] - Loss: 0.051559 - Valid. (MSE): 0.032258 - Valid. (MAE): 0.133795\n",
      "Epoch [13/1000] - Loss: 0.051185 - Valid. (MSE): 0.032128 - Valid. (MAE): 0.129430\n",
      "Epoch [13/1000] - Loss: 0.050490 - Valid. (MSE): 0.031113 - Valid. (MAE): 0.126478\n",
      "Epoch [14/1000] - Loss: 0.050312 - Valid. (MSE): 0.029135 - Valid. (MAE): 0.125157\n",
      "Epoch [14/1000] - Loss: 0.051160 - Valid. (MSE): 0.028263 - Valid. (MAE): 0.125363\n",
      "Epoch [15/1000] - Loss: 0.047848 - Valid. (MSE): 0.030146 - Valid. (MAE): 0.123172\n",
      "Epoch [16/1000] - Loss: 0.051357 - Valid. (MSE): 0.032482 - Valid. (MAE): 0.125406\n",
      "Epoch [16/1000] - Loss: 0.046539 - Valid. (MSE): 0.027401 - Valid. (MAE): 0.119958\n",
      "Epoch [17/1000] - Loss: 0.044062 - Valid. (MSE): 0.025871 - Valid. (MAE): 0.123852\n",
      "Epoch [18/1000] - Loss: 0.048539 - Valid. (MSE): 0.027263 - Valid. (MAE): 0.117467\n",
      "Epoch [18/1000] - Loss: 0.044019 - Valid. (MSE): 0.026250 - Valid. (MAE): 0.116336\n",
      "Epoch [19/1000] - Loss: 0.044998 - Valid. (MSE): 0.025828 - Valid. (MAE): 0.114642\n",
      "Epoch [19/1000] - Loss: 0.043435 - Valid. (MSE): 0.027362 - Valid. (MAE): 0.116393\n",
      "Epoch [20/1000] - Loss: 0.043180 - Valid. (MSE): 0.025543 - Valid. (MAE): 0.116455\n",
      "Epoch [21/1000] - Loss: 0.043514 - Valid. (MSE): 0.023954 - Valid. (MAE): 0.116064\n",
      "Epoch [21/1000] - Loss: 0.043804 - Valid. (MSE): 0.025005 - Valid. (MAE): 0.112794\n",
      "Epoch [22/1000] - Loss: 0.042754 - Valid. (MSE): 0.026108 - Valid. (MAE): 0.113571\n",
      "Epoch [23/1000] - Loss: 0.040800 - Valid. (MSE): 0.023594 - Valid. (MAE): 0.110697\n",
      "Epoch [23/1000] - Loss: 0.039518 - Valid. (MSE): 0.023062 - Valid. (MAE): 0.109776\n",
      "Epoch [24/1000] - Loss: 0.040428 - Valid. (MSE): 0.023583 - Valid. (MAE): 0.108773\n",
      "Epoch [24/1000] - Loss: 0.039499 - Valid. (MSE): 0.023965 - Valid. (MAE): 0.108810\n",
      "Epoch [25/1000] - Loss: 0.034716 - Valid. (MSE): 0.023195 - Valid. (MAE): 0.107838\n",
      "Epoch [26/1000] - Loss: 0.037675 - Valid. (MSE): 0.021686 - Valid. (MAE): 0.107232\n",
      "Epoch [26/1000] - Loss: 0.038323 - Valid. (MSE): 0.021749 - Valid. (MAE): 0.106788\n",
      "Epoch [27/1000] - Loss: 0.035430 - Valid. (MSE): 0.022586 - Valid. (MAE): 0.107623\n",
      "Epoch [28/1000] - Loss: 0.040699 - Valid. (MSE): 0.022773 - Valid. (MAE): 0.106696\n",
      "Epoch [28/1000] - Loss: 0.038757 - Valid. (MSE): 0.022430 - Valid. (MAE): 0.104900\n",
      "Epoch [29/1000] - Loss: 0.034735 - Valid. (MSE): 0.022410 - Valid. (MAE): 0.104676\n",
      "Epoch [29/1000] - Loss: 0.037488 - Valid. (MSE): 0.020666 - Valid. (MAE): 0.104589\n",
      "Epoch [30/1000] - Loss: 0.037778 - Valid. (MSE): 0.021012 - Valid. (MAE): 0.102707\n",
      "Epoch [31/1000] - Loss: 0.032224 - Valid. (MSE): 0.022357 - Valid. (MAE): 0.103671\n",
      "Epoch [31/1000] - Loss: 0.035832 - Valid. (MSE): 0.020970 - Valid. (MAE): 0.101180\n",
      "Epoch [32/1000] - Loss: 0.035544 - Valid. (MSE): 0.020195 - Valid. (MAE): 0.101079\n",
      "Epoch [33/1000] - Loss: 0.036405 - Valid. (MSE): 0.020456 - Valid. (MAE): 0.102202\n",
      "Epoch [33/1000] - Loss: 0.034356 - Valid. (MSE): 0.020529 - Valid. (MAE): 0.100026\n",
      "Epoch [34/1000] - Loss: 0.035228 - Valid. (MSE): 0.021317 - Valid. (MAE): 0.101487\n",
      "Epoch [34/1000] - Loss: 0.033961 - Valid. (MSE): 0.020377 - Valid. (MAE): 0.099783\n",
      "Epoch [35/1000] - Loss: 0.032559 - Valid. (MSE): 0.019439 - Valid. (MAE): 0.099384\n",
      "Epoch [36/1000] - Loss: 0.035877 - Valid. (MSE): 0.020480 - Valid. (MAE): 0.100746\n",
      "Epoch [36/1000] - Loss: 0.033171 - Valid. (MSE): 0.020191 - Valid. (MAE): 0.099330\n",
      "Epoch [37/1000] - Loss: 0.032549 - Valid. (MSE): 0.019705 - Valid. (MAE): 0.099420\n",
      "Epoch [38/1000] - Loss: 0.033575 - Valid. (MSE): 0.019981 - Valid. (MAE): 0.099928\n",
      "Epoch [38/1000] - Loss: 0.032759 - Valid. (MSE): 0.019485 - Valid. (MAE): 0.098146\n",
      "Epoch [39/1000] - Loss: 0.029723 - Valid. (MSE): 0.019676 - Valid. (MAE): 0.098015\n",
      "Epoch [39/1000] - Loss: 0.036030 - Valid. (MSE): 0.019073 - Valid. (MAE): 0.099229\n",
      "Epoch [40/1000] - Loss: 0.031987 - Valid. (MSE): 0.019655 - Valid. (MAE): 0.098442\n",
      "Epoch [41/1000] - Loss: 0.032225 - Valid. (MSE): 0.020019 - Valid. (MAE): 0.097977\n",
      "Epoch [41/1000] - Loss: 0.031204 - Valid. (MSE): 0.019194 - Valid. (MAE): 0.096548\n",
      "Epoch [42/1000] - Loss: 0.033001 - Valid. (MSE): 0.019206 - Valid. (MAE): 0.096583\n",
      "Epoch [43/1000] - Loss: 0.032525 - Valid. (MSE): 0.019578 - Valid. (MAE): 0.097700\n",
      "Epoch [43/1000] - Loss: 0.032300 - Valid. (MSE): 0.018563 - Valid. (MAE): 0.097576\n",
      "Epoch [44/1000] - Loss: 0.033820 - Valid. (MSE): 0.019661 - Valid. (MAE): 0.096636\n",
      "Epoch [44/1000] - Loss: 0.030248 - Valid. (MSE): 0.018688 - Valid. (MAE): 0.097249\n",
      "Epoch [45/1000] - Loss: 0.028798 - Valid. (MSE): 0.018151 - Valid. (MAE): 0.097375\n",
      "Epoch [46/1000] - Loss: 0.031216 - Valid. (MSE): 0.019472 - Valid. (MAE): 0.096710\n",
      "Epoch [46/1000] - Loss: 0.031294 - Valid. (MSE): 0.019074 - Valid. (MAE): 0.096466\n",
      "Epoch [47/1000] - Loss: 0.030519 - Valid. (MSE): 0.018932 - Valid. (MAE): 0.095074\n",
      "Epoch [48/1000] - Loss: 0.031431 - Valid. (MSE): 0.019003 - Valid. (MAE): 0.097434\n",
      "Epoch [48/1000] - Loss: 0.029651 - Valid. (MSE): 0.018277 - Valid. (MAE): 0.095237\n",
      "Epoch [49/1000] - Loss: 0.028413 - Valid. (MSE): 0.018708 - Valid. (MAE): 0.094840\n",
      "Epoch [49/1000] - Loss: 0.029679 - Valid. (MSE): 0.019215 - Valid. (MAE): 0.096495\n",
      "Epoch [50/1000] - Loss: 0.028546 - Valid. (MSE): 0.018737 - Valid. (MAE): 0.094693\n",
      "Epoch [51/1000] - Loss: 0.030401 - Valid. (MSE): 0.018878 - Valid. (MAE): 0.097003\n",
      "Epoch [51/1000] - Loss: 0.032420 - Valid. (MSE): 0.018548 - Valid. (MAE): 0.094408\n",
      "Epoch [52/1000] - Loss: 0.029009 - Valid. (MSE): 0.019552 - Valid. (MAE): 0.095762\n",
      "Epoch [53/1000] - Loss: 0.024777 - Valid. (MSE): 0.018099 - Valid. (MAE): 0.093836\n",
      "Epoch [53/1000] - Loss: 0.028000 - Valid. (MSE): 0.018223 - Valid. (MAE): 0.095169\n",
      "Epoch [54/1000] - Loss: 0.029961 - Valid. (MSE): 0.018962 - Valid. (MAE): 0.094510\n",
      "Epoch [54/1000] - Loss: 0.029918 - Valid. (MSE): 0.017829 - Valid. (MAE): 0.093793\n",
      "Epoch [55/1000] - Loss: 0.028422 - Valid. (MSE): 0.017989 - Valid. (MAE): 0.094378\n",
      "Epoch [56/1000] - Loss: 0.028175 - Valid. (MSE): 0.018843 - Valid. (MAE): 0.094109\n",
      "Epoch [56/1000] - Loss: 0.028891 - Valid. (MSE): 0.018403 - Valid. (MAE): 0.094581\n",
      "Epoch [57/1000] - Loss: 0.026871 - Valid. (MSE): 0.018149 - Valid. (MAE): 0.093513\n",
      "Epoch [58/1000] - Loss: 0.027690 - Valid. (MSE): 0.017899 - Valid. (MAE): 0.093619\n",
      "Epoch [58/1000] - Loss: 0.027158 - Valid. (MSE): 0.018202 - Valid. (MAE): 0.093531\n",
      "Epoch [59/1000] - Loss: 0.027014 - Valid. (MSE): 0.018125 - Valid. (MAE): 0.093941\n",
      "Epoch [59/1000] - Loss: 0.029036 - Valid. (MSE): 0.017845 - Valid. (MAE): 0.093106\n",
      "Epoch [60/1000] - Loss: 0.028403 - Valid. (MSE): 0.018180 - Valid. (MAE): 0.095139\n",
      "Epoch [61/1000] - Loss: 0.025988 - Valid. (MSE): 0.018477 - Valid. (MAE): 0.093143\n",
      "Epoch [61/1000] - Loss: 0.027504 - Valid. (MSE): 0.018142 - Valid. (MAE): 0.094867\n",
      "Epoch [62/1000] - Loss: 0.031155 - Valid. (MSE): 0.017479 - Valid. (MAE): 0.093120\n",
      "Epoch [63/1000] - Loss: 0.029844 - Valid. (MSE): 0.017987 - Valid. (MAE): 0.092929\n",
      "Epoch [63/1000] - Loss: 0.026587 - Valid. (MSE): 0.018117 - Valid. (MAE): 0.092679\n",
      "Epoch [64/1000] - Loss: 0.029463 - Valid. (MSE): 0.017441 - Valid. (MAE): 0.091859\n",
      "Epoch [64/1000] - Loss: 0.025946 - Valid. (MSE): 0.017878 - Valid. (MAE): 0.094518\n",
      "Epoch [65/1000] - Loss: 0.027160 - Valid. (MSE): 0.018392 - Valid. (MAE): 0.092836\n",
      "Epoch [66/1000] - Loss: 0.028143 - Valid. (MSE): 0.018687 - Valid. (MAE): 0.095319\n",
      "Epoch [66/1000] - Loss: 0.028637 - Valid. (MSE): 0.017533 - Valid. (MAE): 0.091939\n",
      "Epoch [67/1000] - Loss: 0.027912 - Valid. (MSE): 0.018350 - Valid. (MAE): 0.095391\n",
      "Epoch [68/1000] - Loss: 0.026176 - Valid. (MSE): 0.017427 - Valid. (MAE): 0.092751\n",
      "Epoch [68/1000] - Loss: 0.027250 - Valid. (MSE): 0.018464 - Valid. (MAE): 0.093658\n",
      "Epoch [69/1000] - Loss: 0.026715 - Valid. (MSE): 0.018156 - Valid. (MAE): 0.092676\n",
      "Epoch [69/1000] - Loss: 0.028034 - Valid. (MSE): 0.017527 - Valid. (MAE): 0.092873\n",
      "Epoch [70/1000] - Loss: 0.028368 - Valid. (MSE): 0.017318 - Valid. (MAE): 0.093043\n",
      "Epoch [71/1000] - Loss: 0.025237 - Valid. (MSE): 0.017971 - Valid. (MAE): 0.092028\n",
      "Epoch [71/1000] - Loss: 0.029333 - Valid. (MSE): 0.017509 - Valid. (MAE): 0.093732\n",
      "Epoch [72/1000] - Loss: 0.029288 - Valid. (MSE): 0.017572 - Valid. (MAE): 0.091298\n",
      "Epoch [73/1000] - Loss: 0.025090 - Valid. (MSE): 0.018140 - Valid. (MAE): 0.093358\n",
      "Epoch [73/1000] - Loss: 0.027057 - Valid. (MSE): 0.017545 - Valid. (MAE): 0.092326\n",
      "Epoch [74/1000] - Loss: 0.024045 - Valid. (MSE): 0.017449 - Valid. (MAE): 0.092451\n",
      "Epoch [74/1000] - Loss: 0.025918 - Valid. (MSE): 0.018055 - Valid. (MAE): 0.093574\n",
      "Epoch [75/1000] - Loss: 0.026756 - Valid. (MSE): 0.017322 - Valid. (MAE): 0.092495\n",
      "Epoch [76/1000] - Loss: 0.027630 - Valid. (MSE): 0.018240 - Valid. (MAE): 0.092661\n",
      "Epoch [76/1000] - Loss: 0.026905 - Valid. (MSE): 0.018315 - Valid. (MAE): 0.092868\n",
      "Epoch [77/1000] - Loss: 0.026236 - Valid. (MSE): 0.017254 - Valid. (MAE): 0.092043\n",
      "Epoch [78/1000] - Loss: 0.024046 - Valid. (MSE): 0.018278 - Valid. (MAE): 0.093908\n",
      "Epoch [78/1000] - Loss: 0.025553 - Valid. (MSE): 0.017622 - Valid. (MAE): 0.091573\n",
      "Epoch [79/1000] - Loss: 0.026215 - Valid. (MSE): 0.017638 - Valid. (MAE): 0.095901\n",
      "Epoch [79/1000] - Loss: 0.027574 - Valid. (MSE): 0.017663 - Valid. (MAE): 0.092150\n",
      "Epoch [80/1000] - Loss: 0.025923 - Valid. (MSE): 0.018324 - Valid. (MAE): 0.092613\n",
      "Epoch [81/1000] - Loss: 0.025687 - Valid. (MSE): 0.017305 - Valid. (MAE): 0.092359\n",
      "Epoch [81/1000] - Loss: 0.023922 - Valid. (MSE): 0.017738 - Valid. (MAE): 0.092460\n",
      "Epoch [82/1000] - Loss: 0.022724 - Valid. (MSE): 0.017937 - Valid. (MAE): 0.092434\n",
      "Epoch [83/1000] - Loss: 0.024889 - Valid. (MSE): 0.017660 - Valid. (MAE): 0.094316\n",
      "Epoch [83/1000] - Loss: 0.027120 - Valid. (MSE): 0.016901 - Valid. (MAE): 0.092173\n",
      "Epoch [84/1000] - Loss: 0.025443 - Valid. (MSE): 0.018155 - Valid. (MAE): 0.092719\n",
      "Epoch [84/1000] - Loss: 0.025125 - Valid. (MSE): 0.017346 - Valid. (MAE): 0.090771\n",
      "Epoch [85/1000] - Loss: 0.025920 - Valid. (MSE): 0.017544 - Valid. (MAE): 0.095926\n",
      "Epoch [86/1000] - Loss: 0.026280 - Valid. (MSE): 0.018044 - Valid. (MAE): 0.092708\n",
      "Epoch [86/1000] - Loss: 0.024765 - Valid. (MSE): 0.017513 - Valid. (MAE): 0.094087\n",
      "Epoch [87/1000] - Loss: 0.023756 - Valid. (MSE): 0.017295 - Valid. (MAE): 0.091608\n",
      "Epoch [88/1000] - Loss: 0.025536 - Valid. (MSE): 0.017999 - Valid. (MAE): 0.093161\n",
      "Epoch [88/1000] - Loss: 0.023607 - Valid. (MSE): 0.017329 - Valid. (MAE): 0.091175\n",
      "Epoch [89/1000] - Loss: 0.025958 - Valid. (MSE): 0.017538 - Valid. (MAE): 0.091301\n",
      "Epoch [89/1000] - Loss: 0.026587 - Valid. (MSE): 0.017845 - Valid. (MAE): 0.094807\n",
      "Epoch [90/1000] - Loss: 0.026225 - Valid. (MSE): 0.017323 - Valid. (MAE): 0.091100\n",
      "Epoch [91/1000] - Loss: 0.025155 - Valid. (MSE): 0.017972 - Valid. (MAE): 0.092363\n",
      "Epoch [91/1000] - Loss: 0.024975 - Valid. (MSE): 0.017156 - Valid. (MAE): 0.092412\n",
      "Epoch [92/1000] - Loss: 0.024327 - Valid. (MSE): 0.017287 - Valid. (MAE): 0.092267\n",
      "Epoch [93/1000] - Loss: 0.025557 - Valid. (MSE): 0.017584 - Valid. (MAE): 0.091553\n",
      "Epoch [93/1000] - Loss: 0.024702 - Valid. (MSE): 0.016903 - Valid. (MAE): 0.093580\n",
      "Epoch [94/1000] - Loss: 0.023547 - Valid. (MSE): 0.018255 - Valid. (MAE): 0.092837\n",
      "Epoch [94/1000] - Loss: 0.024605 - Valid. (MSE): 0.017021 - Valid. (MAE): 0.090594\n",
      "Epoch [95/1000] - Loss: 0.023218 - Valid. (MSE): 0.017250 - Valid. (MAE): 0.091667\n",
      "Epoch [96/1000] - Loss: 0.023056 - Valid. (MSE): 0.017002 - Valid. (MAE): 0.090559\n",
      "Epoch [96/1000] - Loss: 0.022969 - Valid. (MSE): 0.017551 - Valid. (MAE): 0.092274\n",
      "Epoch [97/1000] - Loss: 0.022785 - Valid. (MSE): 0.017255 - Valid. (MAE): 0.091350\n",
      "Epoch [98/1000] - Loss: 0.023646 - Valid. (MSE): 0.017298 - Valid. (MAE): 0.091638\n",
      "Epoch [98/1000] - Loss: 0.024023 - Valid. (MSE): 0.017622 - Valid. (MAE): 0.092310\n",
      "Epoch [99/1000] - Loss: 0.024433 - Valid. (MSE): 0.017252 - Valid. (MAE): 0.091021\n",
      "Epoch [99/1000] - Loss: 0.025480 - Valid. (MSE): 0.017661 - Valid. (MAE): 0.094481\n",
      "Epoch [100/1000] - Loss: 0.025796 - Valid. (MSE): 0.017273 - Valid. (MAE): 0.090860\n",
      "Epoch [101/1000] - Loss: 0.023820 - Valid. (MSE): 0.017265 - Valid. (MAE): 0.092166\n",
      "Epoch [101/1000] - Loss: 0.025002 - Valid. (MSE): 0.018487 - Valid. (MAE): 0.092986\n",
      "Epoch [102/1000] - Loss: 0.024997 - Valid. (MSE): 0.016849 - Valid. (MAE): 0.092869\n",
      "Epoch [103/1000] - Loss: 0.023958 - Valid. (MSE): 0.018338 - Valid. (MAE): 0.093609\n",
      "Epoch [103/1000] - Loss: 0.025357 - Valid. (MSE): 0.016999 - Valid. (MAE): 0.092091\n",
      "Epoch [104/1000] - Loss: 0.025149 - Valid. (MSE): 0.017300 - Valid. (MAE): 0.092700\n",
      "Epoch [104/1000] - Loss: 0.022980 - Valid. (MSE): 0.017481 - Valid. (MAE): 0.091594\n",
      "Epoch [105/1000] - Loss: 0.022513 - Valid. (MSE): 0.017277 - Valid. (MAE): 0.091967\n",
      "Epoch [106/1000] - Loss: 0.026389 - Valid. (MSE): 0.017164 - Valid. (MAE): 0.093846\n",
      "Epoch [106/1000] - Loss: 0.025398 - Valid. (MSE): 0.017228 - Valid. (MAE): 0.091633\n",
      "Epoch [107/1000] - Loss: 0.025578 - Valid. (MSE): 0.017189 - Valid. (MAE): 0.091543\n",
      "Epoch [108/1000] - Loss: 0.024708 - Valid. (MSE): 0.017187 - Valid. (MAE): 0.093267\n",
      "Epoch [108/1000] - Loss: 0.026556 - Valid. (MSE): 0.017318 - Valid. (MAE): 0.091378\n",
      "Epoch [109/1000] - Loss: 0.024232 - Valid. (MSE): 0.016935 - Valid. (MAE): 0.093103\n",
      "Epoch [109/1000] - Loss: 0.024475 - Valid. (MSE): 0.017547 - Valid. (MAE): 0.092172\n",
      "Epoch [110/1000] - Loss: 0.024684 - Valid. (MSE): 0.017262 - Valid. (MAE): 0.092002\n",
      "Epoch [111/1000] - Loss: 0.023383 - Valid. (MSE): 0.017072 - Valid. (MAE): 0.094085\n",
      "Epoch [111/1000] - Loss: 0.024478 - Valid. (MSE): 0.017475 - Valid. (MAE): 0.091374\n",
      "Epoch [112/1000] - Loss: 0.023661 - Valid. (MSE): 0.017302 - Valid. (MAE): 0.092277\n",
      "Epoch [113/1000] - Loss: 0.022758 - Valid. (MSE): 0.016851 - Valid. (MAE): 0.091657\n",
      "Epoch [113/1000] - Loss: 0.024401 - Valid. (MSE): 0.017587 - Valid. (MAE): 0.091991\n",
      "Epoch [114/1000] - Loss: 0.022632 - Valid. (MSE): 0.017115 - Valid. (MAE): 0.092216\n",
      "Epoch [114/1000] - Loss: 0.021743 - Valid. (MSE): 0.017119 - Valid. (MAE): 0.091027\n",
      "Stopping early at epoch 115. Best validation MSE: 0.016900802639119996 at epoch 83.\n",
      "Seed 44 completed:\n",
      "  - Final epoch: 115\n",
      "  - Best epoch: 83\n",
      "  - Training time: 1268.91s\n",
      "  - Test MSE: 0.016690\n",
      "  - Test MAE: 0.091407\n",
      "  - MPE: 0.034452\n",
      "  - Coverage 95%: 0.9297\n",
      "\n",
      "--- Training with seed 45 (4/10) ---\n",
      "Starting training for seed 45...\n",
      "Epoch [0/1000] - Loss: 0.152846 - Valid. (MSE): 0.077448 - Valid. (MAE): 0.196794\n",
      "Epoch [1/1000] - Loss: 0.121720 - Valid. (MSE): 0.060580 - Valid. (MAE): 0.176104\n",
      "Epoch [1/1000] - Loss: 0.105593 - Valid. (MSE): 0.066858 - Valid. (MAE): 0.181446\n",
      "Epoch [2/1000] - Loss: 0.087830 - Valid. (MSE): 0.053139 - Valid. (MAE): 0.170558\n",
      "Epoch [3/1000] - Loss: 0.080439 - Valid. (MSE): 0.057596 - Valid. (MAE): 0.168877\n",
      "Epoch [3/1000] - Loss: 0.083924 - Valid. (MSE): 0.048870 - Valid. (MAE): 0.163383\n",
      "Epoch [4/1000] - Loss: 0.075181 - Valid. (MSE): 0.051107 - Valid. (MAE): 0.159977\n",
      "Epoch [4/1000] - Loss: 0.078331 - Valid. (MSE): 0.047688 - Valid. (MAE): 0.155033\n",
      "Epoch [5/1000] - Loss: 0.072252 - Valid. (MSE): 0.043682 - Valid. (MAE): 0.151902\n",
      "Epoch [6/1000] - Loss: 0.068390 - Valid. (MSE): 0.043100 - Valid. (MAE): 0.149516\n",
      "Epoch [6/1000] - Loss: 0.072723 - Valid. (MSE): 0.043743 - Valid. (MAE): 0.147190\n",
      "Epoch [7/1000] - Loss: 0.063482 - Valid. (MSE): 0.044438 - Valid. (MAE): 0.146255\n",
      "Epoch [8/1000] - Loss: 0.064094 - Valid. (MSE): 0.044149 - Valid. (MAE): 0.145027\n",
      "Epoch [8/1000] - Loss: 0.061377 - Valid. (MSE): 0.039154 - Valid. (MAE): 0.138941\n",
      "Epoch [9/1000] - Loss: 0.059882 - Valid. (MSE): 0.036617 - Valid. (MAE): 0.137171\n",
      "Epoch [9/1000] - Loss: 0.062881 - Valid. (MSE): 0.035560 - Valid. (MAE): 0.135088\n",
      "Epoch [10/1000] - Loss: 0.057176 - Valid. (MSE): 0.039137 - Valid. (MAE): 0.135569\n",
      "Epoch [11/1000] - Loss: 0.053764 - Valid. (MSE): 0.036350 - Valid. (MAE): 0.131710\n",
      "Epoch [11/1000] - Loss: 0.054243 - Valid. (MSE): 0.033319 - Valid. (MAE): 0.128479\n",
      "Epoch [12/1000] - Loss: 0.052639 - Valid. (MSE): 0.032895 - Valid. (MAE): 0.127799\n",
      "Epoch [13/1000] - Loss: 0.053124 - Valid. (MSE): 0.035336 - Valid. (MAE): 0.127895\n",
      "Epoch [13/1000] - Loss: 0.049208 - Valid. (MSE): 0.039297 - Valid. (MAE): 0.134656\n",
      "Epoch [14/1000] - Loss: 0.054754 - Valid. (MSE): 0.029538 - Valid. (MAE): 0.124851\n",
      "Epoch [14/1000] - Loss: 0.049261 - Valid. (MSE): 0.030023 - Valid. (MAE): 0.123961\n",
      "Epoch [15/1000] - Loss: 0.046354 - Valid. (MSE): 0.032278 - Valid. (MAE): 0.122824\n",
      "Epoch [16/1000] - Loss: 0.047837 - Valid. (MSE): 0.030698 - Valid. (MAE): 0.120792\n",
      "Epoch [16/1000] - Loss: 0.045368 - Valid. (MSE): 0.028701 - Valid. (MAE): 0.118929\n",
      "Epoch [17/1000] - Loss: 0.042604 - Valid. (MSE): 0.027708 - Valid. (MAE): 0.119089\n",
      "Epoch [18/1000] - Loss: 0.049375 - Valid. (MSE): 0.029648 - Valid. (MAE): 0.117960\n",
      "Epoch [18/1000] - Loss: 0.041322 - Valid. (MSE): 0.029972 - Valid. (MAE): 0.119027\n",
      "Epoch [19/1000] - Loss: 0.043325 - Valid. (MSE): 0.026441 - Valid. (MAE): 0.118895\n",
      "Epoch [19/1000] - Loss: 0.039925 - Valid. (MSE): 0.027597 - Valid. (MAE): 0.117055\n",
      "Epoch [20/1000] - Loss: 0.040212 - Valid. (MSE): 0.027213 - Valid. (MAE): 0.115288\n",
      "Epoch [21/1000] - Loss: 0.038077 - Valid. (MSE): 0.025827 - Valid. (MAE): 0.114248\n",
      "Epoch [21/1000] - Loss: 0.038515 - Valid. (MSE): 0.025537 - Valid. (MAE): 0.113522\n",
      "Epoch [22/1000] - Loss: 0.039605 - Valid. (MSE): 0.027541 - Valid. (MAE): 0.114270\n",
      "Epoch [23/1000] - Loss: 0.041410 - Valid. (MSE): 0.027380 - Valid. (MAE): 0.113932\n",
      "Epoch [23/1000] - Loss: 0.039095 - Valid. (MSE): 0.023932 - Valid. (MAE): 0.113129\n",
      "Epoch [24/1000] - Loss: 0.038965 - Valid. (MSE): 0.024808 - Valid. (MAE): 0.111209\n",
      "Epoch [24/1000] - Loss: 0.038882 - Valid. (MSE): 0.025499 - Valid. (MAE): 0.111579\n",
      "Epoch [25/1000] - Loss: 0.040451 - Valid. (MSE): 0.025121 - Valid. (MAE): 0.110132\n",
      "Epoch [26/1000] - Loss: 0.039567 - Valid. (MSE): 0.024644 - Valid. (MAE): 0.108919\n",
      "Epoch [26/1000] - Loss: 0.036794 - Valid. (MSE): 0.023774 - Valid. (MAE): 0.108726\n",
      "Epoch [27/1000] - Loss: 0.036514 - Valid. (MSE): 0.024469 - Valid. (MAE): 0.108402\n",
      "Epoch [28/1000] - Loss: 0.036863 - Valid. (MSE): 0.023665 - Valid. (MAE): 0.109197\n",
      "Epoch [28/1000] - Loss: 0.034420 - Valid. (MSE): 0.023464 - Valid. (MAE): 0.106376\n",
      "Epoch [29/1000] - Loss: 0.032556 - Valid. (MSE): 0.023355 - Valid. (MAE): 0.107168\n",
      "Epoch [29/1000] - Loss: 0.037066 - Valid. (MSE): 0.023792 - Valid. (MAE): 0.107959\n",
      "Epoch [30/1000] - Loss: 0.035803 - Valid. (MSE): 0.023541 - Valid. (MAE): 0.106308\n",
      "Epoch [31/1000] - Loss: 0.037956 - Valid. (MSE): 0.022990 - Valid. (MAE): 0.105238\n",
      "Epoch [31/1000] - Loss: 0.034341 - Valid. (MSE): 0.022833 - Valid. (MAE): 0.107158\n",
      "Epoch [32/1000] - Loss: 0.035274 - Valid. (MSE): 0.023138 - Valid. (MAE): 0.107212\n",
      "Epoch [33/1000] - Loss: 0.034403 - Valid. (MSE): 0.021779 - Valid. (MAE): 0.106016\n",
      "Epoch [33/1000] - Loss: 0.035804 - Valid. (MSE): 0.022149 - Valid. (MAE): 0.105311\n",
      "Epoch [34/1000] - Loss: 0.033961 - Valid. (MSE): 0.023311 - Valid. (MAE): 0.106782\n",
      "Epoch [34/1000] - Loss: 0.035162 - Valid. (MSE): 0.023627 - Valid. (MAE): 0.105227\n",
      "Epoch [35/1000] - Loss: 0.033281 - Valid. (MSE): 0.023874 - Valid. (MAE): 0.106045\n",
      "Epoch [36/1000] - Loss: 0.034968 - Valid. (MSE): 0.021762 - Valid. (MAE): 0.106727\n",
      "Epoch [36/1000] - Loss: 0.031963 - Valid. (MSE): 0.021517 - Valid. (MAE): 0.102905\n",
      "Epoch [37/1000] - Loss: 0.033465 - Valid. (MSE): 0.023310 - Valid. (MAE): 0.105331\n",
      "Epoch [38/1000] - Loss: 0.030527 - Valid. (MSE): 0.022510 - Valid. (MAE): 0.102868\n",
      "Epoch [38/1000] - Loss: 0.034559 - Valid. (MSE): 0.021828 - Valid. (MAE): 0.103934\n",
      "Epoch [39/1000] - Loss: 0.031466 - Valid. (MSE): 0.021368 - Valid. (MAE): 0.103790\n",
      "Epoch [39/1000] - Loss: 0.032752 - Valid. (MSE): 0.022639 - Valid. (MAE): 0.102358\n",
      "Epoch [40/1000] - Loss: 0.032902 - Valid. (MSE): 0.023248 - Valid. (MAE): 0.104273\n",
      "Epoch [41/1000] - Loss: 0.033994 - Valid. (MSE): 0.020932 - Valid. (MAE): 0.104170\n",
      "Epoch [41/1000] - Loss: 0.032614 - Valid. (MSE): 0.021262 - Valid. (MAE): 0.101518\n",
      "Epoch [42/1000] - Loss: 0.033400 - Valid. (MSE): 0.022220 - Valid. (MAE): 0.102721\n",
      "Epoch [43/1000] - Loss: 0.029844 - Valid. (MSE): 0.021018 - Valid. (MAE): 0.101986\n",
      "Epoch [43/1000] - Loss: 0.030535 - Valid. (MSE): 0.020839 - Valid. (MAE): 0.102222\n",
      "Epoch [44/1000] - Loss: 0.031386 - Valid. (MSE): 0.021219 - Valid. (MAE): 0.100579\n",
      "Epoch [44/1000] - Loss: 0.033970 - Valid. (MSE): 0.021794 - Valid. (MAE): 0.101808\n",
      "Epoch [45/1000] - Loss: 0.030376 - Valid. (MSE): 0.020435 - Valid. (MAE): 0.099792\n",
      "Epoch [46/1000] - Loss: 0.031952 - Valid. (MSE): 0.020328 - Valid. (MAE): 0.100362\n",
      "Epoch [46/1000] - Loss: 0.031146 - Valid. (MSE): 0.021172 - Valid. (MAE): 0.100796\n",
      "Epoch [47/1000] - Loss: 0.030504 - Valid. (MSE): 0.022129 - Valid. (MAE): 0.100530\n",
      "Epoch [48/1000] - Loss: 0.029863 - Valid. (MSE): 0.021066 - Valid. (MAE): 0.100419\n",
      "Epoch [48/1000] - Loss: 0.027769 - Valid. (MSE): 0.020227 - Valid. (MAE): 0.098769\n",
      "Epoch [49/1000] - Loss: 0.030421 - Valid. (MSE): 0.020243 - Valid. (MAE): 0.101097\n",
      "Epoch [49/1000] - Loss: 0.033049 - Valid. (MSE): 0.021353 - Valid. (MAE): 0.101720\n",
      "Epoch [50/1000] - Loss: 0.032732 - Valid. (MSE): 0.020924 - Valid. (MAE): 0.099750\n",
      "Epoch [51/1000] - Loss: 0.030082 - Valid. (MSE): 0.020150 - Valid. (MAE): 0.099830\n",
      "Epoch [51/1000] - Loss: 0.032149 - Valid. (MSE): 0.021092 - Valid. (MAE): 0.101119\n",
      "Epoch [52/1000] - Loss: 0.030307 - Valid. (MSE): 0.020144 - Valid. (MAE): 0.098158\n",
      "Epoch [53/1000] - Loss: 0.029267 - Valid. (MSE): 0.020347 - Valid. (MAE): 0.105226\n",
      "Epoch [53/1000] - Loss: 0.029304 - Valid. (MSE): 0.021019 - Valid. (MAE): 0.099416\n",
      "Epoch [54/1000] - Loss: 0.027928 - Valid. (MSE): 0.020252 - Valid. (MAE): 0.098438\n",
      "Epoch [54/1000] - Loss: 0.029283 - Valid. (MSE): 0.020362 - Valid. (MAE): 0.100251\n",
      "Epoch [55/1000] - Loss: 0.031710 - Valid. (MSE): 0.020387 - Valid. (MAE): 0.102043\n",
      "Epoch [56/1000] - Loss: 0.028679 - Valid. (MSE): 0.021410 - Valid. (MAE): 0.099394\n",
      "Epoch [56/1000] - Loss: 0.028725 - Valid. (MSE): 0.020213 - Valid. (MAE): 0.098889\n",
      "Epoch [57/1000] - Loss: 0.027832 - Valid. (MSE): 0.019683 - Valid. (MAE): 0.100213\n",
      "Epoch [58/1000] - Loss: 0.027000 - Valid. (MSE): 0.019606 - Valid. (MAE): 0.099549\n",
      "Epoch [58/1000] - Loss: 0.029197 - Valid. (MSE): 0.020196 - Valid. (MAE): 0.097995\n",
      "Epoch [59/1000] - Loss: 0.028634 - Valid. (MSE): 0.020236 - Valid. (MAE): 0.099603\n",
      "Epoch [59/1000] - Loss: 0.028115 - Valid. (MSE): 0.019537 - Valid. (MAE): 0.101295\n",
      "Epoch [60/1000] - Loss: 0.027653 - Valid. (MSE): 0.020654 - Valid. (MAE): 0.098503\n",
      "Epoch [61/1000] - Loss: 0.029181 - Valid. (MSE): 0.020111 - Valid. (MAE): 0.098336\n",
      "Epoch [61/1000] - Loss: 0.029502 - Valid. (MSE): 0.019237 - Valid. (MAE): 0.100401\n",
      "Epoch [62/1000] - Loss: 0.028318 - Valid. (MSE): 0.020557 - Valid. (MAE): 0.099327\n",
      "Epoch [63/1000] - Loss: 0.029261 - Valid. (MSE): 0.020453 - Valid. (MAE): 0.098179\n",
      "Epoch [63/1000] - Loss: 0.028703 - Valid. (MSE): 0.019728 - Valid. (MAE): 0.100685\n",
      "Epoch [64/1000] - Loss: 0.027698 - Valid. (MSE): 0.020492 - Valid. (MAE): 0.097209\n",
      "Epoch [64/1000] - Loss: 0.027231 - Valid. (MSE): 0.020219 - Valid. (MAE): 0.098383\n",
      "Epoch [65/1000] - Loss: 0.027192 - Valid. (MSE): 0.019755 - Valid. (MAE): 0.100206\n",
      "Epoch [66/1000] - Loss: 0.028893 - Valid. (MSE): 0.019881 - Valid. (MAE): 0.097334\n",
      "Epoch [66/1000] - Loss: 0.027082 - Valid. (MSE): 0.020340 - Valid. (MAE): 0.100810\n",
      "Epoch [67/1000] - Loss: 0.024555 - Valid. (MSE): 0.019148 - Valid. (MAE): 0.097533\n",
      "Epoch [68/1000] - Loss: 0.025800 - Valid. (MSE): 0.019627 - Valid. (MAE): 0.099172\n",
      "Epoch [68/1000] - Loss: 0.026232 - Valid. (MSE): 0.019428 - Valid. (MAE): 0.097293\n",
      "Epoch [69/1000] - Loss: 0.027537 - Valid. (MSE): 0.019995 - Valid. (MAE): 0.098384\n",
      "Epoch [69/1000] - Loss: 0.026830 - Valid. (MSE): 0.021188 - Valid. (MAE): 0.098881\n",
      "Epoch [70/1000] - Loss: 0.027899 - Valid. (MSE): 0.019236 - Valid. (MAE): 0.102007\n",
      "Epoch [71/1000] - Loss: 0.027425 - Valid. (MSE): 0.019702 - Valid. (MAE): 0.096449\n",
      "Epoch [71/1000] - Loss: 0.025362 - Valid. (MSE): 0.019875 - Valid. (MAE): 0.097671\n",
      "Epoch [72/1000] - Loss: 0.028692 - Valid. (MSE): 0.019312 - Valid. (MAE): 0.098561\n",
      "Epoch [73/1000] - Loss: 0.025195 - Valid. (MSE): 0.020019 - Valid. (MAE): 0.098221\n",
      "Epoch [73/1000] - Loss: 0.026702 - Valid. (MSE): 0.019311 - Valid. (MAE): 0.097045\n",
      "Epoch [74/1000] - Loss: 0.028044 - Valid. (MSE): 0.019322 - Valid. (MAE): 0.097518\n",
      "Epoch [74/1000] - Loss: 0.025004 - Valid. (MSE): 0.020489 - Valid. (MAE): 0.100185\n",
      "Epoch [75/1000] - Loss: 0.027449 - Valid. (MSE): 0.019548 - Valid. (MAE): 0.097092\n",
      "Epoch [76/1000] - Loss: 0.027004 - Valid. (MSE): 0.019222 - Valid. (MAE): 0.097326\n",
      "Epoch [76/1000] - Loss: 0.029684 - Valid. (MSE): 0.019581 - Valid. (MAE): 0.099287\n",
      "Epoch [77/1000] - Loss: 0.026898 - Valid. (MSE): 0.019161 - Valid. (MAE): 0.096574\n",
      "Epoch [78/1000] - Loss: 0.025844 - Valid. (MSE): 0.019845 - Valid. (MAE): 0.101068\n",
      "Epoch [78/1000] - Loss: 0.025928 - Valid. (MSE): 0.019094 - Valid. (MAE): 0.095769\n",
      "Epoch [79/1000] - Loss: 0.024920 - Valid. (MSE): 0.019036 - Valid. (MAE): 0.096942\n",
      "Epoch [79/1000] - Loss: 0.024930 - Valid. (MSE): 0.019108 - Valid. (MAE): 0.098274\n",
      "Epoch [80/1000] - Loss: 0.025561 - Valid. (MSE): 0.018679 - Valid. (MAE): 0.097420\n",
      "Epoch [81/1000] - Loss: 0.025466 - Valid. (MSE): 0.019398 - Valid. (MAE): 0.098161\n",
      "Epoch [81/1000] - Loss: 0.024578 - Valid. (MSE): 0.019555 - Valid. (MAE): 0.096130\n",
      "Epoch [82/1000] - Loss: 0.025025 - Valid. (MSE): 0.018782 - Valid. (MAE): 0.097897\n",
      "Epoch [83/1000] - Loss: 0.025084 - Valid. (MSE): 0.019416 - Valid. (MAE): 0.098650\n",
      "Epoch [83/1000] - Loss: 0.026082 - Valid. (MSE): 0.018823 - Valid. (MAE): 0.095459\n",
      "Epoch [84/1000] - Loss: 0.025775 - Valid. (MSE): 0.018882 - Valid. (MAE): 0.098325\n",
      "Epoch [84/1000] - Loss: 0.025040 - Valid. (MSE): 0.019414 - Valid. (MAE): 0.097473\n",
      "Epoch [85/1000] - Loss: 0.025051 - Valid. (MSE): 0.019447 - Valid. (MAE): 0.097338\n",
      "Epoch [86/1000] - Loss: 0.025327 - Valid. (MSE): 0.019178 - Valid. (MAE): 0.096822\n",
      "Epoch [86/1000] - Loss: 0.024271 - Valid. (MSE): 0.018560 - Valid. (MAE): 0.097924\n",
      "Epoch [87/1000] - Loss: 0.025666 - Valid. (MSE): 0.019621 - Valid. (MAE): 0.099253\n",
      "Epoch [88/1000] - Loss: 0.024364 - Valid. (MSE): 0.018413 - Valid. (MAE): 0.097061\n",
      "Epoch [88/1000] - Loss: 0.025839 - Valid. (MSE): 0.018909 - Valid. (MAE): 0.098889\n",
      "Epoch [89/1000] - Loss: 0.022988 - Valid. (MSE): 0.019031 - Valid. (MAE): 0.095252\n",
      "Epoch [89/1000] - Loss: 0.026518 - Valid. (MSE): 0.019104 - Valid. (MAE): 0.099890\n",
      "Epoch [90/1000] - Loss: 0.026462 - Valid. (MSE): 0.019646 - Valid. (MAE): 0.097238\n",
      "Epoch [91/1000] - Loss: 0.023902 - Valid. (MSE): 0.018677 - Valid. (MAE): 0.098387\n",
      "Epoch [91/1000] - Loss: 0.023716 - Valid. (MSE): 0.019014 - Valid. (MAE): 0.096395\n",
      "Epoch [92/1000] - Loss: 0.024485 - Valid. (MSE): 0.018896 - Valid. (MAE): 0.096014\n",
      "Epoch [93/1000] - Loss: 0.023997 - Valid. (MSE): 0.019047 - Valid. (MAE): 0.097228\n",
      "Epoch [93/1000] - Loss: 0.024916 - Valid. (MSE): 0.018463 - Valid. (MAE): 0.097165\n",
      "Epoch [94/1000] - Loss: 0.025172 - Valid. (MSE): 0.019719 - Valid. (MAE): 0.100324\n",
      "Epoch [94/1000] - Loss: 0.024590 - Valid. (MSE): 0.018360 - Valid. (MAE): 0.095756\n",
      "Epoch [95/1000] - Loss: 0.024097 - Valid. (MSE): 0.018940 - Valid. (MAE): 0.097888\n",
      "Epoch [96/1000] - Loss: 0.025633 - Valid. (MSE): 0.018742 - Valid. (MAE): 0.097138\n",
      "Epoch [96/1000] - Loss: 0.024441 - Valid. (MSE): 0.018995 - Valid. (MAE): 0.097335\n",
      "Epoch [97/1000] - Loss: 0.025682 - Valid. (MSE): 0.018942 - Valid. (MAE): 0.096295\n",
      "Epoch [98/1000] - Loss: 0.027078 - Valid. (MSE): 0.018538 - Valid. (MAE): 0.096376\n",
      "Epoch [98/1000] - Loss: 0.027589 - Valid. (MSE): 0.018574 - Valid. (MAE): 0.097841\n",
      "Epoch [99/1000] - Loss: 0.025019 - Valid. (MSE): 0.018467 - Valid. (MAE): 0.094470\n",
      "Epoch [99/1000] - Loss: 0.024609 - Valid. (MSE): 0.019074 - Valid. (MAE): 0.098022\n",
      "Epoch [100/1000] - Loss: 0.025531 - Valid. (MSE): 0.018310 - Valid. (MAE): 0.095838\n",
      "Epoch [101/1000] - Loss: 0.024696 - Valid. (MSE): 0.018459 - Valid. (MAE): 0.096386\n",
      "Epoch [101/1000] - Loss: 0.025368 - Valid. (MSE): 0.018837 - Valid. (MAE): 0.096224\n",
      "Epoch [102/1000] - Loss: 0.024555 - Valid. (MSE): 0.018821 - Valid. (MAE): 0.095830\n",
      "Epoch [103/1000] - Loss: 0.025386 - Valid. (MSE): 0.018495 - Valid. (MAE): 0.099152\n",
      "Epoch [103/1000] - Loss: 0.025300 - Valid. (MSE): 0.018211 - Valid. (MAE): 0.094618\n",
      "Epoch [104/1000] - Loss: 0.026120 - Valid. (MSE): 0.019337 - Valid. (MAE): 0.095569\n",
      "Epoch [104/1000] - Loss: 0.026314 - Valid. (MSE): 0.018386 - Valid. (MAE): 0.096491\n",
      "Epoch [105/1000] - Loss: 0.024436 - Valid. (MSE): 0.018359 - Valid. (MAE): 0.098717\n",
      "Epoch [106/1000] - Loss: 0.023607 - Valid. (MSE): 0.018728 - Valid. (MAE): 0.095668\n",
      "Epoch [106/1000] - Loss: 0.024731 - Valid. (MSE): 0.018177 - Valid. (MAE): 0.095417\n",
      "Epoch [107/1000] - Loss: 0.024937 - Valid. (MSE): 0.018474 - Valid. (MAE): 0.096353\n",
      "Epoch [108/1000] - Loss: 0.024533 - Valid. (MSE): 0.018791 - Valid. (MAE): 0.095252\n",
      "Epoch [108/1000] - Loss: 0.024408 - Valid. (MSE): 0.018818 - Valid. (MAE): 0.099721\n",
      "Epoch [109/1000] - Loss: 0.023210 - Valid. (MSE): 0.018337 - Valid. (MAE): 0.094282\n",
      "Epoch [109/1000] - Loss: 0.023475 - Valid. (MSE): 0.018726 - Valid. (MAE): 0.099606\n",
      "Epoch [110/1000] - Loss: 0.025883 - Valid. (MSE): 0.018410 - Valid. (MAE): 0.096304\n",
      "Epoch [111/1000] - Loss: 0.024636 - Valid. (MSE): 0.018521 - Valid. (MAE): 0.095572\n",
      "Epoch [111/1000] - Loss: 0.025241 - Valid. (MSE): 0.018732 - Valid. (MAE): 0.097566\n",
      "Epoch [112/1000] - Loss: 0.026082 - Valid. (MSE): 0.018018 - Valid. (MAE): 0.095191\n",
      "Epoch [113/1000] - Loss: 0.025301 - Valid. (MSE): 0.018514 - Valid. (MAE): 0.097259\n",
      "Epoch [113/1000] - Loss: 0.023185 - Valid. (MSE): 0.018478 - Valid. (MAE): 0.095401\n",
      "Epoch [114/1000] - Loss: 0.024086 - Valid. (MSE): 0.018527 - Valid. (MAE): 0.097078\n",
      "Epoch [114/1000] - Loss: 0.024378 - Valid. (MSE): 0.018067 - Valid. (MAE): 0.095241\n",
      "Epoch [115/1000] - Loss: 0.023222 - Valid. (MSE): 0.018322 - Valid. (MAE): 0.096187\n",
      "Epoch [116/1000] - Loss: 0.024093 - Valid. (MSE): 0.018826 - Valid. (MAE): 0.095334\n",
      "Epoch [116/1000] - Loss: 0.023440 - Valid. (MSE): 0.018254 - Valid. (MAE): 0.098291\n",
      "Epoch [117/1000] - Loss: 0.023459 - Valid. (MSE): 0.018010 - Valid. (MAE): 0.094942\n",
      "Epoch [118/1000] - Loss: 0.023699 - Valid. (MSE): 0.018662 - Valid. (MAE): 0.096398\n",
      "Epoch [118/1000] - Loss: 0.023223 - Valid. (MSE): 0.018192 - Valid. (MAE): 0.096056\n",
      "Epoch [119/1000] - Loss: 0.022893 - Valid. (MSE): 0.018189 - Valid. (MAE): 0.096382\n",
      "Epoch [119/1000] - Loss: 0.023545 - Valid. (MSE): 0.018470 - Valid. (MAE): 0.095785\n",
      "Epoch [120/1000] - Loss: 0.024854 - Valid. (MSE): 0.017881 - Valid. (MAE): 0.093273\n",
      "Epoch [121/1000] - Loss: 0.024355 - Valid. (MSE): 0.018375 - Valid. (MAE): 0.098227\n",
      "Epoch [121/1000] - Loss: 0.023306 - Valid. (MSE): 0.018060 - Valid. (MAE): 0.093713\n",
      "Epoch [122/1000] - Loss: 0.022586 - Valid. (MSE): 0.018313 - Valid. (MAE): 0.096727\n",
      "Epoch [123/1000] - Loss: 0.024581 - Valid. (MSE): 0.018035 - Valid. (MAE): 0.096261\n",
      "Epoch [123/1000] - Loss: 0.023367 - Valid. (MSE): 0.018800 - Valid. (MAE): 0.094147\n",
      "Epoch [124/1000] - Loss: 0.024950 - Valid. (MSE): 0.018767 - Valid. (MAE): 0.096793\n",
      "Epoch [124/1000] - Loss: 0.023304 - Valid. (MSE): 0.018105 - Valid. (MAE): 0.098858\n",
      "Epoch [125/1000] - Loss: 0.023786 - Valid. (MSE): 0.018157 - Valid. (MAE): 0.094484\n",
      "Epoch [126/1000] - Loss: 0.023064 - Valid. (MSE): 0.018629 - Valid. (MAE): 0.094827\n",
      "Epoch [126/1000] - Loss: 0.026090 - Valid. (MSE): 0.018031 - Valid. (MAE): 0.094650\n",
      "Epoch [127/1000] - Loss: 0.024485 - Valid. (MSE): 0.018510 - Valid. (MAE): 0.098651\n",
      "Epoch [128/1000] - Loss: 0.027157 - Valid. (MSE): 0.018008 - Valid. (MAE): 0.095354\n",
      "Epoch [128/1000] - Loss: 0.022239 - Valid. (MSE): 0.018628 - Valid. (MAE): 0.094287\n",
      "Epoch [129/1000] - Loss: 0.024018 - Valid. (MSE): 0.018048 - Valid. (MAE): 0.095644\n",
      "Epoch [129/1000] - Loss: 0.023734 - Valid. (MSE): 0.018155 - Valid. (MAE): 0.097438\n",
      "Epoch [130/1000] - Loss: 0.023087 - Valid. (MSE): 0.018300 - Valid. (MAE): 0.094371\n",
      "Epoch [131/1000] - Loss: 0.021761 - Valid. (MSE): 0.017935 - Valid. (MAE): 0.094975\n",
      "Epoch [131/1000] - Loss: 0.021613 - Valid. (MSE): 0.017992 - Valid. (MAE): 0.094351\n",
      "Epoch [132/1000] - Loss: 0.022221 - Valid. (MSE): 0.018177 - Valid. (MAE): 0.096583\n",
      "Epoch [133/1000] - Loss: 0.022658 - Valid. (MSE): 0.018039 - Valid. (MAE): 0.095313\n",
      "Epoch [133/1000] - Loss: 0.025220 - Valid. (MSE): 0.018183 - Valid. (MAE): 0.095640\n",
      "Epoch [134/1000] - Loss: 0.021892 - Valid. (MSE): 0.018507 - Valid. (MAE): 0.098058\n",
      "Epoch [134/1000] - Loss: 0.022513 - Valid. (MSE): 0.018007 - Valid. (MAE): 0.095969\n",
      "Epoch [135/1000] - Loss: 0.024961 - Valid. (MSE): 0.018336 - Valid. (MAE): 0.095097\n",
      "Epoch [136/1000] - Loss: 0.021601 - Valid. (MSE): 0.017972 - Valid. (MAE): 0.096288\n",
      "Epoch [136/1000] - Loss: 0.023097 - Valid. (MSE): 0.018227 - Valid. (MAE): 0.098447\n",
      "Epoch [137/1000] - Loss: 0.023368 - Valid. (MSE): 0.018161 - Valid. (MAE): 0.094813\n",
      "Epoch [138/1000] - Loss: 0.023169 - Valid. (MSE): 0.018155 - Valid. (MAE): 0.095819\n",
      "Epoch [138/1000] - Loss: 0.024223 - Valid. (MSE): 0.018192 - Valid. (MAE): 0.098300\n",
      "Epoch [139/1000] - Loss: 0.022820 - Valid. (MSE): 0.017916 - Valid. (MAE): 0.094430\n",
      "Epoch [139/1000] - Loss: 0.023852 - Valid. (MSE): 0.018165 - Valid. (MAE): 0.094505\n",
      "Epoch [140/1000] - Loss: 0.025287 - Valid. (MSE): 0.018457 - Valid. (MAE): 0.099351\n",
      "Epoch [141/1000] - Loss: 0.025535 - Valid. (MSE): 0.018001 - Valid. (MAE): 0.094450\n",
      "Epoch [141/1000] - Loss: 0.022814 - Valid. (MSE): 0.018179 - Valid. (MAE): 0.094978\n",
      "Epoch [142/1000] - Loss: 0.022965 - Valid. (MSE): 0.018154 - Valid. (MAE): 0.098524\n",
      "Epoch [143/1000] - Loss: 0.023969 - Valid. (MSE): 0.018069 - Valid. (MAE): 0.093940\n",
      "Epoch [143/1000] - Loss: 0.022179 - Valid. (MSE): 0.017901 - Valid. (MAE): 0.094702\n",
      "Stopping early at epoch 144. Best validation MSE: 0.018018217245568426 at epoch 112.\n",
      "Seed 45 completed:\n",
      "  - Final epoch: 144\n",
      "  - Best epoch: 112\n",
      "  - Training time: 1588.35s\n",
      "  - Test MSE: 0.017126\n",
      "  - Test MAE: 0.095175\n",
      "  - MPE: 0.035174\n",
      "  - Coverage 95%: 0.9399\n",
      "\n",
      "--- Training with seed 46 (5/10) ---\n",
      "Starting training for seed 46...\n",
      "Epoch [0/1000] - Loss: 0.107455 - Valid. (MSE): 0.055827 - Valid. (MAE): 0.184391\n",
      "Epoch [1/1000] - Loss: 0.108693 - Valid. (MSE): 0.055383 - Valid. (MAE): 0.192742\n",
      "Epoch [1/1000] - Loss: 0.091622 - Valid. (MSE): 0.059037 - Valid. (MAE): 0.176539\n",
      "Epoch [2/1000] - Loss: 0.080125 - Valid. (MSE): 0.053214 - Valid. (MAE): 0.174228\n",
      "Epoch [3/1000] - Loss: 0.077317 - Valid. (MSE): 0.050612 - Valid. (MAE): 0.174256\n",
      "Epoch [3/1000] - Loss: 0.077286 - Valid. (MSE): 0.049007 - Valid. (MAE): 0.171313\n",
      "Epoch [4/1000] - Loss: 0.070066 - Valid. (MSE): 0.047067 - Valid. (MAE): 0.169472\n",
      "Epoch [4/1000] - Loss: 0.074478 - Valid. (MSE): 0.046024 - Valid. (MAE): 0.160406\n",
      "Epoch [5/1000] - Loss: 0.068722 - Valid. (MSE): 0.043736 - Valid. (MAE): 0.157305\n",
      "Epoch [6/1000] - Loss: 0.066403 - Valid. (MSE): 0.042133 - Valid. (MAE): 0.154106\n",
      "Epoch [6/1000] - Loss: 0.059084 - Valid. (MSE): 0.041188 - Valid. (MAE): 0.150542\n",
      "Epoch [7/1000] - Loss: 0.060066 - Valid. (MSE): 0.039378 - Valid. (MAE): 0.150494\n",
      "Epoch [8/1000] - Loss: 0.056885 - Valid. (MSE): 0.038396 - Valid. (MAE): 0.150003\n",
      "Epoch [8/1000] - Loss: 0.055580 - Valid. (MSE): 0.039025 - Valid. (MAE): 0.144478\n",
      "Epoch [9/1000] - Loss: 0.058189 - Valid. (MSE): 0.036499 - Valid. (MAE): 0.147341\n",
      "Epoch [9/1000] - Loss: 0.059272 - Valid. (MSE): 0.035878 - Valid. (MAE): 0.139156\n",
      "Epoch [10/1000] - Loss: 0.053683 - Valid. (MSE): 0.034647 - Valid. (MAE): 0.136519\n",
      "Epoch [11/1000] - Loss: 0.051515 - Valid. (MSE): 0.033165 - Valid. (MAE): 0.136260\n",
      "Epoch [11/1000] - Loss: 0.046868 - Valid. (MSE): 0.033305 - Valid. (MAE): 0.132879\n",
      "Epoch [12/1000] - Loss: 0.048146 - Valid. (MSE): 0.031888 - Valid. (MAE): 0.131117\n",
      "Epoch [13/1000] - Loss: 0.045737 - Valid. (MSE): 0.030468 - Valid. (MAE): 0.132359\n",
      "Epoch [13/1000] - Loss: 0.043865 - Valid. (MSE): 0.030040 - Valid. (MAE): 0.127504\n",
      "Epoch [14/1000] - Loss: 0.045129 - Valid. (MSE): 0.029690 - Valid. (MAE): 0.125794\n",
      "Epoch [14/1000] - Loss: 0.048473 - Valid. (MSE): 0.028625 - Valid. (MAE): 0.125148\n",
      "Epoch [15/1000] - Loss: 0.045441 - Valid. (MSE): 0.028288 - Valid. (MAE): 0.121824\n",
      "Epoch [16/1000] - Loss: 0.038880 - Valid. (MSE): 0.028742 - Valid. (MAE): 0.120717\n",
      "Epoch [16/1000] - Loss: 0.045514 - Valid. (MSE): 0.026926 - Valid. (MAE): 0.119933\n",
      "Epoch [17/1000] - Loss: 0.044134 - Valid. (MSE): 0.026441 - Valid. (MAE): 0.120487\n",
      "Epoch [18/1000] - Loss: 0.041357 - Valid. (MSE): 0.027307 - Valid. (MAE): 0.118844\n",
      "Epoch [18/1000] - Loss: 0.037350 - Valid. (MSE): 0.027427 - Valid. (MAE): 0.117510\n",
      "Epoch [19/1000] - Loss: 0.041709 - Valid. (MSE): 0.025143 - Valid. (MAE): 0.117091\n",
      "Epoch [19/1000] - Loss: 0.039642 - Valid. (MSE): 0.025154 - Valid. (MAE): 0.114240\n",
      "Epoch [20/1000] - Loss: 0.037451 - Valid. (MSE): 0.024189 - Valid. (MAE): 0.114025\n",
      "Epoch [21/1000] - Loss: 0.040760 - Valid. (MSE): 0.023951 - Valid. (MAE): 0.113691\n",
      "Epoch [21/1000] - Loss: 0.038947 - Valid. (MSE): 0.025307 - Valid. (MAE): 0.111407\n",
      "Epoch [22/1000] - Loss: 0.038301 - Valid. (MSE): 0.023654 - Valid. (MAE): 0.113801\n",
      "Epoch [23/1000] - Loss: 0.036710 - Valid. (MSE): 0.023723 - Valid. (MAE): 0.109885\n",
      "Epoch [23/1000] - Loss: 0.039302 - Valid. (MSE): 0.022996 - Valid. (MAE): 0.110695\n",
      "Epoch [24/1000] - Loss: 0.038192 - Valid. (MSE): 0.023352 - Valid. (MAE): 0.109578\n",
      "Epoch [24/1000] - Loss: 0.035632 - Valid. (MSE): 0.024833 - Valid. (MAE): 0.108533\n",
      "Epoch [25/1000] - Loss: 0.035197 - Valid. (MSE): 0.022326 - Valid. (MAE): 0.111369\n",
      "Epoch [26/1000] - Loss: 0.034474 - Valid. (MSE): 0.022511 - Valid. (MAE): 0.111496\n",
      "Epoch [26/1000] - Loss: 0.034732 - Valid. (MSE): 0.024251 - Valid. (MAE): 0.107773\n",
      "Epoch [27/1000] - Loss: 0.035194 - Valid. (MSE): 0.022009 - Valid. (MAE): 0.108213\n",
      "Epoch [28/1000] - Loss: 0.033309 - Valid. (MSE): 0.021778 - Valid. (MAE): 0.107601\n",
      "Epoch [28/1000] - Loss: 0.035707 - Valid. (MSE): 0.022375 - Valid. (MAE): 0.104944\n",
      "Epoch [29/1000] - Loss: 0.034721 - Valid. (MSE): 0.021524 - Valid. (MAE): 0.105605\n",
      "Epoch [29/1000] - Loss: 0.031483 - Valid. (MSE): 0.021824 - Valid. (MAE): 0.104060\n",
      "Epoch [30/1000] - Loss: 0.035369 - Valid. (MSE): 0.021490 - Valid. (MAE): 0.105225\n",
      "Epoch [31/1000] - Loss: 0.034702 - Valid. (MSE): 0.021558 - Valid. (MAE): 0.103133\n",
      "Epoch [31/1000] - Loss: 0.032664 - Valid. (MSE): 0.020758 - Valid. (MAE): 0.104830\n",
      "Epoch [32/1000] - Loss: 0.033187 - Valid. (MSE): 0.020754 - Valid. (MAE): 0.102881\n",
      "Epoch [33/1000] - Loss: 0.030939 - Valid. (MSE): 0.020630 - Valid. (MAE): 0.104052\n",
      "Epoch [33/1000] - Loss: 0.029774 - Valid. (MSE): 0.020964 - Valid. (MAE): 0.103775\n",
      "Epoch [34/1000] - Loss: 0.028535 - Valid. (MSE): 0.020884 - Valid. (MAE): 0.102014\n",
      "Epoch [34/1000] - Loss: 0.033018 - Valid. (MSE): 0.020085 - Valid. (MAE): 0.103622\n",
      "Epoch [35/1000] - Loss: 0.030989 - Valid. (MSE): 0.020400 - Valid. (MAE): 0.101914\n",
      "Epoch [36/1000] - Loss: 0.029478 - Valid. (MSE): 0.020745 - Valid. (MAE): 0.102152\n",
      "Epoch [36/1000] - Loss: 0.031698 - Valid. (MSE): 0.020454 - Valid. (MAE): 0.103188\n",
      "Epoch [37/1000] - Loss: 0.030632 - Valid. (MSE): 0.020182 - Valid. (MAE): 0.100456\n",
      "Epoch [38/1000] - Loss: 0.032182 - Valid. (MSE): 0.019874 - Valid. (MAE): 0.102523\n",
      "Epoch [38/1000] - Loss: 0.029251 - Valid. (MSE): 0.020450 - Valid. (MAE): 0.100219\n",
      "Epoch [39/1000] - Loss: 0.028690 - Valid. (MSE): 0.020059 - Valid. (MAE): 0.100117\n",
      "Epoch [39/1000] - Loss: 0.030535 - Valid. (MSE): 0.019486 - Valid. (MAE): 0.099902\n",
      "Epoch [40/1000] - Loss: 0.026611 - Valid. (MSE): 0.019592 - Valid. (MAE): 0.099984\n",
      "Epoch [41/1000] - Loss: 0.029658 - Valid. (MSE): 0.019204 - Valid. (MAE): 0.099247\n",
      "Epoch [41/1000] - Loss: 0.029661 - Valid. (MSE): 0.019639 - Valid. (MAE): 0.101494\n",
      "Epoch [42/1000] - Loss: 0.030129 - Valid. (MSE): 0.019468 - Valid. (MAE): 0.100957\n",
      "Epoch [43/1000] - Loss: 0.030980 - Valid. (MSE): 0.020058 - Valid. (MAE): 0.099131\n",
      "Epoch [43/1000] - Loss: 0.028876 - Valid. (MSE): 0.019451 - Valid. (MAE): 0.099257\n",
      "Epoch [44/1000] - Loss: 0.028767 - Valid. (MSE): 0.019286 - Valid. (MAE): 0.102073\n",
      "Epoch [44/1000] - Loss: 0.028253 - Valid. (MSE): 0.019568 - Valid. (MAE): 0.098910\n",
      "Epoch [45/1000] - Loss: 0.029136 - Valid. (MSE): 0.019213 - Valid. (MAE): 0.100390\n",
      "Epoch [46/1000] - Loss: 0.029092 - Valid. (MSE): 0.020011 - Valid. (MAE): 0.098731\n",
      "Epoch [46/1000] - Loss: 0.027492 - Valid. (MSE): 0.018987 - Valid. (MAE): 0.099557\n",
      "Epoch [47/1000] - Loss: 0.027998 - Valid. (MSE): 0.018844 - Valid. (MAE): 0.099784\n",
      "Epoch [48/1000] - Loss: 0.027983 - Valid. (MSE): 0.019613 - Valid. (MAE): 0.098847\n",
      "Epoch [48/1000] - Loss: 0.028754 - Valid. (MSE): 0.018822 - Valid. (MAE): 0.097148\n",
      "Epoch [49/1000] - Loss: 0.028873 - Valid. (MSE): 0.018567 - Valid. (MAE): 0.098279\n",
      "Epoch [49/1000] - Loss: 0.027993 - Valid. (MSE): 0.018711 - Valid. (MAE): 0.098426\n",
      "Epoch [50/1000] - Loss: 0.027784 - Valid. (MSE): 0.018725 - Valid. (MAE): 0.097059\n",
      "Epoch [51/1000] - Loss: 0.027798 - Valid. (MSE): 0.018901 - Valid. (MAE): 0.097132\n",
      "Epoch [51/1000] - Loss: 0.028051 - Valid. (MSE): 0.018820 - Valid. (MAE): 0.098265\n",
      "Epoch [52/1000] - Loss: 0.028036 - Valid. (MSE): 0.018513 - Valid. (MAE): 0.098466\n",
      "Epoch [53/1000] - Loss: 0.027932 - Valid. (MSE): 0.018872 - Valid. (MAE): 0.097087\n",
      "Epoch [53/1000] - Loss: 0.027095 - Valid. (MSE): 0.018751 - Valid. (MAE): 0.097452\n",
      "Epoch [54/1000] - Loss: 0.027868 - Valid. (MSE): 0.018538 - Valid. (MAE): 0.097544\n",
      "Epoch [54/1000] - Loss: 0.026400 - Valid. (MSE): 0.018348 - Valid. (MAE): 0.096709\n",
      "Epoch [55/1000] - Loss: 0.026082 - Valid. (MSE): 0.018309 - Valid. (MAE): 0.099153\n",
      "Epoch [56/1000] - Loss: 0.023088 - Valid. (MSE): 0.018531 - Valid. (MAE): 0.095580\n",
      "Epoch [56/1000] - Loss: 0.028124 - Valid. (MSE): 0.018033 - Valid. (MAE): 0.097431\n",
      "Epoch [57/1000] - Loss: 0.025229 - Valid. (MSE): 0.018234 - Valid. (MAE): 0.098541\n",
      "Epoch [58/1000] - Loss: 0.027223 - Valid. (MSE): 0.018733 - Valid. (MAE): 0.095461\n",
      "Epoch [58/1000] - Loss: 0.025277 - Valid. (MSE): 0.018117 - Valid. (MAE): 0.097632\n",
      "Epoch [59/1000] - Loss: 0.025152 - Valid. (MSE): 0.018001 - Valid. (MAE): 0.099060\n",
      "Epoch [59/1000] - Loss: 0.025715 - Valid. (MSE): 0.018857 - Valid. (MAE): 0.095744\n",
      "Epoch [60/1000] - Loss: 0.027422 - Valid. (MSE): 0.017927 - Valid. (MAE): 0.097326\n",
      "Epoch [61/1000] - Loss: 0.025146 - Valid. (MSE): 0.017962 - Valid. (MAE): 0.095840\n",
      "Epoch [61/1000] - Loss: 0.029139 - Valid. (MSE): 0.019192 - Valid. (MAE): 0.098081\n",
      "Epoch [62/1000] - Loss: 0.027931 - Valid. (MSE): 0.017957 - Valid. (MAE): 0.095909\n",
      "Epoch [63/1000] - Loss: 0.028263 - Valid. (MSE): 0.018122 - Valid. (MAE): 0.096712\n",
      "Epoch [63/1000] - Loss: 0.024781 - Valid. (MSE): 0.018456 - Valid. (MAE): 0.097525\n",
      "Epoch [64/1000] - Loss: 0.029012 - Valid. (MSE): 0.017766 - Valid. (MAE): 0.095628\n",
      "Epoch [64/1000] - Loss: 0.025282 - Valid. (MSE): 0.017724 - Valid. (MAE): 0.095398\n",
      "Epoch [65/1000] - Loss: 0.026749 - Valid. (MSE): 0.018137 - Valid. (MAE): 0.096689\n",
      "Epoch [66/1000] - Loss: 0.026199 - Valid. (MSE): 0.017997 - Valid. (MAE): 0.095428\n",
      "Epoch [66/1000] - Loss: 0.026295 - Valid. (MSE): 0.017918 - Valid. (MAE): 0.097512\n",
      "Epoch [67/1000] - Loss: 0.026533 - Valid. (MSE): 0.018049 - Valid. (MAE): 0.095409\n",
      "Epoch [68/1000] - Loss: 0.025892 - Valid. (MSE): 0.017815 - Valid. (MAE): 0.095944\n",
      "Epoch [68/1000] - Loss: 0.022963 - Valid. (MSE): 0.018046 - Valid. (MAE): 0.095627\n",
      "Epoch [69/1000] - Loss: 0.024207 - Valid. (MSE): 0.017813 - Valid. (MAE): 0.095068\n",
      "Epoch [69/1000] - Loss: 0.025712 - Valid. (MSE): 0.017962 - Valid. (MAE): 0.097967\n",
      "Epoch [70/1000] - Loss: 0.023257 - Valid. (MSE): 0.018148 - Valid. (MAE): 0.094498\n",
      "Epoch [71/1000] - Loss: 0.023924 - Valid. (MSE): 0.018269 - Valid. (MAE): 0.098341\n",
      "Epoch [71/1000] - Loss: 0.026216 - Valid. (MSE): 0.017831 - Valid. (MAE): 0.096152\n",
      "Epoch [72/1000] - Loss: 0.025506 - Valid. (MSE): 0.017994 - Valid. (MAE): 0.094663\n",
      "Epoch [73/1000] - Loss: 0.023756 - Valid. (MSE): 0.018152 - Valid. (MAE): 0.096349\n",
      "Epoch [73/1000] - Loss: 0.025268 - Valid. (MSE): 0.017594 - Valid. (MAE): 0.096797\n",
      "Epoch [74/1000] - Loss: 0.024604 - Valid. (MSE): 0.017620 - Valid. (MAE): 0.095239\n",
      "Epoch [74/1000] - Loss: 0.025100 - Valid. (MSE): 0.018095 - Valid. (MAE): 0.095524\n",
      "Epoch [75/1000] - Loss: 0.027430 - Valid. (MSE): 0.017527 - Valid. (MAE): 0.095516\n",
      "Epoch [76/1000] - Loss: 0.025040 - Valid. (MSE): 0.018175 - Valid. (MAE): 0.097556\n",
      "Epoch [76/1000] - Loss: 0.023822 - Valid. (MSE): 0.018034 - Valid. (MAE): 0.094312\n",
      "Epoch [77/1000] - Loss: 0.021737 - Valid. (MSE): 0.017882 - Valid. (MAE): 0.096717\n",
      "Epoch [78/1000] - Loss: 0.024680 - Valid. (MSE): 0.018089 - Valid. (MAE): 0.098050\n",
      "Epoch [78/1000] - Loss: 0.023782 - Valid. (MSE): 0.017996 - Valid. (MAE): 0.094162\n",
      "Epoch [79/1000] - Loss: 0.023087 - Valid. (MSE): 0.017662 - Valid. (MAE): 0.095824\n",
      "Epoch [79/1000] - Loss: 0.023647 - Valid. (MSE): 0.017974 - Valid. (MAE): 0.095613\n",
      "Epoch [80/1000] - Loss: 0.023363 - Valid. (MSE): 0.017722 - Valid. (MAE): 0.094216\n",
      "Epoch [81/1000] - Loss: 0.025430 - Valid. (MSE): 0.017801 - Valid. (MAE): 0.097546\n",
      "Epoch [81/1000] - Loss: 0.023598 - Valid. (MSE): 0.017843 - Valid. (MAE): 0.096156\n",
      "Epoch [82/1000] - Loss: 0.022696 - Valid. (MSE): 0.018037 - Valid. (MAE): 0.094571\n",
      "Epoch [83/1000] - Loss: 0.027476 - Valid. (MSE): 0.017653 - Valid. (MAE): 0.097597\n",
      "Epoch [83/1000] - Loss: 0.024495 - Valid. (MSE): 0.017961 - Valid. (MAE): 0.095050\n",
      "Epoch [84/1000] - Loss: 0.024362 - Valid. (MSE): 0.017638 - Valid. (MAE): 0.096152\n",
      "Epoch [84/1000] - Loss: 0.025100 - Valid. (MSE): 0.017555 - Valid. (MAE): 0.095501\n",
      "Epoch [85/1000] - Loss: 0.022347 - Valid. (MSE): 0.017754 - Valid. (MAE): 0.094191\n",
      "Epoch [86/1000] - Loss: 0.023453 - Valid. (MSE): 0.017562 - Valid. (MAE): 0.096845\n",
      "Epoch [86/1000] - Loss: 0.024932 - Valid. (MSE): 0.017835 - Valid. (MAE): 0.094174\n",
      "Epoch [87/1000] - Loss: 0.024616 - Valid. (MSE): 0.017700 - Valid. (MAE): 0.094494\n",
      "Epoch [88/1000] - Loss: 0.022624 - Valid. (MSE): 0.017628 - Valid. (MAE): 0.097812\n",
      "Epoch [88/1000] - Loss: 0.022401 - Valid. (MSE): 0.018227 - Valid. (MAE): 0.094132\n",
      "Epoch [89/1000] - Loss: 0.024232 - Valid. (MSE): 0.017703 - Valid. (MAE): 0.097865\n",
      "Epoch [89/1000] - Loss: 0.023950 - Valid. (MSE): 0.017786 - Valid. (MAE): 0.093851\n",
      "Epoch [90/1000] - Loss: 0.024615 - Valid. (MSE): 0.017753 - Valid. (MAE): 0.095158\n",
      "Epoch [91/1000] - Loss: 0.024499 - Valid. (MSE): 0.017711 - Valid. (MAE): 0.097288\n",
      "Epoch [91/1000] - Loss: 0.023638 - Valid. (MSE): 0.018510 - Valid. (MAE): 0.095280\n",
      "Epoch [92/1000] - Loss: 0.025227 - Valid. (MSE): 0.017543 - Valid. (MAE): 0.096206\n",
      "Epoch [93/1000] - Loss: 0.024704 - Valid. (MSE): 0.017507 - Valid. (MAE): 0.094354\n",
      "Epoch [93/1000] - Loss: 0.024986 - Valid. (MSE): 0.018012 - Valid. (MAE): 0.096124\n",
      "Epoch [94/1000] - Loss: 0.023322 - Valid. (MSE): 0.017390 - Valid. (MAE): 0.094956\n",
      "Epoch [94/1000] - Loss: 0.025118 - Valid. (MSE): 0.017536 - Valid. (MAE): 0.094891\n",
      "Epoch [95/1000] - Loss: 0.022883 - Valid. (MSE): 0.017324 - Valid. (MAE): 0.094561\n",
      "Epoch [96/1000] - Loss: 0.023176 - Valid. (MSE): 0.017776 - Valid. (MAE): 0.095486\n",
      "Epoch [96/1000] - Loss: 0.022998 - Valid. (MSE): 0.017481 - Valid. (MAE): 0.095081\n",
      "Epoch [97/1000] - Loss: 0.024370 - Valid. (MSE): 0.017345 - Valid. (MAE): 0.094540\n",
      "Epoch [98/1000] - Loss: 0.022976 - Valid. (MSE): 0.017647 - Valid. (MAE): 0.097173\n",
      "Epoch [98/1000] - Loss: 0.023669 - Valid. (MSE): 0.017565 - Valid. (MAE): 0.093896\n",
      "Epoch [99/1000] - Loss: 0.023874 - Valid. (MSE): 0.017380 - Valid. (MAE): 0.095038\n",
      "Epoch [99/1000] - Loss: 0.022193 - Valid. (MSE): 0.017396 - Valid. (MAE): 0.095710\n",
      "Epoch [100/1000] - Loss: 0.022452 - Valid. (MSE): 0.017425 - Valid. (MAE): 0.094010\n",
      "Epoch [101/1000] - Loss: 0.021553 - Valid. (MSE): 0.017232 - Valid. (MAE): 0.094516\n",
      "Epoch [101/1000] - Loss: 0.023768 - Valid. (MSE): 0.017513 - Valid. (MAE): 0.096564\n",
      "Epoch [102/1000] - Loss: 0.022290 - Valid. (MSE): 0.017388 - Valid. (MAE): 0.093019\n",
      "Epoch [103/1000] - Loss: 0.024315 - Valid. (MSE): 0.017307 - Valid. (MAE): 0.096852\n",
      "Epoch [103/1000] - Loss: 0.021956 - Valid. (MSE): 0.017288 - Valid. (MAE): 0.093282\n",
      "Epoch [104/1000] - Loss: 0.023076 - Valid. (MSE): 0.017337 - Valid. (MAE): 0.094402\n",
      "Epoch [104/1000] - Loss: 0.024707 - Valid. (MSE): 0.017570 - Valid. (MAE): 0.096447\n",
      "Epoch [105/1000] - Loss: 0.023906 - Valid. (MSE): 0.017325 - Valid. (MAE): 0.096065\n",
      "Epoch [106/1000] - Loss: 0.023567 - Valid. (MSE): 0.017537 - Valid. (MAE): 0.093424\n",
      "Epoch [106/1000] - Loss: 0.023346 - Valid. (MSE): 0.017463 - Valid. (MAE): 0.096539\n",
      "Epoch [107/1000] - Loss: 0.024278 - Valid. (MSE): 0.017176 - Valid. (MAE): 0.094279\n",
      "Epoch [108/1000] - Loss: 0.021316 - Valid. (MSE): 0.017713 - Valid. (MAE): 0.094682\n",
      "Epoch [108/1000] - Loss: 0.025553 - Valid. (MSE): 0.017138 - Valid. (MAE): 0.095115\n",
      "Epoch [109/1000] - Loss: 0.023801 - Valid. (MSE): 0.017325 - Valid. (MAE): 0.093842\n",
      "Epoch [109/1000] - Loss: 0.025332 - Valid. (MSE): 0.017436 - Valid. (MAE): 0.094595\n",
      "Epoch [110/1000] - Loss: 0.023132 - Valid. (MSE): 0.017267 - Valid. (MAE): 0.095147\n",
      "Epoch [111/1000] - Loss: 0.023377 - Valid. (MSE): 0.018048 - Valid. (MAE): 0.095438\n",
      "Epoch [111/1000] - Loss: 0.024041 - Valid. (MSE): 0.017200 - Valid. (MAE): 0.096261\n",
      "Epoch [112/1000] - Loss: 0.022593 - Valid. (MSE): 0.017366 - Valid. (MAE): 0.093219\n",
      "Epoch [113/1000] - Loss: 0.022761 - Valid. (MSE): 0.017271 - Valid. (MAE): 0.094747\n",
      "Epoch [113/1000] - Loss: 0.022115 - Valid. (MSE): 0.017210 - Valid. (MAE): 0.094108\n",
      "Epoch [114/1000] - Loss: 0.022415 - Valid. (MSE): 0.017380 - Valid. (MAE): 0.095723\n",
      "Epoch [114/1000] - Loss: 0.022288 - Valid. (MSE): 0.017181 - Valid. (MAE): 0.094602\n",
      "Epoch [115/1000] - Loss: 0.023241 - Valid. (MSE): 0.017282 - Valid. (MAE): 0.094120\n",
      "Epoch [116/1000] - Loss: 0.023833 - Valid. (MSE): 0.017264 - Valid. (MAE): 0.095496\n",
      "Epoch [116/1000] - Loss: 0.024057 - Valid. (MSE): 0.017371 - Valid. (MAE): 0.093666\n",
      "Epoch [117/1000] - Loss: 0.023511 - Valid. (MSE): 0.017192 - Valid. (MAE): 0.094003\n",
      "Epoch [118/1000] - Loss: 0.022918 - Valid. (MSE): 0.017244 - Valid. (MAE): 0.094266\n",
      "Epoch [118/1000] - Loss: 0.024018 - Valid. (MSE): 0.017156 - Valid. (MAE): 0.094517\n",
      "Epoch [119/1000] - Loss: 0.022571 - Valid. (MSE): 0.017589 - Valid. (MAE): 0.096929\n",
      "Epoch [119/1000] - Loss: 0.023219 - Valid. (MSE): 0.017298 - Valid. (MAE): 0.093384\n",
      "Epoch [120/1000] - Loss: 0.022753 - Valid. (MSE): 0.017112 - Valid. (MAE): 0.093935\n",
      "Epoch [121/1000] - Loss: 0.023628 - Valid. (MSE): 0.017645 - Valid. (MAE): 0.095358\n",
      "Epoch [121/1000] - Loss: 0.023891 - Valid. (MSE): 0.017166 - Valid. (MAE): 0.094440\n",
      "Epoch [122/1000] - Loss: 0.023664 - Valid. (MSE): 0.017388 - Valid. (MAE): 0.096114\n",
      "Epoch [123/1000] - Loss: 0.020359 - Valid. (MSE): 0.017528 - Valid. (MAE): 0.093281\n",
      "Epoch [123/1000] - Loss: 0.022091 - Valid. (MSE): 0.017296 - Valid. (MAE): 0.096097\n",
      "Epoch [124/1000] - Loss: 0.022611 - Valid. (MSE): 0.017263 - Valid. (MAE): 0.094591\n",
      "Epoch [124/1000] - Loss: 0.022749 - Valid. (MSE): 0.017438 - Valid. (MAE): 0.093849\n",
      "Epoch [125/1000] - Loss: 0.023592 - Valid. (MSE): 0.017110 - Valid. (MAE): 0.094311\n",
      "Epoch [126/1000] - Loss: 0.023540 - Valid. (MSE): 0.017312 - Valid. (MAE): 0.095319\n",
      "Epoch [126/1000] - Loss: 0.023114 - Valid. (MSE): 0.017172 - Valid. (MAE): 0.094341\n",
      "Epoch [127/1000] - Loss: 0.022343 - Valid. (MSE): 0.017175 - Valid. (MAE): 0.094424\n",
      "Epoch [128/1000] - Loss: 0.021989 - Valid. (MSE): 0.017173 - Valid. (MAE): 0.093677\n",
      "Epoch [128/1000] - Loss: 0.021738 - Valid. (MSE): 0.017558 - Valid. (MAE): 0.095791\n",
      "Epoch [129/1000] - Loss: 0.020776 - Valid. (MSE): 0.017197 - Valid. (MAE): 0.093607\n",
      "Epoch [129/1000] - Loss: 0.022820 - Valid. (MSE): 0.017124 - Valid. (MAE): 0.095131\n",
      "Epoch [130/1000] - Loss: 0.021918 - Valid. (MSE): 0.017095 - Valid. (MAE): 0.092600\n",
      "Epoch [131/1000] - Loss: 0.023971 - Valid. (MSE): 0.017143 - Valid. (MAE): 0.095524\n",
      "Epoch [131/1000] - Loss: 0.022789 - Valid. (MSE): 0.017372 - Valid. (MAE): 0.094073\n",
      "Epoch [132/1000] - Loss: 0.025598 - Valid. (MSE): 0.017451 - Valid. (MAE): 0.095118\n",
      "Epoch [133/1000] - Loss: 0.021658 - Valid. (MSE): 0.017404 - Valid. (MAE): 0.094490\n",
      "Epoch [133/1000] - Loss: 0.020382 - Valid. (MSE): 0.017287 - Valid. (MAE): 0.094352\n",
      "Epoch [134/1000] - Loss: 0.021730 - Valid. (MSE): 0.017316 - Valid. (MAE): 0.094252\n",
      "Epoch [134/1000] - Loss: 0.022013 - Valid. (MSE): 0.017678 - Valid. (MAE): 0.096857\n",
      "Epoch [135/1000] - Loss: 0.022369 - Valid. (MSE): 0.017078 - Valid. (MAE): 0.092567\n",
      "Epoch [136/1000] - Loss: 0.023255 - Valid. (MSE): 0.017176 - Valid. (MAE): 0.095158\n",
      "Epoch [136/1000] - Loss: 0.022531 - Valid. (MSE): 0.017179 - Valid. (MAE): 0.093392\n",
      "Epoch [137/1000] - Loss: 0.022334 - Valid. (MSE): 0.017195 - Valid. (MAE): 0.095395\n",
      "Epoch [138/1000] - Loss: 0.022215 - Valid. (MSE): 0.017008 - Valid. (MAE): 0.093056\n",
      "Epoch [138/1000] - Loss: 0.021694 - Valid. (MSE): 0.017041 - Valid. (MAE): 0.094673\n",
      "Epoch [139/1000] - Loss: 0.023857 - Valid. (MSE): 0.017303 - Valid. (MAE): 0.095962\n",
      "Epoch [139/1000] - Loss: 0.021729 - Valid. (MSE): 0.017151 - Valid. (MAE): 0.092245\n",
      "Stopping early at epoch 140. Best validation MSE: 0.017137598176712145 at epoch 108.\n",
      "Seed 46 completed:\n",
      "  - Final epoch: 140\n",
      "  - Best epoch: 108\n",
      "  - Training time: 1544.91s\n",
      "  - Test MSE: 0.018841\n",
      "  - Test MAE: 0.098423\n",
      "  - MPE: 0.037162\n",
      "  - Coverage 95%: 0.9230\n",
      "\n",
      "--- Training with seed 47 (6/10) ---\n",
      "Starting training for seed 47...\n",
      "Epoch [0/1000] - Loss: 0.175306 - Valid. (MSE): 0.134320 - Valid. (MAE): 0.280944\n",
      "Epoch [1/1000] - Loss: 0.119080 - Valid. (MSE): 0.057563 - Valid. (MAE): 0.195124\n",
      "Epoch [1/1000] - Loss: 0.114584 - Valid. (MSE): 0.055229 - Valid. (MAE): 0.185120\n",
      "Epoch [2/1000] - Loss: 0.094490 - Valid. (MSE): 0.069069 - Valid. (MAE): 0.187145\n",
      "Epoch [3/1000] - Loss: 0.088872 - Valid. (MSE): 0.062538 - Valid. (MAE): 0.179510\n",
      "Epoch [3/1000] - Loss: 0.086527 - Valid. (MSE): 0.051767 - Valid. (MAE): 0.178737\n",
      "Epoch [4/1000] - Loss: 0.081671 - Valid. (MSE): 0.050693 - Valid. (MAE): 0.175411\n",
      "Epoch [4/1000] - Loss: 0.082325 - Valid. (MSE): 0.053327 - Valid. (MAE): 0.169971\n",
      "Epoch [5/1000] - Loss: 0.069222 - Valid. (MSE): 0.050097 - Valid. (MAE): 0.168922\n",
      "Epoch [6/1000] - Loss: 0.072245 - Valid. (MSE): 0.048011 - Valid. (MAE): 0.167513\n",
      "Epoch [6/1000] - Loss: 0.070432 - Valid. (MSE): 0.047211 - Valid. (MAE): 0.163035\n",
      "Epoch [7/1000] - Loss: 0.068551 - Valid. (MSE): 0.045501 - Valid. (MAE): 0.159302\n",
      "Epoch [8/1000] - Loss: 0.068911 - Valid. (MSE): 0.043855 - Valid. (MAE): 0.155196\n",
      "Epoch [8/1000] - Loss: 0.062252 - Valid. (MSE): 0.042840 - Valid. (MAE): 0.150833\n",
      "Epoch [9/1000] - Loss: 0.060194 - Valid. (MSE): 0.040503 - Valid. (MAE): 0.149594\n",
      "Epoch [9/1000] - Loss: 0.062094 - Valid. (MSE): 0.040441 - Valid. (MAE): 0.145076\n",
      "Epoch [10/1000] - Loss: 0.057250 - Valid. (MSE): 0.038666 - Valid. (MAE): 0.143159\n",
      "Epoch [11/1000] - Loss: 0.058565 - Valid. (MSE): 0.037439 - Valid. (MAE): 0.140637\n",
      "Epoch [11/1000] - Loss: 0.055078 - Valid. (MSE): 0.036004 - Valid. (MAE): 0.138395\n",
      "Epoch [12/1000] - Loss: 0.057498 - Valid. (MSE): 0.035557 - Valid. (MAE): 0.134800\n",
      "Epoch [13/1000] - Loss: 0.059122 - Valid. (MSE): 0.034107 - Valid. (MAE): 0.132214\n",
      "Epoch [13/1000] - Loss: 0.048117 - Valid. (MSE): 0.033293 - Valid. (MAE): 0.129225\n",
      "Epoch [14/1000] - Loss: 0.051280 - Valid. (MSE): 0.031599 - Valid. (MAE): 0.127541\n",
      "Epoch [14/1000] - Loss: 0.052471 - Valid. (MSE): 0.030710 - Valid. (MAE): 0.125191\n",
      "Epoch [15/1000] - Loss: 0.047835 - Valid. (MSE): 0.030344 - Valid. (MAE): 0.122636\n",
      "Epoch [16/1000] - Loss: 0.044750 - Valid. (MSE): 0.029841 - Valid. (MAE): 0.120644\n",
      "Epoch [16/1000] - Loss: 0.044446 - Valid. (MSE): 0.027972 - Valid. (MAE): 0.119852\n",
      "Epoch [17/1000] - Loss: 0.044325 - Valid. (MSE): 0.028644 - Valid. (MAE): 0.117542\n",
      "Epoch [18/1000] - Loss: 0.046431 - Valid. (MSE): 0.026243 - Valid. (MAE): 0.119719\n",
      "Epoch [18/1000] - Loss: 0.045041 - Valid. (MSE): 0.025973 - Valid. (MAE): 0.116677\n",
      "Epoch [19/1000] - Loss: 0.041715 - Valid. (MSE): 0.028253 - Valid. (MAE): 0.115058\n",
      "Epoch [19/1000] - Loss: 0.039432 - Valid. (MSE): 0.025497 - Valid. (MAE): 0.112599\n",
      "Epoch [20/1000] - Loss: 0.037893 - Valid. (MSE): 0.025470 - Valid. (MAE): 0.111119\n",
      "Epoch [21/1000] - Loss: 0.045039 - Valid. (MSE): 0.026007 - Valid. (MAE): 0.110991\n",
      "Epoch [21/1000] - Loss: 0.040217 - Valid. (MSE): 0.025119 - Valid. (MAE): 0.110012\n",
      "Epoch [22/1000] - Loss: 0.040496 - Valid. (MSE): 0.025120 - Valid. (MAE): 0.109625\n",
      "Epoch [23/1000] - Loss: 0.040234 - Valid. (MSE): 0.024221 - Valid. (MAE): 0.108216\n",
      "Epoch [23/1000] - Loss: 0.037163 - Valid. (MSE): 0.023766 - Valid. (MAE): 0.106617\n",
      "Epoch [24/1000] - Loss: 0.040124 - Valid. (MSE): 0.023136 - Valid. (MAE): 0.105997\n",
      "Epoch [24/1000] - Loss: 0.037411 - Valid. (MSE): 0.024345 - Valid. (MAE): 0.106471\n",
      "Epoch [25/1000] - Loss: 0.036965 - Valid. (MSE): 0.025986 - Valid. (MAE): 0.108819\n",
      "Epoch [26/1000] - Loss: 0.044419 - Valid. (MSE): 0.023006 - Valid. (MAE): 0.104482\n",
      "Epoch [26/1000] - Loss: 0.038115 - Valid. (MSE): 0.021653 - Valid. (MAE): 0.106018\n",
      "Epoch [27/1000] - Loss: 0.036885 - Valid. (MSE): 0.022844 - Valid. (MAE): 0.104670\n",
      "Epoch [28/1000] - Loss: 0.035007 - Valid. (MSE): 0.024433 - Valid. (MAE): 0.105197\n",
      "Epoch [28/1000] - Loss: 0.039094 - Valid. (MSE): 0.021527 - Valid. (MAE): 0.102343\n",
      "Epoch [29/1000] - Loss: 0.037001 - Valid. (MSE): 0.021706 - Valid. (MAE): 0.102278\n",
      "Epoch [29/1000] - Loss: 0.035303 - Valid. (MSE): 0.022749 - Valid. (MAE): 0.103247\n",
      "Epoch [30/1000] - Loss: 0.035610 - Valid. (MSE): 0.021753 - Valid. (MAE): 0.101925\n",
      "Epoch [31/1000] - Loss: 0.033638 - Valid. (MSE): 0.020903 - Valid. (MAE): 0.101258\n",
      "Epoch [31/1000] - Loss: 0.035567 - Valid. (MSE): 0.021128 - Valid. (MAE): 0.101297\n",
      "Epoch [32/1000] - Loss: 0.033024 - Valid. (MSE): 0.020331 - Valid. (MAE): 0.099957\n",
      "Epoch [33/1000] - Loss: 0.032348 - Valid. (MSE): 0.019989 - Valid. (MAE): 0.100697\n",
      "Epoch [33/1000] - Loss: 0.036061 - Valid. (MSE): 0.020148 - Valid. (MAE): 0.100076\n",
      "Epoch [34/1000] - Loss: 0.036232 - Valid. (MSE): 0.022157 - Valid. (MAE): 0.101823\n",
      "Epoch [34/1000] - Loss: 0.034039 - Valid. (MSE): 0.021382 - Valid. (MAE): 0.100806\n",
      "Epoch [35/1000] - Loss: 0.033470 - Valid. (MSE): 0.020514 - Valid. (MAE): 0.100301\n",
      "Epoch [36/1000] - Loss: 0.031977 - Valid. (MSE): 0.020888 - Valid. (MAE): 0.100159\n",
      "Epoch [36/1000] - Loss: 0.034209 - Valid. (MSE): 0.021149 - Valid. (MAE): 0.099788\n",
      "Epoch [37/1000] - Loss: 0.033451 - Valid. (MSE): 0.020220 - Valid. (MAE): 0.099204\n",
      "Epoch [38/1000] - Loss: 0.032826 - Valid. (MSE): 0.021174 - Valid. (MAE): 0.099606\n",
      "Epoch [38/1000] - Loss: 0.032411 - Valid. (MSE): 0.019937 - Valid. (MAE): 0.099216\n",
      "Epoch [39/1000] - Loss: 0.033321 - Valid. (MSE): 0.019766 - Valid. (MAE): 0.097836\n",
      "Epoch [39/1000] - Loss: 0.033324 - Valid. (MSE): 0.021015 - Valid. (MAE): 0.100404\n",
      "Epoch [40/1000] - Loss: 0.032053 - Valid. (MSE): 0.021631 - Valid. (MAE): 0.100107\n",
      "Epoch [41/1000] - Loss: 0.032584 - Valid. (MSE): 0.021055 - Valid. (MAE): 0.099388\n",
      "Epoch [41/1000] - Loss: 0.035910 - Valid. (MSE): 0.019770 - Valid. (MAE): 0.098837\n",
      "Epoch [42/1000] - Loss: 0.032485 - Valid. (MSE): 0.019875 - Valid. (MAE): 0.098042\n",
      "Epoch [43/1000] - Loss: 0.029983 - Valid. (MSE): 0.021564 - Valid. (MAE): 0.099732\n",
      "Epoch [43/1000] - Loss: 0.030939 - Valid. (MSE): 0.020267 - Valid. (MAE): 0.097752\n",
      "Epoch [44/1000] - Loss: 0.030108 - Valid. (MSE): 0.019489 - Valid. (MAE): 0.096328\n",
      "Epoch [44/1000] - Loss: 0.032711 - Valid. (MSE): 0.020235 - Valid. (MAE): 0.098705\n",
      "Epoch [45/1000] - Loss: 0.032499 - Valid. (MSE): 0.021594 - Valid. (MAE): 0.099644\n",
      "Epoch [46/1000] - Loss: 0.029863 - Valid. (MSE): 0.019561 - Valid. (MAE): 0.098280\n",
      "Epoch [46/1000] - Loss: 0.033131 - Valid. (MSE): 0.020743 - Valid. (MAE): 0.098439\n",
      "Epoch [47/1000] - Loss: 0.029757 - Valid. (MSE): 0.021107 - Valid. (MAE): 0.098760\n",
      "Epoch [48/1000] - Loss: 0.031378 - Valid. (MSE): 0.019473 - Valid. (MAE): 0.098973\n",
      "Epoch [48/1000] - Loss: 0.031712 - Valid. (MSE): 0.021391 - Valid. (MAE): 0.099714\n",
      "Epoch [49/1000] - Loss: 0.029166 - Valid. (MSE): 0.020725 - Valid. (MAE): 0.098035\n",
      "Epoch [49/1000] - Loss: 0.031852 - Valid. (MSE): 0.020011 - Valid. (MAE): 0.096861\n",
      "Epoch [50/1000] - Loss: 0.030219 - Valid. (MSE): 0.019251 - Valid. (MAE): 0.096204\n",
      "Epoch [51/1000] - Loss: 0.029548 - Valid. (MSE): 0.019841 - Valid. (MAE): 0.096708\n",
      "Epoch [51/1000] - Loss: 0.028968 - Valid. (MSE): 0.019270 - Valid. (MAE): 0.096692\n",
      "Epoch [52/1000] - Loss: 0.028701 - Valid. (MSE): 0.018787 - Valid. (MAE): 0.096954\n",
      "Epoch [53/1000] - Loss: 0.027399 - Valid. (MSE): 0.020684 - Valid. (MAE): 0.097515\n",
      "Epoch [53/1000] - Loss: 0.026961 - Valid. (MSE): 0.019544 - Valid. (MAE): 0.096080\n",
      "Epoch [54/1000] - Loss: 0.028353 - Valid. (MSE): 0.019387 - Valid. (MAE): 0.095883\n",
      "Epoch [54/1000] - Loss: 0.029216 - Valid. (MSE): 0.019255 - Valid. (MAE): 0.095911\n",
      "Epoch [55/1000] - Loss: 0.027550 - Valid. (MSE): 0.020070 - Valid. (MAE): 0.096472\n",
      "Epoch [56/1000] - Loss: 0.028986 - Valid. (MSE): 0.019616 - Valid. (MAE): 0.096165\n",
      "Epoch [56/1000] - Loss: 0.028708 - Valid. (MSE): 0.019528 - Valid. (MAE): 0.096184\n",
      "Epoch [57/1000] - Loss: 0.028710 - Valid. (MSE): 0.018738 - Valid. (MAE): 0.096617\n",
      "Epoch [58/1000] - Loss: 0.026913 - Valid. (MSE): 0.019168 - Valid. (MAE): 0.097383\n",
      "Epoch [58/1000] - Loss: 0.026591 - Valid. (MSE): 0.020257 - Valid. (MAE): 0.096964\n",
      "Epoch [59/1000] - Loss: 0.028297 - Valid. (MSE): 0.019219 - Valid. (MAE): 0.096342\n",
      "Epoch [59/1000] - Loss: 0.028360 - Valid. (MSE): 0.020115 - Valid. (MAE): 0.096499\n",
      "Epoch [60/1000] - Loss: 0.030051 - Valid. (MSE): 0.019017 - Valid. (MAE): 0.096745\n",
      "Epoch [61/1000] - Loss: 0.027867 - Valid. (MSE): 0.019200 - Valid. (MAE): 0.095208\n",
      "Epoch [61/1000] - Loss: 0.029706 - Valid. (MSE): 0.018919 - Valid. (MAE): 0.096401\n",
      "Epoch [62/1000] - Loss: 0.028687 - Valid. (MSE): 0.019096 - Valid. (MAE): 0.096441\n",
      "Epoch [63/1000] - Loss: 0.027401 - Valid. (MSE): 0.020710 - Valid. (MAE): 0.097263\n",
      "Epoch [63/1000] - Loss: 0.028886 - Valid. (MSE): 0.019522 - Valid. (MAE): 0.096026\n",
      "Epoch [64/1000] - Loss: 0.029987 - Valid. (MSE): 0.018576 - Valid. (MAE): 0.096246\n",
      "Epoch [64/1000] - Loss: 0.028218 - Valid. (MSE): 0.018928 - Valid. (MAE): 0.094925\n",
      "Epoch [65/1000] - Loss: 0.027306 - Valid. (MSE): 0.019478 - Valid. (MAE): 0.097101\n",
      "Epoch [66/1000] - Loss: 0.027569 - Valid. (MSE): 0.018989 - Valid. (MAE): 0.094463\n",
      "Epoch [66/1000] - Loss: 0.027896 - Valid. (MSE): 0.019998 - Valid. (MAE): 0.096840\n",
      "Epoch [67/1000] - Loss: 0.026475 - Valid. (MSE): 0.018329 - Valid. (MAE): 0.094441\n",
      "Epoch [68/1000] - Loss: 0.028096 - Valid. (MSE): 0.019785 - Valid. (MAE): 0.096651\n",
      "Epoch [68/1000] - Loss: 0.024290 - Valid. (MSE): 0.018591 - Valid. (MAE): 0.094301\n",
      "Epoch [69/1000] - Loss: 0.026670 - Valid. (MSE): 0.018758 - Valid. (MAE): 0.094703\n",
      "Epoch [69/1000] - Loss: 0.027174 - Valid. (MSE): 0.019063 - Valid. (MAE): 0.094600\n",
      "Epoch [70/1000] - Loss: 0.029030 - Valid. (MSE): 0.018563 - Valid. (MAE): 0.095167\n",
      "Epoch [71/1000] - Loss: 0.028074 - Valid. (MSE): 0.018820 - Valid. (MAE): 0.094705\n",
      "Epoch [71/1000] - Loss: 0.029345 - Valid. (MSE): 0.018926 - Valid. (MAE): 0.094297\n",
      "Epoch [72/1000] - Loss: 0.027548 - Valid. (MSE): 0.018962 - Valid. (MAE): 0.095676\n",
      "Epoch [73/1000] - Loss: 0.025018 - Valid. (MSE): 0.019727 - Valid. (MAE): 0.095370\n",
      "Epoch [73/1000] - Loss: 0.026900 - Valid. (MSE): 0.018419 - Valid. (MAE): 0.094006\n",
      "Epoch [74/1000] - Loss: 0.026491 - Valid. (MSE): 0.018712 - Valid. (MAE): 0.096765\n",
      "Epoch [74/1000] - Loss: 0.025401 - Valid. (MSE): 0.019346 - Valid. (MAE): 0.094889\n",
      "Epoch [75/1000] - Loss: 0.025585 - Valid. (MSE): 0.018360 - Valid. (MAE): 0.095050\n",
      "Epoch [76/1000] - Loss: 0.026543 - Valid. (MSE): 0.019128 - Valid. (MAE): 0.094958\n",
      "Epoch [76/1000] - Loss: 0.025228 - Valid. (MSE): 0.018502 - Valid. (MAE): 0.093805\n",
      "Epoch [77/1000] - Loss: 0.025631 - Valid. (MSE): 0.018542 - Valid. (MAE): 0.095487\n",
      "Epoch [78/1000] - Loss: 0.026111 - Valid. (MSE): 0.019888 - Valid. (MAE): 0.095437\n",
      "Epoch [78/1000] - Loss: 0.025641 - Valid. (MSE): 0.019229 - Valid. (MAE): 0.094556\n",
      "Epoch [79/1000] - Loss: 0.025570 - Valid. (MSE): 0.018436 - Valid. (MAE): 0.095469\n",
      "Epoch [79/1000] - Loss: 0.024295 - Valid. (MSE): 0.019911 - Valid. (MAE): 0.095588\n",
      "Epoch [80/1000] - Loss: 0.024966 - Valid. (MSE): 0.018273 - Valid. (MAE): 0.093761\n",
      "Epoch [81/1000] - Loss: 0.026618 - Valid. (MSE): 0.018283 - Valid. (MAE): 0.094405\n",
      "Epoch [81/1000] - Loss: 0.027013 - Valid. (MSE): 0.019586 - Valid. (MAE): 0.095125\n",
      "Epoch [82/1000] - Loss: 0.028578 - Valid. (MSE): 0.018375 - Valid. (MAE): 0.095455\n",
      "Epoch [83/1000] - Loss: 0.023599 - Valid. (MSE): 0.018477 - Valid. (MAE): 0.094157\n",
      "Epoch [83/1000] - Loss: 0.026062 - Valid. (MSE): 0.018661 - Valid. (MAE): 0.094326\n",
      "Epoch [84/1000] - Loss: 0.026684 - Valid. (MSE): 0.018462 - Valid. (MAE): 0.094196\n",
      "Epoch [84/1000] - Loss: 0.025857 - Valid. (MSE): 0.018698 - Valid. (MAE): 0.095154\n",
      "Epoch [85/1000] - Loss: 0.026101 - Valid. (MSE): 0.018474 - Valid. (MAE): 0.094397\n",
      "Epoch [86/1000] - Loss: 0.026377 - Valid. (MSE): 0.019037 - Valid. (MAE): 0.095754\n",
      "Epoch [86/1000] - Loss: 0.025369 - Valid. (MSE): 0.018519 - Valid. (MAE): 0.094263\n",
      "Epoch [87/1000] - Loss: 0.026074 - Valid. (MSE): 0.018691 - Valid. (MAE): 0.095671\n",
      "Epoch [88/1000] - Loss: 0.024719 - Valid. (MSE): 0.018314 - Valid. (MAE): 0.095567\n",
      "Epoch [88/1000] - Loss: 0.024269 - Valid. (MSE): 0.020058 - Valid. (MAE): 0.096255\n",
      "Epoch [89/1000] - Loss: 0.025295 - Valid. (MSE): 0.018692 - Valid. (MAE): 0.096134\n",
      "Epoch [89/1000] - Loss: 0.030042 - Valid. (MSE): 0.018423 - Valid. (MAE): 0.094373\n",
      "Epoch [90/1000] - Loss: 0.024528 - Valid. (MSE): 0.018698 - Valid. (MAE): 0.095129\n",
      "Epoch [91/1000] - Loss: 0.023064 - Valid. (MSE): 0.018192 - Valid. (MAE): 0.094473\n",
      "Epoch [91/1000] - Loss: 0.027072 - Valid. (MSE): 0.018835 - Valid. (MAE): 0.094798\n",
      "Epoch [92/1000] - Loss: 0.025818 - Valid. (MSE): 0.018687 - Valid. (MAE): 0.095407\n",
      "Epoch [93/1000] - Loss: 0.026447 - Valid. (MSE): 0.018329 - Valid. (MAE): 0.094511\n",
      "Epoch [93/1000] - Loss: 0.024674 - Valid. (MSE): 0.018995 - Valid. (MAE): 0.094792\n",
      "Epoch [94/1000] - Loss: 0.023697 - Valid. (MSE): 0.018302 - Valid. (MAE): 0.095625\n",
      "Epoch [94/1000] - Loss: 0.025679 - Valid. (MSE): 0.018685 - Valid. (MAE): 0.094234\n",
      "Epoch [95/1000] - Loss: 0.023133 - Valid. (MSE): 0.018421 - Valid. (MAE): 0.094415\n",
      "Epoch [96/1000] - Loss: 0.024629 - Valid. (MSE): 0.018391 - Valid. (MAE): 0.094498\n",
      "Epoch [96/1000] - Loss: 0.024974 - Valid. (MSE): 0.018983 - Valid. (MAE): 0.094619\n",
      "Epoch [97/1000] - Loss: 0.024443 - Valid. (MSE): 0.018312 - Valid. (MAE): 0.096740\n",
      "Epoch [98/1000] - Loss: 0.026422 - Valid. (MSE): 0.018491 - Valid. (MAE): 0.093832\n",
      "Epoch [98/1000] - Loss: 0.022543 - Valid. (MSE): 0.018561 - Valid. (MAE): 0.094062\n",
      "Epoch [99/1000] - Loss: 0.025771 - Valid. (MSE): 0.018074 - Valid. (MAE): 0.093425\n",
      "Epoch [99/1000] - Loss: 0.024662 - Valid. (MSE): 0.018099 - Valid. (MAE): 0.095156\n",
      "Epoch [100/1000] - Loss: 0.022748 - Valid. (MSE): 0.018238 - Valid. (MAE): 0.093636\n",
      "Epoch [101/1000] - Loss: 0.023625 - Valid. (MSE): 0.018910 - Valid. (MAE): 0.094233\n",
      "Epoch [101/1000] - Loss: 0.024158 - Valid. (MSE): 0.018165 - Valid. (MAE): 0.094405\n",
      "Epoch [102/1000] - Loss: 0.023456 - Valid. (MSE): 0.018255 - Valid. (MAE): 0.094374\n",
      "Epoch [103/1000] - Loss: 0.023226 - Valid. (MSE): 0.018768 - Valid. (MAE): 0.094109\n",
      "Epoch [103/1000] - Loss: 0.024365 - Valid. (MSE): 0.018204 - Valid. (MAE): 0.095960\n",
      "Epoch [104/1000] - Loss: 0.024004 - Valid. (MSE): 0.018751 - Valid. (MAE): 0.094015\n",
      "Epoch [104/1000] - Loss: 0.023557 - Valid. (MSE): 0.018072 - Valid. (MAE): 0.094293\n",
      "Epoch [105/1000] - Loss: 0.024339 - Valid. (MSE): 0.018209 - Valid. (MAE): 0.095675\n",
      "Epoch [106/1000] - Loss: 0.024738 - Valid. (MSE): 0.018547 - Valid. (MAE): 0.093928\n",
      "Epoch [106/1000] - Loss: 0.025039 - Valid. (MSE): 0.018271 - Valid. (MAE): 0.098069\n",
      "Epoch [107/1000] - Loss: 0.025655 - Valid. (MSE): 0.018620 - Valid. (MAE): 0.094141\n",
      "Epoch [108/1000] - Loss: 0.024810 - Valid. (MSE): 0.018400 - Valid. (MAE): 0.094348\n",
      "Epoch [108/1000] - Loss: 0.022795 - Valid. (MSE): 0.018034 - Valid. (MAE): 0.095449\n",
      "Epoch [109/1000] - Loss: 0.025158 - Valid. (MSE): 0.018528 - Valid. (MAE): 0.093922\n",
      "Epoch [109/1000] - Loss: 0.022226 - Valid. (MSE): 0.018649 - Valid. (MAE): 0.094045\n",
      "Epoch [110/1000] - Loss: 0.025111 - Valid. (MSE): 0.018173 - Valid. (MAE): 0.096172\n",
      "Epoch [111/1000] - Loss: 0.024962 - Valid. (MSE): 0.018664 - Valid. (MAE): 0.094048\n",
      "Epoch [111/1000] - Loss: 0.023769 - Valid. (MSE): 0.018201 - Valid. (MAE): 0.095154\n",
      "Epoch [112/1000] - Loss: 0.023899 - Valid. (MSE): 0.018284 - Valid. (MAE): 0.095167\n",
      "Epoch [113/1000] - Loss: 0.023518 - Valid. (MSE): 0.018174 - Valid. (MAE): 0.093380\n",
      "Epoch [113/1000] - Loss: 0.025346 - Valid. (MSE): 0.018774 - Valid. (MAE): 0.094339\n",
      "Epoch [114/1000] - Loss: 0.024125 - Valid. (MSE): 0.018312 - Valid. (MAE): 0.094619\n",
      "Epoch [114/1000] - Loss: 0.021992 - Valid. (MSE): 0.018060 - Valid. (MAE): 0.094658\n",
      "Epoch [115/1000] - Loss: 0.025069 - Valid. (MSE): 0.019101 - Valid. (MAE): 0.094669\n",
      "Epoch [116/1000] - Loss: 0.024611 - Valid. (MSE): 0.017989 - Valid. (MAE): 0.096829\n",
      "Epoch [116/1000] - Loss: 0.025753 - Valid. (MSE): 0.018720 - Valid. (MAE): 0.094255\n",
      "Epoch [117/1000] - Loss: 0.025361 - Valid. (MSE): 0.018588 - Valid. (MAE): 0.095424\n",
      "Epoch [118/1000] - Loss: 0.023333 - Valid. (MSE): 0.018285 - Valid. (MAE): 0.095694\n",
      "Epoch [118/1000] - Loss: 0.021006 - Valid. (MSE): 0.018556 - Valid. (MAE): 0.094781\n",
      "Epoch [119/1000] - Loss: 0.025153 - Valid. (MSE): 0.018027 - Valid. (MAE): 0.094762\n",
      "Epoch [119/1000] - Loss: 0.023318 - Valid. (MSE): 0.018974 - Valid. (MAE): 0.094952\n",
      "Epoch [120/1000] - Loss: 0.024004 - Valid. (MSE): 0.017912 - Valid. (MAE): 0.095021\n",
      "Epoch [121/1000] - Loss: 0.026417 - Valid. (MSE): 0.018586 - Valid. (MAE): 0.093812\n",
      "Epoch [121/1000] - Loss: 0.024051 - Valid. (MSE): 0.018394 - Valid. (MAE): 0.095031\n",
      "Epoch [122/1000] - Loss: 0.024055 - Valid. (MSE): 0.018257 - Valid. (MAE): 0.094044\n",
      "Epoch [123/1000] - Loss: 0.024266 - Valid. (MSE): 0.018239 - Valid. (MAE): 0.094360\n",
      "Epoch [123/1000] - Loss: 0.022527 - Valid. (MSE): 0.018248 - Valid. (MAE): 0.095092\n",
      "Epoch [124/1000] - Loss: 0.023369 - Valid. (MSE): 0.018114 - Valid. (MAE): 0.093362\n",
      "Epoch [124/1000] - Loss: 0.023733 - Valid. (MSE): 0.017989 - Valid. (MAE): 0.094617\n",
      "Epoch [125/1000] - Loss: 0.023164 - Valid. (MSE): 0.018217 - Valid. (MAE): 0.093345\n",
      "Epoch [126/1000] - Loss: 0.026712 - Valid. (MSE): 0.018111 - Valid. (MAE): 0.094495\n",
      "Epoch [126/1000] - Loss: 0.022097 - Valid. (MSE): 0.018425 - Valid. (MAE): 0.094229\n",
      "Epoch [127/1000] - Loss: 0.024204 - Valid. (MSE): 0.017978 - Valid. (MAE): 0.093935\n",
      "Epoch [128/1000] - Loss: 0.023924 - Valid. (MSE): 0.018901 - Valid. (MAE): 0.096139\n",
      "Epoch [128/1000] - Loss: 0.023617 - Valid. (MSE): 0.018114 - Valid. (MAE): 0.094391\n",
      "Epoch [129/1000] - Loss: 0.021974 - Valid. (MSE): 0.018481 - Valid. (MAE): 0.094585\n",
      "Epoch [129/1000] - Loss: 0.022786 - Valid. (MSE): 0.018323 - Valid. (MAE): 0.094487\n",
      "Epoch [130/1000] - Loss: 0.024379 - Valid. (MSE): 0.018039 - Valid. (MAE): 0.094247\n",
      "Stopping early at epoch 131. Best validation MSE: 0.01807426116500088 at epoch 99.\n",
      "Seed 47 completed:\n",
      "  - Final epoch: 131\n",
      "  - Best epoch: 99\n",
      "  - Training time: 1452.89s\n",
      "  - Test MSE: 0.017827\n",
      "  - Test MAE: 0.095155\n",
      "  - MPE: 0.035701\n",
      "  - Coverage 95%: 0.9312\n",
      "\n",
      "--- Training with seed 48 (7/10) ---\n",
      "Starting training for seed 48...\n",
      "Epoch [0/1000] - Loss: 0.128388 - Valid. (MSE): 0.075127 - Valid. (MAE): 0.193442\n",
      "Epoch [1/1000] - Loss: 0.095820 - Valid. (MSE): 0.054080 - Valid. (MAE): 0.186676\n",
      "Epoch [1/1000] - Loss: 0.088539 - Valid. (MSE): 0.053632 - Valid. (MAE): 0.178472\n",
      "Epoch [2/1000] - Loss: 0.084828 - Valid. (MSE): 0.057367 - Valid. (MAE): 0.176416\n",
      "Epoch [3/1000] - Loss: 0.084779 - Valid. (MSE): 0.053853 - Valid. (MAE): 0.177185\n",
      "Epoch [3/1000] - Loss: 0.088103 - Valid. (MSE): 0.053201 - Valid. (MAE): 0.175685\n",
      "Epoch [4/1000] - Loss: 0.080088 - Valid. (MSE): 0.052348 - Valid. (MAE): 0.171591\n",
      "Epoch [4/1000] - Loss: 0.075353 - Valid. (MSE): 0.050146 - Valid. (MAE): 0.168413\n",
      "Epoch [5/1000] - Loss: 0.068936 - Valid. (MSE): 0.047932 - Valid. (MAE): 0.165120\n",
      "Epoch [6/1000] - Loss: 0.068794 - Valid. (MSE): 0.046067 - Valid. (MAE): 0.159908\n",
      "Epoch [6/1000] - Loss: 0.063105 - Valid. (MSE): 0.043644 - Valid. (MAE): 0.156155\n",
      "Epoch [7/1000] - Loss: 0.062790 - Valid. (MSE): 0.042934 - Valid. (MAE): 0.150550\n",
      "Epoch [8/1000] - Loss: 0.059071 - Valid. (MSE): 0.039709 - Valid. (MAE): 0.152342\n",
      "Epoch [8/1000] - Loss: 0.064210 - Valid. (MSE): 0.041822 - Valid. (MAE): 0.145813\n",
      "Epoch [9/1000] - Loss: 0.059910 - Valid. (MSE): 0.038917 - Valid. (MAE): 0.148270\n",
      "Epoch [9/1000] - Loss: 0.059602 - Valid. (MSE): 0.037707 - Valid. (MAE): 0.142742\n",
      "Epoch [10/1000] - Loss: 0.056281 - Valid. (MSE): 0.036414 - Valid. (MAE): 0.138955\n",
      "Epoch [11/1000] - Loss: 0.053263 - Valid. (MSE): 0.035998 - Valid. (MAE): 0.136852\n",
      "Epoch [11/1000] - Loss: 0.051869 - Valid. (MSE): 0.034594 - Valid. (MAE): 0.134841\n",
      "Epoch [12/1000] - Loss: 0.048597 - Valid. (MSE): 0.032548 - Valid. (MAE): 0.134662\n",
      "Epoch [13/1000] - Loss: 0.047176 - Valid. (MSE): 0.032614 - Valid. (MAE): 0.129323\n",
      "Epoch [13/1000] - Loss: 0.047476 - Valid. (MSE): 0.030867 - Valid. (MAE): 0.127823\n",
      "Epoch [14/1000] - Loss: 0.046947 - Valid. (MSE): 0.030185 - Valid. (MAE): 0.126813\n",
      "Epoch [14/1000] - Loss: 0.049672 - Valid. (MSE): 0.029725 - Valid. (MAE): 0.123275\n",
      "Epoch [15/1000] - Loss: 0.049763 - Valid. (MSE): 0.027585 - Valid. (MAE): 0.120259\n",
      "Epoch [16/1000] - Loss: 0.043769 - Valid. (MSE): 0.027368 - Valid. (MAE): 0.118750\n",
      "Epoch [16/1000] - Loss: 0.041368 - Valid. (MSE): 0.031274 - Valid. (MAE): 0.121439\n",
      "Epoch [17/1000] - Loss: 0.040766 - Valid. (MSE): 0.028133 - Valid. (MAE): 0.117418\n",
      "Epoch [18/1000] - Loss: 0.043655 - Valid. (MSE): 0.025058 - Valid. (MAE): 0.118157\n",
      "Epoch [18/1000] - Loss: 0.043532 - Valid. (MSE): 0.025555 - Valid. (MAE): 0.113778\n",
      "Epoch [19/1000] - Loss: 0.040426 - Valid. (MSE): 0.024585 - Valid. (MAE): 0.114162\n",
      "Epoch [19/1000] - Loss: 0.039215 - Valid. (MSE): 0.024977 - Valid. (MAE): 0.110905\n",
      "Epoch [20/1000] - Loss: 0.034043 - Valid. (MSE): 0.024765 - Valid. (MAE): 0.110674\n",
      "Epoch [21/1000] - Loss: 0.036207 - Valid. (MSE): 0.024482 - Valid. (MAE): 0.110037\n",
      "Epoch [21/1000] - Loss: 0.040743 - Valid. (MSE): 0.023860 - Valid. (MAE): 0.108846\n",
      "Epoch [22/1000] - Loss: 0.036753 - Valid. (MSE): 0.023762 - Valid. (MAE): 0.106980\n",
      "Epoch [23/1000] - Loss: 0.036540 - Valid. (MSE): 0.022849 - Valid. (MAE): 0.109003\n",
      "Epoch [23/1000] - Loss: 0.038855 - Valid. (MSE): 0.022144 - Valid. (MAE): 0.107582\n",
      "Epoch [24/1000] - Loss: 0.036569 - Valid. (MSE): 0.023836 - Valid. (MAE): 0.106848\n",
      "Epoch [24/1000] - Loss: 0.032620 - Valid. (MSE): 0.025067 - Valid. (MAE): 0.108299\n",
      "Epoch [25/1000] - Loss: 0.031162 - Valid. (MSE): 0.022821 - Valid. (MAE): 0.104984\n",
      "Epoch [26/1000] - Loss: 0.034231 - Valid. (MSE): 0.021079 - Valid. (MAE): 0.104997\n",
      "Epoch [26/1000] - Loss: 0.032545 - Valid. (MSE): 0.021365 - Valid. (MAE): 0.103123\n",
      "Epoch [27/1000] - Loss: 0.034409 - Valid. (MSE): 0.021691 - Valid. (MAE): 0.103587\n",
      "Epoch [28/1000] - Loss: 0.031959 - Valid. (MSE): 0.020333 - Valid. (MAE): 0.102328\n",
      "Epoch [28/1000] - Loss: 0.033231 - Valid. (MSE): 0.022459 - Valid. (MAE): 0.104018\n",
      "Epoch [29/1000] - Loss: 0.032397 - Valid. (MSE): 0.021865 - Valid. (MAE): 0.102361\n",
      "Epoch [29/1000] - Loss: 0.032974 - Valid. (MSE): 0.021400 - Valid. (MAE): 0.099628\n",
      "Epoch [30/1000] - Loss: 0.035054 - Valid. (MSE): 0.021033 - Valid. (MAE): 0.102864\n",
      "Epoch [31/1000] - Loss: 0.033615 - Valid. (MSE): 0.019882 - Valid. (MAE): 0.102914\n",
      "Epoch [31/1000] - Loss: 0.033110 - Valid. (MSE): 0.020770 - Valid. (MAE): 0.099506\n",
      "Epoch [32/1000] - Loss: 0.033583 - Valid. (MSE): 0.023314 - Valid. (MAE): 0.103008\n",
      "Epoch [33/1000] - Loss: 0.031809 - Valid. (MSE): 0.019766 - Valid. (MAE): 0.101246\n",
      "Epoch [33/1000] - Loss: 0.031284 - Valid. (MSE): 0.019333 - Valid. (MAE): 0.101532\n",
      "Epoch [34/1000] - Loss: 0.032675 - Valid. (MSE): 0.021953 - Valid. (MAE): 0.101244\n",
      "Epoch [34/1000] - Loss: 0.031426 - Valid. (MSE): 0.020610 - Valid. (MAE): 0.098665\n",
      "Epoch [35/1000] - Loss: 0.027760 - Valid. (MSE): 0.019059 - Valid. (MAE): 0.098868\n",
      "Epoch [36/1000] - Loss: 0.031069 - Valid. (MSE): 0.021767 - Valid. (MAE): 0.100264\n",
      "Epoch [36/1000] - Loss: 0.028708 - Valid. (MSE): 0.020864 - Valid. (MAE): 0.098662\n",
      "Epoch [37/1000] - Loss: 0.030863 - Valid. (MSE): 0.019093 - Valid. (MAE): 0.100041\n",
      "Epoch [38/1000] - Loss: 0.031084 - Valid. (MSE): 0.021256 - Valid. (MAE): 0.098440\n",
      "Epoch [38/1000] - Loss: 0.029396 - Valid. (MSE): 0.019936 - Valid. (MAE): 0.096441\n",
      "Epoch [39/1000] - Loss: 0.030656 - Valid. (MSE): 0.019307 - Valid. (MAE): 0.099906\n",
      "Epoch [39/1000] - Loss: 0.027436 - Valid. (MSE): 0.020020 - Valid. (MAE): 0.097522\n",
      "Epoch [40/1000] - Loss: 0.028772 - Valid. (MSE): 0.019737 - Valid. (MAE): 0.095985\n",
      "Epoch [41/1000] - Loss: 0.030043 - Valid. (MSE): 0.019340 - Valid. (MAE): 0.098468\n",
      "Epoch [41/1000] - Loss: 0.029219 - Valid. (MSE): 0.019337 - Valid. (MAE): 0.095314\n",
      "Epoch [42/1000] - Loss: 0.029074 - Valid. (MSE): 0.020300 - Valid. (MAE): 0.098379\n",
      "Epoch [43/1000] - Loss: 0.027728 - Valid. (MSE): 0.018419 - Valid. (MAE): 0.095724\n",
      "Epoch [43/1000] - Loss: 0.028104 - Valid. (MSE): 0.019244 - Valid. (MAE): 0.094560\n",
      "Epoch [44/1000] - Loss: 0.029944 - Valid. (MSE): 0.019010 - Valid. (MAE): 0.095484\n",
      "Epoch [44/1000] - Loss: 0.029215 - Valid. (MSE): 0.019885 - Valid. (MAE): 0.096188\n",
      "Epoch [45/1000] - Loss: 0.027382 - Valid. (MSE): 0.018486 - Valid. (MAE): 0.095441\n",
      "Epoch [46/1000] - Loss: 0.030814 - Valid. (MSE): 0.019068 - Valid. (MAE): 0.095020\n",
      "Epoch [46/1000] - Loss: 0.027477 - Valid. (MSE): 0.020520 - Valid. (MAE): 0.097215\n",
      "Epoch [47/1000] - Loss: 0.028084 - Valid. (MSE): 0.017931 - Valid. (MAE): 0.094198\n",
      "Epoch [48/1000] - Loss: 0.027295 - Valid. (MSE): 0.018840 - Valid. (MAE): 0.096874\n",
      "Epoch [48/1000] - Loss: 0.027372 - Valid. (MSE): 0.018357 - Valid. (MAE): 0.093093\n",
      "Epoch [49/1000] - Loss: 0.026781 - Valid. (MSE): 0.018557 - Valid. (MAE): 0.096504\n",
      "Epoch [49/1000] - Loss: 0.027628 - Valid. (MSE): 0.021138 - Valid. (MAE): 0.097141\n",
      "Epoch [50/1000] - Loss: 0.028837 - Valid. (MSE): 0.018466 - Valid. (MAE): 0.094689\n",
      "Epoch [51/1000] - Loss: 0.025956 - Valid. (MSE): 0.017952 - Valid. (MAE): 0.095343\n",
      "Epoch [51/1000] - Loss: 0.029272 - Valid. (MSE): 0.019054 - Valid. (MAE): 0.094881\n",
      "Epoch [52/1000] - Loss: 0.027977 - Valid. (MSE): 0.018373 - Valid. (MAE): 0.092137\n",
      "Epoch [53/1000] - Loss: 0.028495 - Valid. (MSE): 0.018215 - Valid. (MAE): 0.098092\n",
      "Epoch [53/1000] - Loss: 0.025754 - Valid. (MSE): 0.019159 - Valid. (MAE): 0.093326\n",
      "Epoch [54/1000] - Loss: 0.031489 - Valid. (MSE): 0.018495 - Valid. (MAE): 0.098034\n",
      "Epoch [54/1000] - Loss: 0.026113 - Valid. (MSE): 0.019125 - Valid. (MAE): 0.093293\n",
      "Epoch [55/1000] - Loss: 0.027352 - Valid. (MSE): 0.017992 - Valid. (MAE): 0.093610\n",
      "Epoch [56/1000] - Loss: 0.027147 - Valid. (MSE): 0.017818 - Valid. (MAE): 0.092183\n",
      "Epoch [56/1000] - Loss: 0.024810 - Valid. (MSE): 0.018942 - Valid. (MAE): 0.094568\n",
      "Epoch [57/1000] - Loss: 0.026307 - Valid. (MSE): 0.018292 - Valid. (MAE): 0.092108\n",
      "Epoch [58/1000] - Loss: 0.026342 - Valid. (MSE): 0.017763 - Valid. (MAE): 0.096009\n",
      "Epoch [58/1000] - Loss: 0.023579 - Valid. (MSE): 0.019496 - Valid. (MAE): 0.094265\n",
      "Epoch [59/1000] - Loss: 0.025470 - Valid. (MSE): 0.017743 - Valid. (MAE): 0.092123\n",
      "Epoch [59/1000] - Loss: 0.026561 - Valid. (MSE): 0.018216 - Valid. (MAE): 0.094005\n",
      "Epoch [60/1000] - Loss: 0.023376 - Valid. (MSE): 0.017863 - Valid. (MAE): 0.094083\n",
      "Epoch [61/1000] - Loss: 0.024953 - Valid. (MSE): 0.018486 - Valid. (MAE): 0.092469\n",
      "Epoch [61/1000] - Loss: 0.027615 - Valid. (MSE): 0.018319 - Valid. (MAE): 0.093642\n",
      "Epoch [62/1000] - Loss: 0.025903 - Valid. (MSE): 0.017420 - Valid. (MAE): 0.092807\n",
      "Epoch [63/1000] - Loss: 0.026491 - Valid. (MSE): 0.018895 - Valid. (MAE): 0.094588\n",
      "Epoch [63/1000] - Loss: 0.024655 - Valid. (MSE): 0.017414 - Valid. (MAE): 0.091267\n",
      "Epoch [64/1000] - Loss: 0.024420 - Valid. (MSE): 0.017874 - Valid. (MAE): 0.093517\n",
      "Epoch [64/1000] - Loss: 0.025750 - Valid. (MSE): 0.018111 - Valid. (MAE): 0.092240\n",
      "Epoch [65/1000] - Loss: 0.023634 - Valid. (MSE): 0.018283 - Valid. (MAE): 0.092602\n",
      "Epoch [66/1000] - Loss: 0.026697 - Valid. (MSE): 0.017725 - Valid. (MAE): 0.093970\n",
      "Epoch [66/1000] - Loss: 0.025233 - Valid. (MSE): 0.018072 - Valid. (MAE): 0.092329\n",
      "Epoch [67/1000] - Loss: 0.026224 - Valid. (MSE): 0.018172 - Valid. (MAE): 0.094283\n",
      "Epoch [68/1000] - Loss: 0.026161 - Valid. (MSE): 0.017164 - Valid. (MAE): 0.091759\n",
      "Epoch [68/1000] - Loss: 0.025291 - Valid. (MSE): 0.019218 - Valid. (MAE): 0.095446\n",
      "Epoch [69/1000] - Loss: 0.024818 - Valid. (MSE): 0.017219 - Valid. (MAE): 0.093462\n",
      "Epoch [69/1000] - Loss: 0.026131 - Valid. (MSE): 0.017853 - Valid. (MAE): 0.091972\n",
      "Epoch [70/1000] - Loss: 0.024933 - Valid. (MSE): 0.018365 - Valid. (MAE): 0.096735\n",
      "Epoch [71/1000] - Loss: 0.026179 - Valid. (MSE): 0.017858 - Valid. (MAE): 0.092339\n",
      "Epoch [71/1000] - Loss: 0.024284 - Valid. (MSE): 0.018255 - Valid. (MAE): 0.094524\n",
      "Epoch [72/1000] - Loss: 0.024140 - Valid. (MSE): 0.017862 - Valid. (MAE): 0.092588\n",
      "Epoch [73/1000] - Loss: 0.027655 - Valid. (MSE): 0.017439 - Valid. (MAE): 0.094026\n",
      "Epoch [73/1000] - Loss: 0.025454 - Valid. (MSE): 0.018474 - Valid. (MAE): 0.092840\n",
      "Epoch [74/1000] - Loss: 0.026350 - Valid. (MSE): 0.017201 - Valid. (MAE): 0.094049\n",
      "Epoch [74/1000] - Loss: 0.024691 - Valid. (MSE): 0.018015 - Valid. (MAE): 0.093711\n",
      "Epoch [75/1000] - Loss: 0.024374 - Valid. (MSE): 0.018423 - Valid. (MAE): 0.092763\n",
      "Epoch [76/1000] - Loss: 0.025023 - Valid. (MSE): 0.017786 - Valid. (MAE): 0.095008\n",
      "Epoch [76/1000] - Loss: 0.024461 - Valid. (MSE): 0.018269 - Valid. (MAE): 0.093645\n",
      "Epoch [77/1000] - Loss: 0.025853 - Valid. (MSE): 0.017482 - Valid. (MAE): 0.093221\n",
      "Epoch [78/1000] - Loss: 0.024860 - Valid. (MSE): 0.017781 - Valid. (MAE): 0.092566\n",
      "Epoch [78/1000] - Loss: 0.022723 - Valid. (MSE): 0.017957 - Valid. (MAE): 0.093442\n",
      "Epoch [79/1000] - Loss: 0.024067 - Valid. (MSE): 0.017563 - Valid. (MAE): 0.093338\n",
      "Epoch [79/1000] - Loss: 0.024389 - Valid. (MSE): 0.018036 - Valid. (MAE): 0.092587\n",
      "Epoch [80/1000] - Loss: 0.025099 - Valid. (MSE): 0.017683 - Valid. (MAE): 0.095237\n",
      "Epoch [81/1000] - Loss: 0.023880 - Valid. (MSE): 0.017606 - Valid. (MAE): 0.090818\n",
      "Epoch [81/1000] - Loss: 0.024426 - Valid. (MSE): 0.017521 - Valid. (MAE): 0.093591\n",
      "Epoch [82/1000] - Loss: 0.024889 - Valid. (MSE): 0.017286 - Valid. (MAE): 0.092299\n",
      "Epoch [83/1000] - Loss: 0.026070 - Valid. (MSE): 0.018461 - Valid. (MAE): 0.091343\n",
      "Epoch [83/1000] - Loss: 0.025203 - Valid. (MSE): 0.017196 - Valid. (MAE): 0.094298\n",
      "Epoch [84/1000] - Loss: 0.024838 - Valid. (MSE): 0.017567 - Valid. (MAE): 0.092732\n",
      "Epoch [84/1000] - Loss: 0.025576 - Valid. (MSE): 0.018526 - Valid. (MAE): 0.094041\n",
      "Epoch [85/1000] - Loss: 0.021797 - Valid. (MSE): 0.017374 - Valid. (MAE): 0.096333\n",
      "Epoch [86/1000] - Loss: 0.025799 - Valid. (MSE): 0.018262 - Valid. (MAE): 0.091360\n",
      "Epoch [86/1000] - Loss: 0.022659 - Valid. (MSE): 0.017546 - Valid. (MAE): 0.096528\n",
      "Epoch [87/1000] - Loss: 0.024548 - Valid. (MSE): 0.018091 - Valid. (MAE): 0.091961\n",
      "Epoch [88/1000] - Loss: 0.024131 - Valid. (MSE): 0.017088 - Valid. (MAE): 0.091743\n",
      "Epoch [88/1000] - Loss: 0.026187 - Valid. (MSE): 0.017449 - Valid. (MAE): 0.092810\n",
      "Epoch [89/1000] - Loss: 0.024091 - Valid. (MSE): 0.017529 - Valid. (MAE): 0.092223\n",
      "Epoch [89/1000] - Loss: 0.023750 - Valid. (MSE): 0.017285 - Valid. (MAE): 0.093534\n",
      "Epoch [90/1000] - Loss: 0.024613 - Valid. (MSE): 0.017265 - Valid. (MAE): 0.091320\n",
      "Epoch [91/1000] - Loss: 0.023940 - Valid. (MSE): 0.017345 - Valid. (MAE): 0.093090\n",
      "Epoch [91/1000] - Loss: 0.023666 - Valid. (MSE): 0.017714 - Valid. (MAE): 0.091399\n",
      "Epoch [92/1000] - Loss: 0.023487 - Valid. (MSE): 0.017259 - Valid. (MAE): 0.092582\n",
      "Epoch [93/1000] - Loss: 0.023718 - Valid. (MSE): 0.017238 - Valid. (MAE): 0.091041\n",
      "Epoch [93/1000] - Loss: 0.022285 - Valid. (MSE): 0.017461 - Valid. (MAE): 0.091497\n",
      "Epoch [94/1000] - Loss: 0.020855 - Valid. (MSE): 0.017079 - Valid. (MAE): 0.093866\n",
      "Epoch [94/1000] - Loss: 0.023836 - Valid. (MSE): 0.017902 - Valid. (MAE): 0.090761\n",
      "Epoch [95/1000] - Loss: 0.023420 - Valid. (MSE): 0.016695 - Valid. (MAE): 0.091841\n",
      "Epoch [96/1000] - Loss: 0.024365 - Valid. (MSE): 0.017828 - Valid. (MAE): 0.092435\n",
      "Epoch [96/1000] - Loss: 0.024131 - Valid. (MSE): 0.017113 - Valid. (MAE): 0.091088\n",
      "Epoch [97/1000] - Loss: 0.022494 - Valid. (MSE): 0.017168 - Valid. (MAE): 0.094754\n",
      "Epoch [98/1000] - Loss: 0.024030 - Valid. (MSE): 0.017149 - Valid. (MAE): 0.090272\n",
      "Epoch [98/1000] - Loss: 0.023373 - Valid. (MSE): 0.017085 - Valid. (MAE): 0.091225\n",
      "Epoch [99/1000] - Loss: 0.024278 - Valid. (MSE): 0.017258 - Valid. (MAE): 0.092837\n",
      "Epoch [99/1000] - Loss: 0.023535 - Valid. (MSE): 0.016794 - Valid. (MAE): 0.090196\n",
      "Epoch [100/1000] - Loss: 0.023606 - Valid. (MSE): 0.017389 - Valid. (MAE): 0.093332\n",
      "Epoch [101/1000] - Loss: 0.024467 - Valid. (MSE): 0.017666 - Valid. (MAE): 0.091253\n",
      "Epoch [101/1000] - Loss: 0.023609 - Valid. (MSE): 0.017246 - Valid. (MAE): 0.091490\n",
      "Epoch [102/1000] - Loss: 0.022388 - Valid. (MSE): 0.017045 - Valid. (MAE): 0.091655\n",
      "Epoch [103/1000] - Loss: 0.023863 - Valid. (MSE): 0.017116 - Valid. (MAE): 0.091090\n",
      "Epoch [103/1000] - Loss: 0.023212 - Valid. (MSE): 0.017405 - Valid. (MAE): 0.092364\n",
      "Epoch [104/1000] - Loss: 0.023548 - Valid. (MSE): 0.017065 - Valid. (MAE): 0.091163\n",
      "Epoch [104/1000] - Loss: 0.023206 - Valid. (MSE): 0.017936 - Valid. (MAE): 0.093197\n",
      "Epoch [105/1000] - Loss: 0.025102 - Valid. (MSE): 0.016993 - Valid. (MAE): 0.090691\n",
      "Epoch [106/1000] - Loss: 0.022878 - Valid. (MSE): 0.016919 - Valid. (MAE): 0.092502\n",
      "Epoch [106/1000] - Loss: 0.024113 - Valid. (MSE): 0.017896 - Valid. (MAE): 0.091786\n",
      "Epoch [107/1000] - Loss: 0.023752 - Valid. (MSE): 0.016914 - Valid. (MAE): 0.091833\n",
      "Epoch [108/1000] - Loss: 0.025260 - Valid. (MSE): 0.016793 - Valid. (MAE): 0.090038\n",
      "Epoch [108/1000] - Loss: 0.024094 - Valid. (MSE): 0.017431 - Valid. (MAE): 0.090991\n",
      "Epoch [109/1000] - Loss: 0.025907 - Valid. (MSE): 0.016866 - Valid. (MAE): 0.091842\n",
      "Epoch [109/1000] - Loss: 0.023022 - Valid. (MSE): 0.017228 - Valid. (MAE): 0.091124\n",
      "Epoch [110/1000] - Loss: 0.022817 - Valid. (MSE): 0.017467 - Valid. (MAE): 0.094152\n",
      "Epoch [111/1000] - Loss: 0.022210 - Valid. (MSE): 0.017317 - Valid. (MAE): 0.091609\n",
      "Epoch [111/1000] - Loss: 0.024940 - Valid. (MSE): 0.016679 - Valid. (MAE): 0.091031\n",
      "Epoch [112/1000] - Loss: 0.022592 - Valid. (MSE): 0.017693 - Valid. (MAE): 0.092158\n",
      "Epoch [113/1000] - Loss: 0.022870 - Valid. (MSE): 0.016803 - Valid. (MAE): 0.089809\n",
      "Epoch [113/1000] - Loss: 0.022562 - Valid. (MSE): 0.016910 - Valid. (MAE): 0.092396\n",
      "Epoch [114/1000] - Loss: 0.023549 - Valid. (MSE): 0.017613 - Valid. (MAE): 0.092243\n",
      "Epoch [114/1000] - Loss: 0.024127 - Valid. (MSE): 0.017219 - Valid. (MAE): 0.091727\n",
      "Epoch [115/1000] - Loss: 0.022140 - Valid. (MSE): 0.016860 - Valid. (MAE): 0.092991\n",
      "Epoch [116/1000] - Loss: 0.024541 - Valid. (MSE): 0.018072 - Valid. (MAE): 0.091513\n",
      "Epoch [116/1000] - Loss: 0.024113 - Valid. (MSE): 0.016903 - Valid. (MAE): 0.091986\n",
      "Epoch [117/1000] - Loss: 0.024199 - Valid. (MSE): 0.018381 - Valid. (MAE): 0.094826\n",
      "Epoch [118/1000] - Loss: 0.024302 - Valid. (MSE): 0.016575 - Valid. (MAE): 0.089825\n",
      "Epoch [118/1000] - Loss: 0.024369 - Valid. (MSE): 0.017478 - Valid. (MAE): 0.093404\n",
      "Epoch [119/1000] - Loss: 0.024758 - Valid. (MSE): 0.017479 - Valid. (MAE): 0.091959\n",
      "Epoch [119/1000] - Loss: 0.021356 - Valid. (MSE): 0.016922 - Valid. (MAE): 0.092999\n",
      "Epoch [120/1000] - Loss: 0.022803 - Valid. (MSE): 0.017411 - Valid. (MAE): 0.091500\n",
      "Epoch [121/1000] - Loss: 0.024091 - Valid. (MSE): 0.017188 - Valid. (MAE): 0.090110\n",
      "Epoch [121/1000] - Loss: 0.021873 - Valid. (MSE): 0.016911 - Valid. (MAE): 0.091795\n",
      "Epoch [122/1000] - Loss: 0.023831 - Valid. (MSE): 0.017414 - Valid. (MAE): 0.092180\n",
      "Epoch [123/1000] - Loss: 0.022898 - Valid. (MSE): 0.016728 - Valid. (MAE): 0.090767\n",
      "Epoch [123/1000] - Loss: 0.024116 - Valid. (MSE): 0.017456 - Valid. (MAE): 0.092603\n",
      "Epoch [124/1000] - Loss: 0.022554 - Valid. (MSE): 0.016758 - Valid. (MAE): 0.090671\n",
      "Epoch [124/1000] - Loss: 0.023331 - Valid. (MSE): 0.017507 - Valid. (MAE): 0.094123\n",
      "Epoch [125/1000] - Loss: 0.021057 - Valid. (MSE): 0.017079 - Valid. (MAE): 0.089618\n",
      "Epoch [126/1000] - Loss: 0.021961 - Valid. (MSE): 0.016937 - Valid. (MAE): 0.091774\n",
      "Epoch [126/1000] - Loss: 0.023259 - Valid. (MSE): 0.016968 - Valid. (MAE): 0.090476\n",
      "Stopping early at epoch 127. Best validation MSE: 0.01669516023688627 at epoch 95.\n",
      "Seed 48 completed:\n",
      "  - Final epoch: 127\n",
      "  - Best epoch: 95\n",
      "  - Training time: 1423.80s\n",
      "  - Test MSE: 0.018000\n",
      "  - Test MAE: 0.093560\n",
      "  - MPE: 0.035402\n",
      "  - Coverage 95%: 0.9254\n",
      "\n",
      "--- Training with seed 49 (8/10) ---\n",
      "Starting training for seed 49...\n",
      "Epoch [0/1000] - Loss: 0.264343 - Valid. (MSE): 0.213889 - Valid. (MAE): 0.398493\n",
      "Epoch [1/1000] - Loss: 0.169174 - Valid. (MSE): 0.084686 - Valid. (MAE): 0.207637\n",
      "Epoch [1/1000] - Loss: 0.151392 - Valid. (MSE): 0.053718 - Valid. (MAE): 0.186966\n",
      "Epoch [2/1000] - Loss: 0.119998 - Valid. (MSE): 0.062797 - Valid. (MAE): 0.179427\n",
      "Epoch [3/1000] - Loss: 0.123524 - Valid. (MSE): 0.066967 - Valid. (MAE): 0.183343\n",
      "Epoch [3/1000] - Loss: 0.109494 - Valid. (MSE): 0.052507 - Valid. (MAE): 0.173073\n",
      "Epoch [4/1000] - Loss: 0.106414 - Valid. (MSE): 0.050479 - Valid. (MAE): 0.173752\n",
      "Epoch [4/1000] - Loss: 0.096524 - Valid. (MSE): 0.054499 - Valid. (MAE): 0.169761\n",
      "Epoch [5/1000] - Loss: 0.092707 - Valid. (MSE): 0.051387 - Valid. (MAE): 0.167265\n",
      "Epoch [6/1000] - Loss: 0.090008 - Valid. (MSE): 0.047893 - Valid. (MAE): 0.166197\n",
      "Epoch [6/1000] - Loss: 0.089116 - Valid. (MSE): 0.050422 - Valid. (MAE): 0.163064\n",
      "Epoch [7/1000] - Loss: 0.083079 - Valid. (MSE): 0.045863 - Valid. (MAE): 0.160891\n",
      "Epoch [8/1000] - Loss: 0.077855 - Valid. (MSE): 0.046182 - Valid. (MAE): 0.156925\n",
      "Epoch [8/1000] - Loss: 0.078707 - Valid. (MSE): 0.043446 - Valid. (MAE): 0.154320\n",
      "Epoch [9/1000] - Loss: 0.071657 - Valid. (MSE): 0.044637 - Valid. (MAE): 0.151649\n",
      "Epoch [9/1000] - Loss: 0.071947 - Valid. (MSE): 0.039981 - Valid. (MAE): 0.151945\n",
      "Epoch [10/1000] - Loss: 0.066756 - Valid. (MSE): 0.044064 - Valid. (MAE): 0.148508\n",
      "Epoch [11/1000] - Loss: 0.068063 - Valid. (MSE): 0.038667 - Valid. (MAE): 0.146238\n",
      "Epoch [11/1000] - Loss: 0.067512 - Valid. (MSE): 0.039958 - Valid. (MAE): 0.142950\n",
      "Epoch [12/1000] - Loss: 0.067749 - Valid. (MSE): 0.037053 - Valid. (MAE): 0.141796\n",
      "Epoch [13/1000] - Loss: 0.063795 - Valid. (MSE): 0.037357 - Valid. (MAE): 0.138934\n",
      "Epoch [13/1000] - Loss: 0.059730 - Valid. (MSE): 0.035428 - Valid. (MAE): 0.137321\n",
      "Epoch [14/1000] - Loss: 0.061724 - Valid. (MSE): 0.034783 - Valid. (MAE): 0.134648\n",
      "Epoch [14/1000] - Loss: 0.059264 - Valid. (MSE): 0.034099 - Valid. (MAE): 0.132221\n",
      "Epoch [15/1000] - Loss: 0.059586 - Valid. (MSE): 0.033612 - Valid. (MAE): 0.130242\n",
      "Epoch [16/1000] - Loss: 0.059025 - Valid. (MSE): 0.031579 - Valid. (MAE): 0.128026\n",
      "Epoch [16/1000] - Loss: 0.060297 - Valid. (MSE): 0.030651 - Valid. (MAE): 0.126156\n",
      "Epoch [17/1000] - Loss: 0.055665 - Valid. (MSE): 0.030069 - Valid. (MAE): 0.124623\n",
      "Epoch [18/1000] - Loss: 0.055129 - Valid. (MSE): 0.030257 - Valid. (MAE): 0.121215\n",
      "Epoch [18/1000] - Loss: 0.054507 - Valid. (MSE): 0.029301 - Valid. (MAE): 0.119154\n",
      "Epoch [19/1000] - Loss: 0.051458 - Valid. (MSE): 0.028908 - Valid. (MAE): 0.117900\n",
      "Epoch [19/1000] - Loss: 0.052329 - Valid. (MSE): 0.027175 - Valid. (MAE): 0.117525\n",
      "Epoch [20/1000] - Loss: 0.053043 - Valid. (MSE): 0.026232 - Valid. (MAE): 0.118527\n",
      "Epoch [21/1000] - Loss: 0.053042 - Valid. (MSE): 0.030032 - Valid. (MAE): 0.117610\n",
      "Epoch [21/1000] - Loss: 0.044877 - Valid. (MSE): 0.028172 - Valid. (MAE): 0.114448\n",
      "Epoch [22/1000] - Loss: 0.049880 - Valid. (MSE): 0.024742 - Valid. (MAE): 0.117250\n",
      "Epoch [23/1000] - Loss: 0.050257 - Valid. (MSE): 0.025306 - Valid. (MAE): 0.113523\n",
      "Epoch [23/1000] - Loss: 0.045644 - Valid. (MSE): 0.028893 - Valid. (MAE): 0.115008\n",
      "Epoch [24/1000] - Loss: 0.049357 - Valid. (MSE): 0.026222 - Valid. (MAE): 0.111495\n",
      "Epoch [24/1000] - Loss: 0.048040 - Valid. (MSE): 0.024053 - Valid. (MAE): 0.110587\n",
      "Epoch [25/1000] - Loss: 0.049447 - Valid. (MSE): 0.023611 - Valid. (MAE): 0.110663\n",
      "Epoch [26/1000] - Loss: 0.047398 - Valid. (MSE): 0.026748 - Valid. (MAE): 0.111122\n",
      "Epoch [26/1000] - Loss: 0.046451 - Valid. (MSE): 0.026168 - Valid. (MAE): 0.109866\n",
      "Epoch [27/1000] - Loss: 0.048311 - Valid. (MSE): 0.022749 - Valid. (MAE): 0.109534\n",
      "Epoch [28/1000] - Loss: 0.045639 - Valid. (MSE): 0.024013 - Valid. (MAE): 0.108685\n",
      "Epoch [28/1000] - Loss: 0.041412 - Valid. (MSE): 0.027987 - Valid. (MAE): 0.113012\n",
      "Epoch [29/1000] - Loss: 0.042026 - Valid. (MSE): 0.022317 - Valid. (MAE): 0.107008\n",
      "Epoch [29/1000] - Loss: 0.044077 - Valid. (MSE): 0.022474 - Valid. (MAE): 0.105718\n",
      "Epoch [30/1000] - Loss: 0.041743 - Valid. (MSE): 0.024501 - Valid. (MAE): 0.106590\n",
      "Epoch [31/1000] - Loss: 0.041349 - Valid. (MSE): 0.022818 - Valid. (MAE): 0.104688\n",
      "Epoch [31/1000] - Loss: 0.040994 - Valid. (MSE): 0.021704 - Valid. (MAE): 0.104363\n",
      "Epoch [32/1000] - Loss: 0.042062 - Valid. (MSE): 0.022725 - Valid. (MAE): 0.104217\n",
      "Epoch [33/1000] - Loss: 0.038773 - Valid. (MSE): 0.023562 - Valid. (MAE): 0.104869\n",
      "Epoch [33/1000] - Loss: 0.042031 - Valid. (MSE): 0.021113 - Valid. (MAE): 0.103636\n",
      "Epoch [34/1000] - Loss: 0.038857 - Valid. (MSE): 0.021287 - Valid. (MAE): 0.101856\n",
      "Epoch [34/1000] - Loss: 0.043652 - Valid. (MSE): 0.021158 - Valid. (MAE): 0.102849\n",
      "Epoch [35/1000] - Loss: 0.041161 - Valid. (MSE): 0.022046 - Valid. (MAE): 0.102448\n",
      "Epoch [36/1000] - Loss: 0.038929 - Valid. (MSE): 0.023014 - Valid. (MAE): 0.103660\n",
      "Epoch [36/1000] - Loss: 0.037271 - Valid. (MSE): 0.022592 - Valid. (MAE): 0.103097\n",
      "Epoch [37/1000] - Loss: 0.039258 - Valid. (MSE): 0.021093 - Valid. (MAE): 0.101958\n",
      "Epoch [38/1000] - Loss: 0.040310 - Valid. (MSE): 0.020786 - Valid. (MAE): 0.100444\n",
      "Epoch [38/1000] - Loss: 0.040286 - Valid. (MSE): 0.021218 - Valid. (MAE): 0.100180\n",
      "Epoch [39/1000] - Loss: 0.038326 - Valid. (MSE): 0.022270 - Valid. (MAE): 0.101568\n",
      "Epoch [39/1000] - Loss: 0.036035 - Valid. (MSE): 0.022713 - Valid. (MAE): 0.102361\n",
      "Epoch [40/1000] - Loss: 0.037477 - Valid. (MSE): 0.020224 - Valid. (MAE): 0.099945\n",
      "Epoch [41/1000] - Loss: 0.039166 - Valid. (MSE): 0.020363 - Valid. (MAE): 0.099203\n",
      "Epoch [41/1000] - Loss: 0.038925 - Valid. (MSE): 0.021808 - Valid. (MAE): 0.101084\n",
      "Epoch [42/1000] - Loss: 0.036277 - Valid. (MSE): 0.020560 - Valid. (MAE): 0.100513\n",
      "Epoch [43/1000] - Loss: 0.035463 - Valid. (MSE): 0.020395 - Valid. (MAE): 0.098748\n",
      "Epoch [43/1000] - Loss: 0.037925 - Valid. (MSE): 0.021393 - Valid. (MAE): 0.100053\n",
      "Epoch [44/1000] - Loss: 0.039255 - Valid. (MSE): 0.020724 - Valid. (MAE): 0.099192\n",
      "Epoch [44/1000] - Loss: 0.039859 - Valid. (MSE): 0.020628 - Valid. (MAE): 0.098828\n",
      "Epoch [45/1000] - Loss: 0.037544 - Valid. (MSE): 0.020302 - Valid. (MAE): 0.099509\n",
      "Epoch [46/1000] - Loss: 0.035144 - Valid. (MSE): 0.020326 - Valid. (MAE): 0.099193\n",
      "Epoch [46/1000] - Loss: 0.037501 - Valid. (MSE): 0.019255 - Valid. (MAE): 0.098357\n",
      "Epoch [47/1000] - Loss: 0.036443 - Valid. (MSE): 0.019766 - Valid. (MAE): 0.098614\n",
      "Epoch [48/1000] - Loss: 0.037369 - Valid. (MSE): 0.021840 - Valid. (MAE): 0.100930\n",
      "Epoch [48/1000] - Loss: 0.034050 - Valid. (MSE): 0.019936 - Valid. (MAE): 0.098456\n",
      "Epoch [49/1000] - Loss: 0.035905 - Valid. (MSE): 0.020830 - Valid. (MAE): 0.099331\n",
      "Epoch [49/1000] - Loss: 0.036413 - Valid. (MSE): 0.020587 - Valid. (MAE): 0.098920\n",
      "Epoch [50/1000] - Loss: 0.037108 - Valid. (MSE): 0.020240 - Valid. (MAE): 0.098669\n",
      "Epoch [51/1000] - Loss: 0.037084 - Valid. (MSE): 0.020839 - Valid. (MAE): 0.099060\n",
      "Epoch [51/1000] - Loss: 0.036752 - Valid. (MSE): 0.020064 - Valid. (MAE): 0.097914\n",
      "Epoch [52/1000] - Loss: 0.035640 - Valid. (MSE): 0.019356 - Valid. (MAE): 0.098219\n",
      "Epoch [53/1000] - Loss: 0.035093 - Valid. (MSE): 0.019669 - Valid. (MAE): 0.097426\n",
      "Epoch [53/1000] - Loss: 0.033935 - Valid. (MSE): 0.020364 - Valid. (MAE): 0.098043\n",
      "Epoch [54/1000] - Loss: 0.035849 - Valid. (MSE): 0.019794 - Valid. (MAE): 0.097625\n",
      "Epoch [54/1000] - Loss: 0.035982 - Valid. (MSE): 0.019679 - Valid. (MAE): 0.097173\n",
      "Epoch [55/1000] - Loss: 0.034960 - Valid. (MSE): 0.019267 - Valid. (MAE): 0.097517\n",
      "Epoch [56/1000] - Loss: 0.032945 - Valid. (MSE): 0.020088 - Valid. (MAE): 0.097678\n",
      "Epoch [56/1000] - Loss: 0.031078 - Valid. (MSE): 0.020036 - Valid. (MAE): 0.097418\n",
      "Epoch [57/1000] - Loss: 0.034750 - Valid. (MSE): 0.019344 - Valid. (MAE): 0.096753\n",
      "Epoch [58/1000] - Loss: 0.030886 - Valid. (MSE): 0.020219 - Valid. (MAE): 0.098408\n",
      "Epoch [58/1000] - Loss: 0.034207 - Valid. (MSE): 0.020197 - Valid. (MAE): 0.097546\n",
      "Epoch [59/1000] - Loss: 0.033860 - Valid. (MSE): 0.019923 - Valid. (MAE): 0.097190\n",
      "Epoch [59/1000] - Loss: 0.032046 - Valid. (MSE): 0.019315 - Valid. (MAE): 0.096678\n",
      "Epoch [60/1000] - Loss: 0.032101 - Valid. (MSE): 0.019114 - Valid. (MAE): 0.096297\n",
      "Epoch [61/1000] - Loss: 0.032709 - Valid. (MSE): 0.020047 - Valid. (MAE): 0.097437\n",
      "Epoch [61/1000] - Loss: 0.033217 - Valid. (MSE): 0.018946 - Valid. (MAE): 0.096940\n",
      "Epoch [62/1000] - Loss: 0.033408 - Valid. (MSE): 0.018871 - Valid. (MAE): 0.096316\n",
      "Epoch [63/1000] - Loss: 0.032039 - Valid. (MSE): 0.020655 - Valid. (MAE): 0.097861\n",
      "Epoch [63/1000] - Loss: 0.034032 - Valid. (MSE): 0.020042 - Valid. (MAE): 0.097126\n",
      "Epoch [64/1000] - Loss: 0.035540 - Valid. (MSE): 0.018714 - Valid. (MAE): 0.098410\n",
      "Epoch [64/1000] - Loss: 0.030903 - Valid. (MSE): 0.020144 - Valid. (MAE): 0.096958\n",
      "Epoch [65/1000] - Loss: 0.032100 - Valid. (MSE): 0.020218 - Valid. (MAE): 0.096981\n",
      "Epoch [66/1000] - Loss: 0.033564 - Valid. (MSE): 0.019154 - Valid. (MAE): 0.096744\n",
      "Epoch [66/1000] - Loss: 0.033509 - Valid. (MSE): 0.018998 - Valid. (MAE): 0.095459\n",
      "Epoch [67/1000] - Loss: 0.032632 - Valid. (MSE): 0.018963 - Valid. (MAE): 0.095616\n",
      "Epoch [68/1000] - Loss: 0.032662 - Valid. (MSE): 0.019032 - Valid. (MAE): 0.095696\n",
      "Epoch [68/1000] - Loss: 0.032282 - Valid. (MSE): 0.020652 - Valid. (MAE): 0.098399\n",
      "Epoch [69/1000] - Loss: 0.030513 - Valid. (MSE): 0.019206 - Valid. (MAE): 0.097758\n",
      "Epoch [69/1000] - Loss: 0.031706 - Valid. (MSE): 0.018416 - Valid. (MAE): 0.095778\n",
      "Epoch [70/1000] - Loss: 0.031515 - Valid. (MSE): 0.019907 - Valid. (MAE): 0.096628\n",
      "Epoch [71/1000] - Loss: 0.034095 - Valid. (MSE): 0.019470 - Valid. (MAE): 0.096220\n",
      "Epoch [71/1000] - Loss: 0.028941 - Valid. (MSE): 0.018370 - Valid. (MAE): 0.097175\n",
      "Epoch [72/1000] - Loss: 0.032847 - Valid. (MSE): 0.020243 - Valid. (MAE): 0.097111\n",
      "Epoch [73/1000] - Loss: 0.031947 - Valid. (MSE): 0.020049 - Valid. (MAE): 0.096999\n",
      "Epoch [73/1000] - Loss: 0.036125 - Valid. (MSE): 0.018444 - Valid. (MAE): 0.095912\n",
      "Epoch [74/1000] - Loss: 0.031227 - Valid. (MSE): 0.019187 - Valid. (MAE): 0.095176\n",
      "Epoch [74/1000] - Loss: 0.032639 - Valid. (MSE): 0.019073 - Valid. (MAE): 0.095533\n",
      "Epoch [75/1000] - Loss: 0.032060 - Valid. (MSE): 0.019058 - Valid. (MAE): 0.095286\n",
      "Epoch [76/1000] - Loss: 0.031355 - Valid. (MSE): 0.018887 - Valid. (MAE): 0.095857\n",
      "Epoch [76/1000] - Loss: 0.031571 - Valid. (MSE): 0.020233 - Valid. (MAE): 0.097537\n",
      "Epoch [77/1000] - Loss: 0.030959 - Valid. (MSE): 0.018747 - Valid. (MAE): 0.095948\n",
      "Epoch [78/1000] - Loss: 0.032776 - Valid. (MSE): 0.018707 - Valid. (MAE): 0.094856\n",
      "Epoch [78/1000] - Loss: 0.029353 - Valid. (MSE): 0.019168 - Valid. (MAE): 0.097387\n",
      "Epoch [79/1000] - Loss: 0.029432 - Valid. (MSE): 0.018796 - Valid. (MAE): 0.095461\n",
      "Epoch [79/1000] - Loss: 0.027730 - Valid. (MSE): 0.018447 - Valid. (MAE): 0.095132\n",
      "Epoch [80/1000] - Loss: 0.032502 - Valid. (MSE): 0.018904 - Valid. (MAE): 0.095442\n",
      "Epoch [81/1000] - Loss: 0.030220 - Valid. (MSE): 0.019127 - Valid. (MAE): 0.095878\n",
      "Epoch [81/1000] - Loss: 0.030419 - Valid. (MSE): 0.018800 - Valid. (MAE): 0.095052\n",
      "Epoch [82/1000] - Loss: 0.029476 - Valid. (MSE): 0.018348 - Valid. (MAE): 0.095140\n",
      "Epoch [83/1000] - Loss: 0.030680 - Valid. (MSE): 0.018817 - Valid. (MAE): 0.095746\n",
      "Epoch [83/1000] - Loss: 0.030393 - Valid. (MSE): 0.019198 - Valid. (MAE): 0.095978\n",
      "Epoch [84/1000] - Loss: 0.029743 - Valid. (MSE): 0.018691 - Valid. (MAE): 0.095095\n",
      "Epoch [84/1000] - Loss: 0.029564 - Valid. (MSE): 0.018798 - Valid. (MAE): 0.094985\n",
      "Epoch [85/1000] - Loss: 0.029389 - Valid. (MSE): 0.019781 - Valid. (MAE): 0.097391\n",
      "Epoch [86/1000] - Loss: 0.026669 - Valid. (MSE): 0.018430 - Valid. (MAE): 0.095345\n",
      "Epoch [86/1000] - Loss: 0.027189 - Valid. (MSE): 0.018158 - Valid. (MAE): 0.096002\n",
      "Epoch [87/1000] - Loss: 0.030096 - Valid. (MSE): 0.020037 - Valid. (MAE): 0.096548\n",
      "Epoch [88/1000] - Loss: 0.030444 - Valid. (MSE): 0.018565 - Valid. (MAE): 0.094757\n",
      "Epoch [88/1000] - Loss: 0.028688 - Valid. (MSE): 0.018338 - Valid. (MAE): 0.095131\n",
      "Epoch [89/1000] - Loss: 0.029327 - Valid. (MSE): 0.018250 - Valid. (MAE): 0.095174\n",
      "Epoch [89/1000] - Loss: 0.030258 - Valid. (MSE): 0.019496 - Valid. (MAE): 0.095728\n",
      "Epoch [90/1000] - Loss: 0.026449 - Valid. (MSE): 0.018378 - Valid. (MAE): 0.095018\n",
      "Epoch [91/1000] - Loss: 0.028193 - Valid. (MSE): 0.018479 - Valid. (MAE): 0.095342\n",
      "Epoch [91/1000] - Loss: 0.026885 - Valid. (MSE): 0.018977 - Valid. (MAE): 0.095003\n",
      "Epoch [92/1000] - Loss: 0.027458 - Valid. (MSE): 0.018061 - Valid. (MAE): 0.094338\n",
      "Epoch [93/1000] - Loss: 0.029731 - Valid. (MSE): 0.019222 - Valid. (MAE): 0.095673\n",
      "Epoch [93/1000] - Loss: 0.030667 - Valid. (MSE): 0.018385 - Valid. (MAE): 0.094690\n",
      "Epoch [94/1000] - Loss: 0.027519 - Valid. (MSE): 0.018838 - Valid. (MAE): 0.095139\n",
      "Epoch [94/1000] - Loss: 0.027495 - Valid. (MSE): 0.018452 - Valid. (MAE): 0.095937\n",
      "Epoch [95/1000] - Loss: 0.027168 - Valid. (MSE): 0.018235 - Valid. (MAE): 0.095016\n",
      "Epoch [96/1000] - Loss: 0.026456 - Valid. (MSE): 0.019872 - Valid. (MAE): 0.096409\n",
      "Epoch [96/1000] - Loss: 0.028588 - Valid. (MSE): 0.018220 - Valid. (MAE): 0.095093\n",
      "Epoch [97/1000] - Loss: 0.026738 - Valid. (MSE): 0.018546 - Valid. (MAE): 0.094491\n",
      "Epoch [98/1000] - Loss: 0.027961 - Valid. (MSE): 0.018398 - Valid. (MAE): 0.094866\n",
      "Epoch [98/1000] - Loss: 0.027394 - Valid. (MSE): 0.018959 - Valid. (MAE): 0.094924\n",
      "Epoch [99/1000] - Loss: 0.027670 - Valid. (MSE): 0.018519 - Valid. (MAE): 0.094672\n",
      "Epoch [99/1000] - Loss: 0.027747 - Valid. (MSE): 0.018842 - Valid. (MAE): 0.094772\n",
      "Epoch [100/1000] - Loss: 0.027935 - Valid. (MSE): 0.018813 - Valid. (MAE): 0.095089\n",
      "Epoch [101/1000] - Loss: 0.027301 - Valid. (MSE): 0.018346 - Valid. (MAE): 0.095994\n",
      "Epoch [101/1000] - Loss: 0.027842 - Valid. (MSE): 0.018929 - Valid. (MAE): 0.094424\n",
      "Epoch [102/1000] - Loss: 0.028392 - Valid. (MSE): 0.018026 - Valid. (MAE): 0.093334\n",
      "Epoch [103/1000] - Loss: 0.027197 - Valid. (MSE): 0.018137 - Valid. (MAE): 0.095156\n",
      "Epoch [103/1000] - Loss: 0.025727 - Valid. (MSE): 0.018775 - Valid. (MAE): 0.094889\n",
      "Epoch [104/1000] - Loss: 0.030693 - Valid. (MSE): 0.018535 - Valid. (MAE): 0.094066\n",
      "Epoch [104/1000] - Loss: 0.028583 - Valid. (MSE): 0.018483 - Valid. (MAE): 0.096554\n",
      "Epoch [105/1000] - Loss: 0.027157 - Valid. (MSE): 0.018735 - Valid. (MAE): 0.094453\n",
      "Epoch [106/1000] - Loss: 0.027813 - Valid. (MSE): 0.018174 - Valid. (MAE): 0.094701\n",
      "Epoch [106/1000] - Loss: 0.027797 - Valid. (MSE): 0.018096 - Valid. (MAE): 0.094388\n",
      "Epoch [107/1000] - Loss: 0.025762 - Valid. (MSE): 0.018585 - Valid. (MAE): 0.094724\n",
      "Epoch [108/1000] - Loss: 0.026701 - Valid. (MSE): 0.017910 - Valid. (MAE): 0.094379\n",
      "Epoch [108/1000] - Loss: 0.027497 - Valid. (MSE): 0.018794 - Valid. (MAE): 0.094572\n",
      "Epoch [109/1000] - Loss: 0.028411 - Valid. (MSE): 0.018205 - Valid. (MAE): 0.095122\n",
      "Epoch [109/1000] - Loss: 0.027343 - Valid. (MSE): 0.018149 - Valid. (MAE): 0.095415\n",
      "Epoch [110/1000] - Loss: 0.027388 - Valid. (MSE): 0.019170 - Valid. (MAE): 0.095142\n",
      "Epoch [111/1000] - Loss: 0.028541 - Valid. (MSE): 0.017735 - Valid. (MAE): 0.094861\n",
      "Epoch [111/1000] - Loss: 0.027349 - Valid. (MSE): 0.018782 - Valid. (MAE): 0.094834\n",
      "Epoch [112/1000] - Loss: 0.026535 - Valid. (MSE): 0.018751 - Valid. (MAE): 0.095006\n",
      "Epoch [113/1000] - Loss: 0.027140 - Valid. (MSE): 0.017673 - Valid. (MAE): 0.094520\n",
      "Epoch [113/1000] - Loss: 0.026044 - Valid. (MSE): 0.018828 - Valid. (MAE): 0.094877\n",
      "Epoch [114/1000] - Loss: 0.026887 - Valid. (MSE): 0.017926 - Valid. (MAE): 0.094476\n",
      "Epoch [114/1000] - Loss: 0.027769 - Valid. (MSE): 0.018761 - Valid. (MAE): 0.094592\n",
      "Epoch [115/1000] - Loss: 0.027062 - Valid. (MSE): 0.018065 - Valid. (MAE): 0.094166\n",
      "Epoch [116/1000] - Loss: 0.024514 - Valid. (MSE): 0.018325 - Valid. (MAE): 0.094276\n",
      "Epoch [116/1000] - Loss: 0.028251 - Valid. (MSE): 0.018515 - Valid. (MAE): 0.094558\n",
      "Epoch [117/1000] - Loss: 0.027739 - Valid. (MSE): 0.018023 - Valid. (MAE): 0.094046\n",
      "Epoch [118/1000] - Loss: 0.028325 - Valid. (MSE): 0.018491 - Valid. (MAE): 0.095103\n",
      "Epoch [118/1000] - Loss: 0.026235 - Valid. (MSE): 0.018001 - Valid. (MAE): 0.094334\n",
      "Epoch [119/1000] - Loss: 0.025853 - Valid. (MSE): 0.018893 - Valid. (MAE): 0.094858\n",
      "Epoch [119/1000] - Loss: 0.026060 - Valid. (MSE): 0.017765 - Valid. (MAE): 0.095922\n",
      "Epoch [120/1000] - Loss: 0.024817 - Valid. (MSE): 0.018892 - Valid. (MAE): 0.094675\n",
      "Epoch [121/1000] - Loss: 0.025801 - Valid. (MSE): 0.018080 - Valid. (MAE): 0.096665\n",
      "Epoch [121/1000] - Loss: 0.025534 - Valid. (MSE): 0.018095 - Valid. (MAE): 0.094161\n",
      "Epoch [122/1000] - Loss: 0.023579 - Valid. (MSE): 0.017859 - Valid. (MAE): 0.093708\n",
      "Epoch [123/1000] - Loss: 0.025113 - Valid. (MSE): 0.018636 - Valid. (MAE): 0.095886\n",
      "Epoch [123/1000] - Loss: 0.023386 - Valid. (MSE): 0.018301 - Valid. (MAE): 0.094542\n",
      "Epoch [124/1000] - Loss: 0.024709 - Valid. (MSE): 0.018136 - Valid. (MAE): 0.093823\n",
      "Epoch [124/1000] - Loss: 0.028006 - Valid. (MSE): 0.018097 - Valid. (MAE): 0.094455\n",
      "Epoch [125/1000] - Loss: 0.024353 - Valid. (MSE): 0.018320 - Valid. (MAE): 0.094103\n",
      "Epoch [126/1000] - Loss: 0.025499 - Valid. (MSE): 0.018184 - Valid. (MAE): 0.093839\n",
      "Epoch [126/1000] - Loss: 0.027022 - Valid. (MSE): 0.017766 - Valid. (MAE): 0.095888\n",
      "Epoch [127/1000] - Loss: 0.025214 - Valid. (MSE): 0.018952 - Valid. (MAE): 0.094970\n",
      "Epoch [128/1000] - Loss: 0.025581 - Valid. (MSE): 0.018180 - Valid. (MAE): 0.095522\n",
      "Epoch [128/1000] - Loss: 0.024143 - Valid. (MSE): 0.018051 - Valid. (MAE): 0.095427\n",
      "Epoch [129/1000] - Loss: 0.024053 - Valid. (MSE): 0.019010 - Valid. (MAE): 0.095173\n",
      "Epoch [129/1000] - Loss: 0.026909 - Valid. (MSE): 0.017829 - Valid. (MAE): 0.096382\n",
      "Epoch [130/1000] - Loss: 0.022743 - Valid. (MSE): 0.018729 - Valid. (MAE): 0.094355\n",
      "Epoch [131/1000] - Loss: 0.025961 - Valid. (MSE): 0.017962 - Valid. (MAE): 0.095822\n",
      "Epoch [131/1000] - Loss: 0.026594 - Valid. (MSE): 0.018250 - Valid. (MAE): 0.094627\n",
      "Epoch [132/1000] - Loss: 0.025515 - Valid. (MSE): 0.018098 - Valid. (MAE): 0.094031\n",
      "Epoch [133/1000] - Loss: 0.025424 - Valid. (MSE): 0.018028 - Valid. (MAE): 0.094676\n",
      "Epoch [133/1000] - Loss: 0.025762 - Valid. (MSE): 0.018214 - Valid. (MAE): 0.094783\n",
      "Epoch [134/1000] - Loss: 0.025296 - Valid. (MSE): 0.018078 - Valid. (MAE): 0.095103\n",
      "Epoch [134/1000] - Loss: 0.023724 - Valid. (MSE): 0.018139 - Valid. (MAE): 0.094805\n",
      "Epoch [135/1000] - Loss: 0.022975 - Valid. (MSE): 0.017926 - Valid. (MAE): 0.094346\n",
      "Epoch [136/1000] - Loss: 0.027290 - Valid. (MSE): 0.018040 - Valid. (MAE): 0.094028\n",
      "Epoch [136/1000] - Loss: 0.023844 - Valid. (MSE): 0.018324 - Valid. (MAE): 0.094849\n",
      "Epoch [137/1000] - Loss: 0.026109 - Valid. (MSE): 0.017983 - Valid. (MAE): 0.094528\n",
      "Epoch [138/1000] - Loss: 0.028404 - Valid. (MSE): 0.018285 - Valid. (MAE): 0.094602\n",
      "Epoch [138/1000] - Loss: 0.023778 - Valid. (MSE): 0.017852 - Valid. (MAE): 0.094412\n",
      "Epoch [139/1000] - Loss: 0.025435 - Valid. (MSE): 0.018211 - Valid. (MAE): 0.093990\n",
      "Epoch [139/1000] - Loss: 0.024614 - Valid. (MSE): 0.018099 - Valid. (MAE): 0.094831\n",
      "Epoch [140/1000] - Loss: 0.023803 - Valid. (MSE): 0.018017 - Valid. (MAE): 0.095064\n",
      "Epoch [141/1000] - Loss: 0.023693 - Valid. (MSE): 0.018259 - Valid. (MAE): 0.094321\n",
      "Epoch [141/1000] - Loss: 0.024983 - Valid. (MSE): 0.017791 - Valid. (MAE): 0.094909\n",
      "Epoch [142/1000] - Loss: 0.026786 - Valid. (MSE): 0.017640 - Valid. (MAE): 0.094989\n",
      "Epoch [143/1000] - Loss: 0.024346 - Valid. (MSE): 0.018335 - Valid. (MAE): 0.094264\n",
      "Epoch [143/1000] - Loss: 0.025003 - Valid. (MSE): 0.017927 - Valid. (MAE): 0.094800\n",
      "Epoch [144/1000] - Loss: 0.025221 - Valid. (MSE): 0.018068 - Valid. (MAE): 0.094195\n",
      "Stopping early at epoch 144. Best validation MSE: 0.017672739405319587 at epoch 113.\n",
      "Seed 49 completed:\n",
      "  - Final epoch: 144\n",
      "  - Best epoch: 113\n",
      "  - Training time: 1781.84s\n",
      "  - Test MSE: 0.017321\n",
      "  - Test MAE: 0.091598\n",
      "  - MPE: 0.034617\n",
      "  - Coverage 95%: 0.9370\n",
      "\n",
      "--- Training with seed 50 (9/10) ---\n",
      "Starting training for seed 50...\n",
      "Epoch [0/1000] - Loss: 0.168804 - Valid. (MSE): 0.128587 - Valid. (MAE): 0.275406\n",
      "Epoch [1/1000] - Loss: 0.124087 - Valid. (MSE): 0.063839 - Valid. (MAE): 0.181865\n",
      "Epoch [1/1000] - Loss: 0.117196 - Valid. (MSE): 0.064136 - Valid. (MAE): 0.181677\n",
      "Epoch [2/1000] - Loss: 0.100594 - Valid. (MSE): 0.072981 - Valid. (MAE): 0.191737\n",
      "Epoch [3/1000] - Loss: 0.096268 - Valid. (MSE): 0.061476 - Valid. (MAE): 0.178043\n",
      "Epoch [3/1000] - Loss: 0.087943 - Valid. (MSE): 0.058507 - Valid. (MAE): 0.174481\n",
      "Epoch [4/1000] - Loss: 0.082438 - Valid. (MSE): 0.056600 - Valid. (MAE): 0.172009\n",
      "Epoch [4/1000] - Loss: 0.082269 - Valid. (MSE): 0.053248 - Valid. (MAE): 0.168725\n",
      "Epoch [5/1000] - Loss: 0.082311 - Valid. (MSE): 0.051017 - Valid. (MAE): 0.165921\n",
      "Epoch [6/1000] - Loss: 0.078145 - Valid. (MSE): 0.050783 - Valid. (MAE): 0.163412\n",
      "Epoch [6/1000] - Loss: 0.075842 - Valid. (MSE): 0.047372 - Valid. (MAE): 0.159807\n",
      "Epoch [7/1000] - Loss: 0.068542 - Valid. (MSE): 0.048202 - Valid. (MAE): 0.158367\n",
      "Epoch [8/1000] - Loss: 0.071399 - Valid. (MSE): 0.043672 - Valid. (MAE): 0.153972\n",
      "Epoch [8/1000] - Loss: 0.066455 - Valid. (MSE): 0.045228 - Valid. (MAE): 0.152812\n",
      "Epoch [9/1000] - Loss: 0.063708 - Valid. (MSE): 0.040582 - Valid. (MAE): 0.148028\n",
      "Epoch [9/1000] - Loss: 0.061366 - Valid. (MSE): 0.040912 - Valid. (MAE): 0.145846\n",
      "Epoch [10/1000] - Loss: 0.063368 - Valid. (MSE): 0.042362 - Valid. (MAE): 0.145857\n",
      "Epoch [11/1000] - Loss: 0.056252 - Valid. (MSE): 0.036898 - Valid. (MAE): 0.140586\n",
      "Epoch [11/1000] - Loss: 0.061582 - Valid. (MSE): 0.037391 - Valid. (MAE): 0.138497\n",
      "Epoch [12/1000] - Loss: 0.056484 - Valid. (MSE): 0.037189 - Valid. (MAE): 0.136634\n",
      "Epoch [13/1000] - Loss: 0.055732 - Valid. (MSE): 0.034006 - Valid. (MAE): 0.132315\n",
      "Epoch [13/1000] - Loss: 0.050903 - Valid. (MSE): 0.034335 - Valid. (MAE): 0.130620\n",
      "Epoch [14/1000] - Loss: 0.049295 - Valid. (MSE): 0.034142 - Valid. (MAE): 0.129409\n",
      "Epoch [14/1000] - Loss: 0.049973 - Valid. (MSE): 0.031033 - Valid. (MAE): 0.125559\n",
      "Epoch [15/1000] - Loss: 0.049490 - Valid. (MSE): 0.029724 - Valid. (MAE): 0.124167\n",
      "Epoch [16/1000] - Loss: 0.049359 - Valid. (MSE): 0.031923 - Valid. (MAE): 0.124349\n",
      "Epoch [16/1000] - Loss: 0.048625 - Valid. (MSE): 0.035818 - Valid. (MAE): 0.130643\n",
      "Epoch [17/1000] - Loss: 0.048229 - Valid. (MSE): 0.028855 - Valid. (MAE): 0.120818\n",
      "Epoch [18/1000] - Loss: 0.048173 - Valid. (MSE): 0.028754 - Valid. (MAE): 0.120910\n",
      "Epoch [18/1000] - Loss: 0.046351 - Valid. (MSE): 0.033385 - Valid. (MAE): 0.127189\n",
      "Epoch [19/1000] - Loss: 0.048005 - Valid. (MSE): 0.027454 - Valid. (MAE): 0.119245\n",
      "Epoch [19/1000] - Loss: 0.042420 - Valid. (MSE): 0.026487 - Valid. (MAE): 0.117357\n",
      "Epoch [20/1000] - Loss: 0.042702 - Valid. (MSE): 0.028241 - Valid. (MAE): 0.117555\n",
      "Epoch [21/1000] - Loss: 0.047290 - Valid. (MSE): 0.028297 - Valid. (MAE): 0.116330\n",
      "Epoch [21/1000] - Loss: 0.041832 - Valid. (MSE): 0.026582 - Valid. (MAE): 0.114077\n",
      "Epoch [22/1000] - Loss: 0.041510 - Valid. (MSE): 0.025390 - Valid. (MAE): 0.112905\n",
      "Epoch [23/1000] - Loss: 0.041020 - Valid. (MSE): 0.025558 - Valid. (MAE): 0.112399\n",
      "Epoch [23/1000] - Loss: 0.039487 - Valid. (MSE): 0.026697 - Valid. (MAE): 0.113732\n",
      "Epoch [24/1000] - Loss: 0.039144 - Valid. (MSE): 0.026295 - Valid. (MAE): 0.112927\n",
      "Epoch [24/1000] - Loss: 0.040576 - Valid. (MSE): 0.024053 - Valid. (MAE): 0.111597\n",
      "Epoch [25/1000] - Loss: 0.038188 - Valid. (MSE): 0.027793 - Valid. (MAE): 0.114509\n",
      "Epoch [26/1000] - Loss: 0.039796 - Valid. (MSE): 0.026927 - Valid. (MAE): 0.113682\n",
      "Epoch [26/1000] - Loss: 0.041699 - Valid. (MSE): 0.024396 - Valid. (MAE): 0.109989\n",
      "Epoch [27/1000] - Loss: 0.035780 - Valid. (MSE): 0.023340 - Valid. (MAE): 0.109332\n",
      "Epoch [28/1000] - Loss: 0.039286 - Valid. (MSE): 0.027440 - Valid. (MAE): 0.113473\n",
      "Epoch [28/1000] - Loss: 0.040605 - Valid. (MSE): 0.026473 - Valid. (MAE): 0.111267\n",
      "Epoch [29/1000] - Loss: 0.038761 - Valid. (MSE): 0.023034 - Valid. (MAE): 0.106577\n",
      "Epoch [29/1000] - Loss: 0.036435 - Valid. (MSE): 0.021924 - Valid. (MAE): 0.107278\n",
      "Epoch [30/1000] - Loss: 0.038118 - Valid. (MSE): 0.025854 - Valid. (MAE): 0.110214\n",
      "Epoch [31/1000] - Loss: 0.039472 - Valid. (MSE): 0.023782 - Valid. (MAE): 0.107244\n",
      "Epoch [31/1000] - Loss: 0.035414 - Valid. (MSE): 0.021781 - Valid. (MAE): 0.107926\n",
      "Epoch [32/1000] - Loss: 0.038099 - Valid. (MSE): 0.026083 - Valid. (MAE): 0.110226\n",
      "Epoch [33/1000] - Loss: 0.039426 - Valid. (MSE): 0.023267 - Valid. (MAE): 0.105710\n",
      "Epoch [33/1000] - Loss: 0.033155 - Valid. (MSE): 0.022438 - Valid. (MAE): 0.104041\n",
      "Epoch [34/1000] - Loss: 0.034960 - Valid. (MSE): 0.023212 - Valid. (MAE): 0.104456\n",
      "Epoch [34/1000] - Loss: 0.035659 - Valid. (MSE): 0.023170 - Valid. (MAE): 0.104394\n",
      "Epoch [35/1000] - Loss: 0.035192 - Valid. (MSE): 0.022511 - Valid. (MAE): 0.103556\n",
      "Epoch [36/1000] - Loss: 0.033050 - Valid. (MSE): 0.023960 - Valid. (MAE): 0.105361\n",
      "Epoch [36/1000] - Loss: 0.035226 - Valid. (MSE): 0.021279 - Valid. (MAE): 0.103034\n",
      "Epoch [37/1000] - Loss: 0.032952 - Valid. (MSE): 0.021778 - Valid. (MAE): 0.102332\n",
      "Epoch [38/1000] - Loss: 0.033397 - Valid. (MSE): 0.022456 - Valid. (MAE): 0.103131\n",
      "Epoch [38/1000] - Loss: 0.034591 - Valid. (MSE): 0.021814 - Valid. (MAE): 0.102342\n",
      "Epoch [39/1000] - Loss: 0.033356 - Valid. (MSE): 0.021815 - Valid. (MAE): 0.102042\n",
      "Epoch [39/1000] - Loss: 0.033776 - Valid. (MSE): 0.021262 - Valid. (MAE): 0.100993\n",
      "Epoch [40/1000] - Loss: 0.033758 - Valid. (MSE): 0.022090 - Valid. (MAE): 0.101570\n",
      "Epoch [41/1000] - Loss: 0.032464 - Valid. (MSE): 0.021679 - Valid. (MAE): 0.101160\n",
      "Epoch [41/1000] - Loss: 0.030183 - Valid. (MSE): 0.021284 - Valid. (MAE): 0.100613\n",
      "Epoch [42/1000] - Loss: 0.033167 - Valid. (MSE): 0.020372 - Valid. (MAE): 0.099518\n",
      "Epoch [43/1000] - Loss: 0.030118 - Valid. (MSE): 0.021955 - Valid. (MAE): 0.102892\n",
      "Epoch [43/1000] - Loss: 0.029984 - Valid. (MSE): 0.022009 - Valid. (MAE): 0.101503\n",
      "Epoch [44/1000] - Loss: 0.033456 - Valid. (MSE): 0.021428 - Valid. (MAE): 0.100650\n",
      "Epoch [44/1000] - Loss: 0.032505 - Valid. (MSE): 0.020825 - Valid. (MAE): 0.101371\n",
      "Epoch [45/1000] - Loss: 0.031170 - Valid. (MSE): 0.021955 - Valid. (MAE): 0.100875\n",
      "Epoch [46/1000] - Loss: 0.029912 - Valid. (MSE): 0.020814 - Valid. (MAE): 0.099162\n",
      "Epoch [46/1000] - Loss: 0.031404 - Valid. (MSE): 0.019875 - Valid. (MAE): 0.098606\n",
      "Epoch [47/1000] - Loss: 0.030371 - Valid. (MSE): 0.020664 - Valid. (MAE): 0.098849\n",
      "Epoch [48/1000] - Loss: 0.031980 - Valid. (MSE): 0.020140 - Valid. (MAE): 0.098464\n",
      "Epoch [48/1000] - Loss: 0.031648 - Valid. (MSE): 0.020132 - Valid. (MAE): 0.099933\n",
      "Epoch [49/1000] - Loss: 0.031314 - Valid. (MSE): 0.021141 - Valid. (MAE): 0.099228\n",
      "Epoch [49/1000] - Loss: 0.029796 - Valid. (MSE): 0.022062 - Valid. (MAE): 0.100947\n",
      "Epoch [50/1000] - Loss: 0.032756 - Valid. (MSE): 0.019621 - Valid. (MAE): 0.099088\n",
      "Epoch [51/1000] - Loss: 0.030547 - Valid. (MSE): 0.019885 - Valid. (MAE): 0.098775\n",
      "Epoch [51/1000] - Loss: 0.031626 - Valid. (MSE): 0.022501 - Valid. (MAE): 0.102258\n",
      "Epoch [52/1000] - Loss: 0.030490 - Valid. (MSE): 0.020950 - Valid. (MAE): 0.099108\n",
      "Epoch [53/1000] - Loss: 0.031454 - Valid. (MSE): 0.019258 - Valid. (MAE): 0.098999\n",
      "Epoch [53/1000] - Loss: 0.032203 - Valid. (MSE): 0.019031 - Valid. (MAE): 0.097444\n",
      "Epoch [54/1000] - Loss: 0.029480 - Valid. (MSE): 0.020833 - Valid. (MAE): 0.098573\n",
      "Epoch [54/1000] - Loss: 0.028135 - Valid. (MSE): 0.020342 - Valid. (MAE): 0.098971\n",
      "Epoch [55/1000] - Loss: 0.028521 - Valid. (MSE): 0.019975 - Valid. (MAE): 0.097469\n",
      "Epoch [56/1000] - Loss: 0.029384 - Valid. (MSE): 0.019799 - Valid. (MAE): 0.098164\n",
      "Epoch [56/1000] - Loss: 0.029212 - Valid. (MSE): 0.018905 - Valid. (MAE): 0.097601\n",
      "Epoch [57/1000] - Loss: 0.028973 - Valid. (MSE): 0.020189 - Valid. (MAE): 0.097560\n",
      "Epoch [58/1000] - Loss: 0.030430 - Valid. (MSE): 0.021361 - Valid. (MAE): 0.099464\n",
      "Epoch [58/1000] - Loss: 0.028833 - Valid. (MSE): 0.020179 - Valid. (MAE): 0.097034\n",
      "Epoch [59/1000] - Loss: 0.027655 - Valid. (MSE): 0.019565 - Valid. (MAE): 0.098249\n",
      "Epoch [59/1000] - Loss: 0.027740 - Valid. (MSE): 0.019909 - Valid. (MAE): 0.096732\n",
      "Epoch [60/1000] - Loss: 0.027981 - Valid. (MSE): 0.019467 - Valid. (MAE): 0.096874\n",
      "Epoch [61/1000] - Loss: 0.027721 - Valid. (MSE): 0.020077 - Valid. (MAE): 0.097152\n",
      "Epoch [61/1000] - Loss: 0.029420 - Valid. (MSE): 0.020893 - Valid. (MAE): 0.098448\n",
      "Epoch [62/1000] - Loss: 0.029487 - Valid. (MSE): 0.019034 - Valid. (MAE): 0.097807\n",
      "Epoch [63/1000] - Loss: 0.029024 - Valid. (MSE): 0.019561 - Valid. (MAE): 0.096237\n",
      "Epoch [63/1000] - Loss: 0.027797 - Valid. (MSE): 0.019824 - Valid. (MAE): 0.096721\n",
      "Epoch [64/1000] - Loss: 0.028663 - Valid. (MSE): 0.019285 - Valid. (MAE): 0.096972\n",
      "Epoch [64/1000] - Loss: 0.028472 - Valid. (MSE): 0.018952 - Valid. (MAE): 0.096009\n",
      "Epoch [65/1000] - Loss: 0.026614 - Valid. (MSE): 0.019478 - Valid. (MAE): 0.096090\n",
      "Epoch [66/1000] - Loss: 0.027369 - Valid. (MSE): 0.020208 - Valid. (MAE): 0.097306\n",
      "Epoch [66/1000] - Loss: 0.028944 - Valid. (MSE): 0.019328 - Valid. (MAE): 0.095641\n",
      "Epoch [67/1000] - Loss: 0.028661 - Valid. (MSE): 0.019986 - Valid. (MAE): 0.096567\n",
      "Epoch [68/1000] - Loss: 0.028129 - Valid. (MSE): 0.019631 - Valid. (MAE): 0.096183\n",
      "Epoch [68/1000] - Loss: 0.028387 - Valid. (MSE): 0.019285 - Valid. (MAE): 0.096614\n",
      "Epoch [69/1000] - Loss: 0.027079 - Valid. (MSE): 0.018966 - Valid. (MAE): 0.095594\n",
      "Epoch [69/1000] - Loss: 0.028165 - Valid. (MSE): 0.019712 - Valid. (MAE): 0.095772\n",
      "Epoch [70/1000] - Loss: 0.026957 - Valid. (MSE): 0.021127 - Valid. (MAE): 0.098321\n",
      "Epoch [71/1000] - Loss: 0.028467 - Valid. (MSE): 0.018296 - Valid. (MAE): 0.095096\n",
      "Epoch [71/1000] - Loss: 0.028261 - Valid. (MSE): 0.019614 - Valid. (MAE): 0.098049\n",
      "Epoch [72/1000] - Loss: 0.025693 - Valid. (MSE): 0.019485 - Valid. (MAE): 0.095654\n",
      "Epoch [73/1000] - Loss: 0.026723 - Valid. (MSE): 0.018859 - Valid. (MAE): 0.096877\n",
      "Epoch [73/1000] - Loss: 0.030641 - Valid. (MSE): 0.019851 - Valid. (MAE): 0.096618\n",
      "Epoch [74/1000] - Loss: 0.026321 - Valid. (MSE): 0.019862 - Valid. (MAE): 0.096012\n",
      "Epoch [74/1000] - Loss: 0.026962 - Valid. (MSE): 0.019064 - Valid. (MAE): 0.096349\n",
      "Epoch [75/1000] - Loss: 0.027015 - Valid. (MSE): 0.018609 - Valid. (MAE): 0.094592\n",
      "Epoch [76/1000] - Loss: 0.026502 - Valid. (MSE): 0.019428 - Valid. (MAE): 0.096233\n",
      "Epoch [76/1000] - Loss: 0.027206 - Valid. (MSE): 0.019169 - Valid. (MAE): 0.095265\n",
      "Epoch [77/1000] - Loss: 0.026792 - Valid. (MSE): 0.019681 - Valid. (MAE): 0.097067\n",
      "Epoch [78/1000] - Loss: 0.027173 - Valid. (MSE): 0.019209 - Valid. (MAE): 0.094674\n",
      "Epoch [78/1000] - Loss: 0.026802 - Valid. (MSE): 0.018967 - Valid. (MAE): 0.095653\n",
      "Epoch [79/1000] - Loss: 0.026191 - Valid. (MSE): 0.018865 - Valid. (MAE): 0.094770\n",
      "Epoch [79/1000] - Loss: 0.026876 - Valid. (MSE): 0.018888 - Valid. (MAE): 0.095532\n",
      "Epoch [80/1000] - Loss: 0.025851 - Valid. (MSE): 0.019304 - Valid. (MAE): 0.095277\n",
      "Epoch [81/1000] - Loss: 0.026374 - Valid. (MSE): 0.018974 - Valid. (MAE): 0.094507\n",
      "Epoch [81/1000] - Loss: 0.025994 - Valid. (MSE): 0.019204 - Valid. (MAE): 0.094967\n",
      "Epoch [82/1000] - Loss: 0.024814 - Valid. (MSE): 0.019676 - Valid. (MAE): 0.096236\n",
      "Epoch [83/1000] - Loss: 0.026873 - Valid. (MSE): 0.018334 - Valid. (MAE): 0.093970\n",
      "Epoch [83/1000] - Loss: 0.024918 - Valid. (MSE): 0.019030 - Valid. (MAE): 0.096124\n",
      "Epoch [84/1000] - Loss: 0.026652 - Valid. (MSE): 0.018803 - Valid. (MAE): 0.095970\n",
      "Epoch [84/1000] - Loss: 0.024616 - Valid. (MSE): 0.019622 - Valid. (MAE): 0.095635\n",
      "Epoch [85/1000] - Loss: 0.025351 - Valid. (MSE): 0.018776 - Valid. (MAE): 0.095122\n",
      "Epoch [86/1000] - Loss: 0.026912 - Valid. (MSE): 0.019213 - Valid. (MAE): 0.094859\n",
      "Epoch [86/1000] - Loss: 0.024381 - Valid. (MSE): 0.018724 - Valid. (MAE): 0.095427\n",
      "Epoch [87/1000] - Loss: 0.026157 - Valid. (MSE): 0.018505 - Valid. (MAE): 0.094980\n",
      "Epoch [88/1000] - Loss: 0.026233 - Valid. (MSE): 0.020194 - Valid. (MAE): 0.096805\n",
      "Epoch [88/1000] - Loss: 0.029012 - Valid. (MSE): 0.018617 - Valid. (MAE): 0.094980\n",
      "Epoch [89/1000] - Loss: 0.026011 - Valid. (MSE): 0.018147 - Valid. (MAE): 0.094308\n",
      "Epoch [89/1000] - Loss: 0.026185 - Valid. (MSE): 0.018998 - Valid. (MAE): 0.094457\n",
      "Epoch [90/1000] - Loss: 0.022933 - Valid. (MSE): 0.019709 - Valid. (MAE): 0.095625\n",
      "Epoch [91/1000] - Loss: 0.027252 - Valid. (MSE): 0.017983 - Valid. (MAE): 0.094597\n",
      "Epoch [91/1000] - Loss: 0.026027 - Valid. (MSE): 0.019531 - Valid. (MAE): 0.096039\n",
      "Epoch [92/1000] - Loss: 0.026197 - Valid. (MSE): 0.018698 - Valid. (MAE): 0.094033\n",
      "Epoch [93/1000] - Loss: 0.026151 - Valid. (MSE): 0.018601 - Valid. (MAE): 0.096009\n",
      "Epoch [93/1000] - Loss: 0.026829 - Valid. (MSE): 0.018311 - Valid. (MAE): 0.093513\n",
      "Epoch [94/1000] - Loss: 0.025636 - Valid. (MSE): 0.018918 - Valid. (MAE): 0.094691\n",
      "Epoch [94/1000] - Loss: 0.024704 - Valid. (MSE): 0.018356 - Valid. (MAE): 0.095146\n",
      "Epoch [95/1000] - Loss: 0.025090 - Valid. (MSE): 0.018721 - Valid. (MAE): 0.093689\n",
      "Epoch [96/1000] - Loss: 0.025946 - Valid. (MSE): 0.018973 - Valid. (MAE): 0.097373\n",
      "Epoch [96/1000] - Loss: 0.026027 - Valid. (MSE): 0.018852 - Valid. (MAE): 0.093990\n",
      "Epoch [97/1000] - Loss: 0.026106 - Valid. (MSE): 0.018884 - Valid. (MAE): 0.094792\n",
      "Epoch [98/1000] - Loss: 0.025722 - Valid. (MSE): 0.018382 - Valid. (MAE): 0.095309\n",
      "Epoch [98/1000] - Loss: 0.026852 - Valid. (MSE): 0.018980 - Valid. (MAE): 0.095641\n",
      "Epoch [99/1000] - Loss: 0.025940 - Valid. (MSE): 0.019313 - Valid. (MAE): 0.095303\n",
      "Epoch [99/1000] - Loss: 0.023484 - Valid. (MSE): 0.018219 - Valid. (MAE): 0.096325\n",
      "Epoch [100/1000] - Loss: 0.025632 - Valid. (MSE): 0.018743 - Valid. (MAE): 0.094647\n",
      "Epoch [101/1000] - Loss: 0.023041 - Valid. (MSE): 0.019090 - Valid. (MAE): 0.094441\n",
      "Epoch [101/1000] - Loss: 0.023836 - Valid. (MSE): 0.018188 - Valid. (MAE): 0.093916\n",
      "Epoch [102/1000] - Loss: 0.023630 - Valid. (MSE): 0.018865 - Valid. (MAE): 0.094963\n",
      "Epoch [103/1000] - Loss: 0.024641 - Valid. (MSE): 0.018105 - Valid. (MAE): 0.093465\n",
      "Epoch [103/1000] - Loss: 0.025554 - Valid. (MSE): 0.018897 - Valid. (MAE): 0.095360\n",
      "Epoch [104/1000] - Loss: 0.025110 - Valid. (MSE): 0.018514 - Valid. (MAE): 0.093665\n",
      "Epoch [104/1000] - Loss: 0.025945 - Valid. (MSE): 0.017877 - Valid. (MAE): 0.095710\n",
      "Epoch [105/1000] - Loss: 0.025753 - Valid. (MSE): 0.019189 - Valid. (MAE): 0.094413\n",
      "Epoch [106/1000] - Loss: 0.024962 - Valid. (MSE): 0.017771 - Valid. (MAE): 0.091926\n",
      "Epoch [106/1000] - Loss: 0.024987 - Valid. (MSE): 0.018508 - Valid. (MAE): 0.097570\n",
      "Epoch [107/1000] - Loss: 0.026490 - Valid. (MSE): 0.019200 - Valid. (MAE): 0.094961\n",
      "Epoch [108/1000] - Loss: 0.025932 - Valid. (MSE): 0.018233 - Valid. (MAE): 0.094455\n",
      "Epoch [108/1000] - Loss: 0.024756 - Valid. (MSE): 0.018543 - Valid. (MAE): 0.095362\n",
      "Epoch [109/1000] - Loss: 0.024952 - Valid. (MSE): 0.018107 - Valid. (MAE): 0.093148\n",
      "Epoch [109/1000] - Loss: 0.022864 - Valid. (MSE): 0.019119 - Valid. (MAE): 0.095444\n",
      "Epoch [110/1000] - Loss: 0.025359 - Valid. (MSE): 0.018185 - Valid. (MAE): 0.095138\n",
      "Epoch [111/1000] - Loss: 0.025639 - Valid. (MSE): 0.018025 - Valid. (MAE): 0.093507\n",
      "Epoch [111/1000] - Loss: 0.023350 - Valid. (MSE): 0.019793 - Valid. (MAE): 0.097038\n",
      "Epoch [112/1000] - Loss: 0.026168 - Valid. (MSE): 0.017707 - Valid. (MAE): 0.093529\n",
      "Epoch [113/1000] - Loss: 0.023801 - Valid. (MSE): 0.019781 - Valid. (MAE): 0.096970\n",
      "Epoch [113/1000] - Loss: 0.025431 - Valid. (MSE): 0.018015 - Valid. (MAE): 0.094682\n",
      "Epoch [114/1000] - Loss: 0.025511 - Valid. (MSE): 0.017905 - Valid. (MAE): 0.092943\n",
      "Epoch [114/1000] - Loss: 0.025025 - Valid. (MSE): 0.019458 - Valid. (MAE): 0.097302\n",
      "Epoch [115/1000] - Loss: 0.027367 - Valid. (MSE): 0.018300 - Valid. (MAE): 0.093127\n",
      "Epoch [116/1000] - Loss: 0.023557 - Valid. (MSE): 0.018349 - Valid. (MAE): 0.095567\n",
      "Epoch [116/1000] - Loss: 0.024531 - Valid. (MSE): 0.018243 - Valid. (MAE): 0.093701\n",
      "Epoch [117/1000] - Loss: 0.023254 - Valid. (MSE): 0.018185 - Valid. (MAE): 0.093455\n",
      "Epoch [118/1000] - Loss: 0.024257 - Valid. (MSE): 0.018725 - Valid. (MAE): 0.096062\n",
      "Epoch [118/1000] - Loss: 0.022841 - Valid. (MSE): 0.018102 - Valid. (MAE): 0.092497\n",
      "Epoch [119/1000] - Loss: 0.024616 - Valid. (MSE): 0.018893 - Valid. (MAE): 0.095689\n",
      "Epoch [119/1000] - Loss: 0.023240 - Valid. (MSE): 0.017820 - Valid. (MAE): 0.092662\n",
      "Epoch [120/1000] - Loss: 0.024112 - Valid. (MSE): 0.018468 - Valid. (MAE): 0.094860\n",
      "Epoch [121/1000] - Loss: 0.023123 - Valid. (MSE): 0.018712 - Valid. (MAE): 0.094501\n",
      "Epoch [121/1000] - Loss: 0.025563 - Valid. (MSE): 0.018269 - Valid. (MAE): 0.093565\n",
      "Epoch [122/1000] - Loss: 0.023847 - Valid. (MSE): 0.017777 - Valid. (MAE): 0.095039\n",
      "Epoch [123/1000] - Loss: 0.026113 - Valid. (MSE): 0.019587 - Valid. (MAE): 0.096512\n",
      "Epoch [123/1000] - Loss: 0.026219 - Valid. (MSE): 0.018141 - Valid. (MAE): 0.093235\n",
      "Epoch [124/1000] - Loss: 0.023788 - Valid. (MSE): 0.017956 - Valid. (MAE): 0.095467\n",
      "Epoch [124/1000] - Loss: 0.026162 - Valid. (MSE): 0.019649 - Valid. (MAE): 0.095591\n",
      "Epoch [125/1000] - Loss: 0.025279 - Valid. (MSE): 0.017761 - Valid. (MAE): 0.093035\n",
      "Epoch [126/1000] - Loss: 0.025393 - Valid. (MSE): 0.018341 - Valid. (MAE): 0.094800\n",
      "Epoch [126/1000] - Loss: 0.025086 - Valid. (MSE): 0.018684 - Valid. (MAE): 0.095104\n",
      "Epoch [127/1000] - Loss: 0.022688 - Valid. (MSE): 0.017950 - Valid. (MAE): 0.093140\n",
      "Epoch [128/1000] - Loss: 0.024445 - Valid. (MSE): 0.018355 - Valid. (MAE): 0.094131\n",
      "Epoch [128/1000] - Loss: 0.022835 - Valid. (MSE): 0.017983 - Valid. (MAE): 0.095757\n",
      "Epoch [129/1000] - Loss: 0.025612 - Valid. (MSE): 0.018577 - Valid. (MAE): 0.094084\n",
      "Epoch [129/1000] - Loss: 0.023754 - Valid. (MSE): 0.018200 - Valid. (MAE): 0.095803\n",
      "Epoch [130/1000] - Loss: 0.023982 - Valid. (MSE): 0.018600 - Valid. (MAE): 0.093607\n",
      "Epoch [131/1000] - Loss: 0.023995 - Valid. (MSE): 0.018141 - Valid. (MAE): 0.096039\n",
      "Epoch [131/1000] - Loss: 0.024020 - Valid. (MSE): 0.018036 - Valid. (MAE): 0.092912\n",
      "Epoch [132/1000] - Loss: 0.023093 - Valid. (MSE): 0.018126 - Valid. (MAE): 0.093596\n",
      "Epoch [133/1000] - Loss: 0.024108 - Valid. (MSE): 0.018555 - Valid. (MAE): 0.095005\n",
      "Epoch [133/1000] - Loss: 0.024200 - Valid. (MSE): 0.018092 - Valid. (MAE): 0.094066\n",
      "Epoch [134/1000] - Loss: 0.022520 - Valid. (MSE): 0.018108 - Valid. (MAE): 0.093303\n",
      "Epoch [134/1000] - Loss: 0.024602 - Valid. (MSE): 0.018193 - Valid. (MAE): 0.095736\n",
      "Epoch [135/1000] - Loss: 0.022016 - Valid. (MSE): 0.018943 - Valid. (MAE): 0.094224\n",
      "Epoch [136/1000] - Loss: 0.021524 - Valid. (MSE): 0.017791 - Valid. (MAE): 0.094495\n",
      "Epoch [136/1000] - Loss: 0.022048 - Valid. (MSE): 0.018521 - Valid. (MAE): 0.093966\n",
      "Epoch [137/1000] - Loss: 0.022547 - Valid. (MSE): 0.018239 - Valid. (MAE): 0.093570\n",
      "Stopping early at epoch 138. Best validation MSE: 0.017771369926639073 at epoch 106.\n",
      "Seed 50 completed:\n",
      "  - Final epoch: 138\n",
      "  - Best epoch: 106\n",
      "  - Training time: 2454.15s\n",
      "  - Test MSE: 0.017518\n",
      "  - Test MAE: 0.094276\n",
      "  - MPE: 0.035678\n",
      "  - Coverage 95%: 0.9336\n",
      "\n",
      "--- Training with seed 51 (10/10) ---\n",
      "Starting training for seed 51...\n",
      "Epoch [0/1000] - Loss: 0.195696 - Valid. (MSE): 0.147093 - Valid. (MAE): 0.302605\n",
      "Epoch [1/1000] - Loss: 0.099094 - Valid. (MSE): 0.056490 - Valid. (MAE): 0.186808\n",
      "Epoch [1/1000] - Loss: 0.098565 - Valid. (MSE): 0.055126 - Valid. (MAE): 0.188131\n",
      "Epoch [2/1000] - Loss: 0.092417 - Valid. (MSE): 0.060747 - Valid. (MAE): 0.181571\n",
      "Epoch [3/1000] - Loss: 0.085327 - Valid. (MSE): 0.057117 - Valid. (MAE): 0.178541\n",
      "Epoch [3/1000] - Loss: 0.086872 - Valid. (MSE): 0.052046 - Valid. (MAE): 0.180185\n",
      "Epoch [4/1000] - Loss: 0.073948 - Valid. (MSE): 0.051156 - Valid. (MAE): 0.175875\n",
      "Epoch [4/1000] - Loss: 0.078768 - Valid. (MSE): 0.052295 - Valid. (MAE): 0.171105\n",
      "Epoch [5/1000] - Loss: 0.072206 - Valid. (MSE): 0.049228 - Valid. (MAE): 0.168839\n",
      "Epoch [6/1000] - Loss: 0.071809 - Valid. (MSE): 0.047604 - Valid. (MAE): 0.166091\n",
      "Epoch [6/1000] - Loss: 0.069380 - Valid. (MSE): 0.047296 - Valid. (MAE): 0.161857\n",
      "Epoch [7/1000] - Loss: 0.072927 - Valid. (MSE): 0.045190 - Valid. (MAE): 0.158734\n",
      "Epoch [8/1000] - Loss: 0.067320 - Valid. (MSE): 0.042910 - Valid. (MAE): 0.157066\n",
      "Epoch [8/1000] - Loss: 0.065748 - Valid. (MSE): 0.042546 - Valid. (MAE): 0.152285\n",
      "Epoch [9/1000] - Loss: 0.061580 - Valid. (MSE): 0.041121 - Valid. (MAE): 0.149456\n",
      "Epoch [9/1000] - Loss: 0.058913 - Valid. (MSE): 0.039756 - Valid. (MAE): 0.147633\n",
      "Epoch [10/1000] - Loss: 0.057826 - Valid. (MSE): 0.039190 - Valid. (MAE): 0.144929\n",
      "Epoch [11/1000] - Loss: 0.062348 - Valid. (MSE): 0.037410 - Valid. (MAE): 0.145571\n",
      "Epoch [11/1000] - Loss: 0.056523 - Valid. (MSE): 0.038805 - Valid. (MAE): 0.140155\n",
      "Epoch [12/1000] - Loss: 0.055004 - Valid. (MSE): 0.035412 - Valid. (MAE): 0.138702\n",
      "Epoch [13/1000] - Loss: 0.053822 - Valid. (MSE): 0.034664 - Valid. (MAE): 0.134658\n",
      "Epoch [13/1000] - Loss: 0.053600 - Valid. (MSE): 0.033718 - Valid. (MAE): 0.131602\n",
      "Epoch [14/1000] - Loss: 0.056102 - Valid. (MSE): 0.032213 - Valid. (MAE): 0.129327\n",
      "Epoch [14/1000] - Loss: 0.051386 - Valid. (MSE): 0.031274 - Valid. (MAE): 0.126634\n",
      "Epoch [15/1000] - Loss: 0.048001 - Valid. (MSE): 0.030082 - Valid. (MAE): 0.125059\n",
      "Epoch [16/1000] - Loss: 0.043495 - Valid. (MSE): 0.029170 - Valid. (MAE): 0.125339\n",
      "Epoch [16/1000] - Loss: 0.043904 - Valid. (MSE): 0.030827 - Valid. (MAE): 0.121930\n",
      "Epoch [17/1000] - Loss: 0.044827 - Valid. (MSE): 0.028613 - Valid. (MAE): 0.120061\n",
      "Epoch [18/1000] - Loss: 0.045058 - Valid. (MSE): 0.027113 - Valid. (MAE): 0.120361\n",
      "Epoch [18/1000] - Loss: 0.043312 - Valid. (MSE): 0.027457 - Valid. (MAE): 0.118128\n",
      "Epoch [19/1000] - Loss: 0.042561 - Valid. (MSE): 0.029398 - Valid. (MAE): 0.117399\n",
      "Epoch [19/1000] - Loss: 0.045317 - Valid. (MSE): 0.027460 - Valid. (MAE): 0.115797\n",
      "Epoch [20/1000] - Loss: 0.040441 - Valid. (MSE): 0.025796 - Valid. (MAE): 0.118542\n",
      "Epoch [21/1000] - Loss: 0.041993 - Valid. (MSE): 0.026605 - Valid. (MAE): 0.114614\n",
      "Epoch [21/1000] - Loss: 0.039519 - Valid. (MSE): 0.025903 - Valid. (MAE): 0.112668\n",
      "Epoch [22/1000] - Loss: 0.040488 - Valid. (MSE): 0.026081 - Valid. (MAE): 0.112069\n",
      "Epoch [23/1000] - Loss: 0.040006 - Valid. (MSE): 0.025581 - Valid. (MAE): 0.111715\n",
      "Epoch [23/1000] - Loss: 0.039526 - Valid. (MSE): 0.024640 - Valid. (MAE): 0.114155\n",
      "Epoch [24/1000] - Loss: 0.039790 - Valid. (MSE): 0.025859 - Valid. (MAE): 0.111273\n",
      "Epoch [24/1000] - Loss: 0.039703 - Valid. (MSE): 0.025490 - Valid. (MAE): 0.110076\n",
      "Epoch [25/1000] - Loss: 0.038481 - Valid. (MSE): 0.024058 - Valid. (MAE): 0.109049\n",
      "Epoch [26/1000] - Loss: 0.038015 - Valid. (MSE): 0.025860 - Valid. (MAE): 0.110557\n",
      "Epoch [26/1000] - Loss: 0.036917 - Valid. (MSE): 0.025879 - Valid. (MAE): 0.110530\n",
      "Epoch [27/1000] - Loss: 0.035804 - Valid. (MSE): 0.023044 - Valid. (MAE): 0.109989\n",
      "Epoch [28/1000] - Loss: 0.038216 - Valid. (MSE): 0.023594 - Valid. (MAE): 0.108106\n",
      "Epoch [28/1000] - Loss: 0.041536 - Valid. (MSE): 0.023676 - Valid. (MAE): 0.108251\n",
      "Epoch [29/1000] - Loss: 0.035921 - Valid. (MSE): 0.023303 - Valid. (MAE): 0.107627\n",
      "Epoch [29/1000] - Loss: 0.034941 - Valid. (MSE): 0.024063 - Valid. (MAE): 0.107393\n",
      "Epoch [30/1000] - Loss: 0.038043 - Valid. (MSE): 0.023818 - Valid. (MAE): 0.106903\n",
      "Epoch [31/1000] - Loss: 0.038014 - Valid. (MSE): 0.022649 - Valid. (MAE): 0.106216\n",
      "Epoch [31/1000] - Loss: 0.036011 - Valid. (MSE): 0.022895 - Valid. (MAE): 0.105779\n",
      "Epoch [32/1000] - Loss: 0.032750 - Valid. (MSE): 0.024189 - Valid. (MAE): 0.106929\n",
      "Epoch [33/1000] - Loss: 0.036050 - Valid. (MSE): 0.022323 - Valid. (MAE): 0.105118\n",
      "Epoch [33/1000] - Loss: 0.036509 - Valid. (MSE): 0.021895 - Valid. (MAE): 0.105099\n",
      "Epoch [34/1000] - Loss: 0.035568 - Valid. (MSE): 0.022628 - Valid. (MAE): 0.105117\n",
      "Epoch [34/1000] - Loss: 0.030836 - Valid. (MSE): 0.023123 - Valid. (MAE): 0.104576\n",
      "Epoch [35/1000] - Loss: 0.034383 - Valid. (MSE): 0.023118 - Valid. (MAE): 0.104805\n",
      "Epoch [36/1000] - Loss: 0.034831 - Valid. (MSE): 0.022748 - Valid. (MAE): 0.104661\n",
      "Epoch [36/1000] - Loss: 0.037452 - Valid. (MSE): 0.022711 - Valid. (MAE): 0.104128\n",
      "Epoch [37/1000] - Loss: 0.034697 - Valid. (MSE): 0.021536 - Valid. (MAE): 0.103642\n",
      "Epoch [38/1000] - Loss: 0.033573 - Valid. (MSE): 0.023242 - Valid. (MAE): 0.104456\n",
      "Epoch [38/1000] - Loss: 0.035151 - Valid. (MSE): 0.023386 - Valid. (MAE): 0.104602\n",
      "Epoch [39/1000] - Loss: 0.033358 - Valid. (MSE): 0.021613 - Valid. (MAE): 0.102033\n",
      "Epoch [39/1000] - Loss: 0.033799 - Valid. (MSE): 0.020970 - Valid. (MAE): 0.104578\n",
      "Epoch [40/1000] - Loss: 0.032887 - Valid. (MSE): 0.022232 - Valid. (MAE): 0.102665\n",
      "Epoch [41/1000] - Loss: 0.033453 - Valid. (MSE): 0.023383 - Valid. (MAE): 0.104550\n",
      "Epoch [41/1000] - Loss: 0.033329 - Valid. (MSE): 0.020891 - Valid. (MAE): 0.102681\n",
      "Epoch [42/1000] - Loss: 0.034671 - Valid. (MSE): 0.022917 - Valid. (MAE): 0.103646\n",
      "Epoch [43/1000] - Loss: 0.031913 - Valid. (MSE): 0.022201 - Valid. (MAE): 0.102574\n",
      "Epoch [43/1000] - Loss: 0.032001 - Valid. (MSE): 0.020924 - Valid. (MAE): 0.101982\n",
      "Epoch [44/1000] - Loss: 0.032374 - Valid. (MSE): 0.021816 - Valid. (MAE): 0.102157\n",
      "Epoch [44/1000] - Loss: 0.031620 - Valid. (MSE): 0.022726 - Valid. (MAE): 0.103461\n",
      "Epoch [45/1000] - Loss: 0.034225 - Valid. (MSE): 0.020705 - Valid. (MAE): 0.102069\n",
      "Epoch [46/1000] - Loss: 0.031194 - Valid. (MSE): 0.020631 - Valid. (MAE): 0.101161\n",
      "Epoch [46/1000] - Loss: 0.031943 - Valid. (MSE): 0.021951 - Valid. (MAE): 0.101871\n",
      "Epoch [47/1000] - Loss: 0.031183 - Valid. (MSE): 0.022134 - Valid. (MAE): 0.101950\n",
      "Epoch [48/1000] - Loss: 0.032837 - Valid. (MSE): 0.020567 - Valid. (MAE): 0.101103\n",
      "Epoch [48/1000] - Loss: 0.031241 - Valid. (MSE): 0.020562 - Valid. (MAE): 0.101462\n",
      "Epoch [49/1000] - Loss: 0.027910 - Valid. (MSE): 0.023169 - Valid. (MAE): 0.103439\n",
      "Epoch [49/1000] - Loss: 0.029807 - Valid. (MSE): 0.020908 - Valid. (MAE): 0.099860\n",
      "Epoch [50/1000] - Loss: 0.032685 - Valid. (MSE): 0.020607 - Valid. (MAE): 0.099232\n",
      "Epoch [51/1000] - Loss: 0.031098 - Valid. (MSE): 0.021505 - Valid. (MAE): 0.100928\n",
      "Epoch [51/1000] - Loss: 0.031378 - Valid. (MSE): 0.021092 - Valid. (MAE): 0.100789\n",
      "Epoch [52/1000] - Loss: 0.029836 - Valid. (MSE): 0.020933 - Valid. (MAE): 0.100062\n",
      "Epoch [53/1000] - Loss: 0.031305 - Valid. (MSE): 0.021671 - Valid. (MAE): 0.100694\n",
      "Epoch [53/1000] - Loss: 0.029357 - Valid. (MSE): 0.020917 - Valid. (MAE): 0.099808\n",
      "Epoch [54/1000] - Loss: 0.032844 - Valid. (MSE): 0.020449 - Valid. (MAE): 0.099208\n",
      "Epoch [54/1000] - Loss: 0.029954 - Valid. (MSE): 0.020914 - Valid. (MAE): 0.099966\n",
      "Epoch [55/1000] - Loss: 0.032838 - Valid. (MSE): 0.020949 - Valid. (MAE): 0.100574\n",
      "Epoch [56/1000] - Loss: 0.030463 - Valid. (MSE): 0.020881 - Valid. (MAE): 0.099111\n",
      "Epoch [56/1000] - Loss: 0.029124 - Valid. (MSE): 0.021099 - Valid. (MAE): 0.099477\n",
      "Epoch [57/1000] - Loss: 0.029775 - Valid. (MSE): 0.020593 - Valid. (MAE): 0.099466\n",
      "Epoch [58/1000] - Loss: 0.028661 - Valid. (MSE): 0.020732 - Valid. (MAE): 0.099604\n",
      "Epoch [58/1000] - Loss: 0.031717 - Valid. (MSE): 0.021462 - Valid. (MAE): 0.100096\n",
      "Epoch [59/1000] - Loss: 0.030370 - Valid. (MSE): 0.020403 - Valid. (MAE): 0.098926\n",
      "Epoch [59/1000] - Loss: 0.031323 - Valid. (MSE): 0.020104 - Valid. (MAE): 0.099107\n",
      "Epoch [60/1000] - Loss: 0.028301 - Valid. (MSE): 0.021373 - Valid. (MAE): 0.099764\n",
      "Epoch [61/1000] - Loss: 0.029473 - Valid. (MSE): 0.021452 - Valid. (MAE): 0.099502\n",
      "Epoch [61/1000] - Loss: 0.030183 - Valid. (MSE): 0.019948 - Valid. (MAE): 0.099282\n",
      "Epoch [62/1000] - Loss: 0.030675 - Valid. (MSE): 0.021093 - Valid. (MAE): 0.099330\n",
      "Epoch [63/1000] - Loss: 0.030916 - Valid. (MSE): 0.021268 - Valid. (MAE): 0.099421\n",
      "Epoch [63/1000] - Loss: 0.031915 - Valid. (MSE): 0.020211 - Valid. (MAE): 0.098964\n",
      "Epoch [64/1000] - Loss: 0.029970 - Valid. (MSE): 0.020749 - Valid. (MAE): 0.098879\n",
      "Epoch [64/1000] - Loss: 0.027189 - Valid. (MSE): 0.021202 - Valid. (MAE): 0.099450\n",
      "Epoch [65/1000] - Loss: 0.027904 - Valid. (MSE): 0.020320 - Valid. (MAE): 0.099005\n",
      "Epoch [66/1000] - Loss: 0.026809 - Valid. (MSE): 0.020495 - Valid. (MAE): 0.099013\n",
      "Epoch [66/1000] - Loss: 0.027167 - Valid. (MSE): 0.020938 - Valid. (MAE): 0.099154\n",
      "Epoch [67/1000] - Loss: 0.028108 - Valid. (MSE): 0.020382 - Valid. (MAE): 0.098681\n",
      "Epoch [68/1000] - Loss: 0.028492 - Valid. (MSE): 0.021209 - Valid. (MAE): 0.099547\n",
      "Epoch [68/1000] - Loss: 0.029340 - Valid. (MSE): 0.021168 - Valid. (MAE): 0.099492\n",
      "Epoch [69/1000] - Loss: 0.028265 - Valid. (MSE): 0.020059 - Valid. (MAE): 0.098860\n",
      "Epoch [69/1000] - Loss: 0.028888 - Valid. (MSE): 0.020616 - Valid. (MAE): 0.099012\n",
      "Epoch [70/1000] - Loss: 0.027757 - Valid. (MSE): 0.020648 - Valid. (MAE): 0.098924\n",
      "Epoch [71/1000] - Loss: 0.026563 - Valid. (MSE): 0.019756 - Valid. (MAE): 0.098648\n",
      "Epoch [71/1000] - Loss: 0.030120 - Valid. (MSE): 0.020143 - Valid. (MAE): 0.097863\n",
      "Epoch [72/1000] - Loss: 0.028127 - Valid. (MSE): 0.020804 - Valid. (MAE): 0.098573\n",
      "Epoch [73/1000] - Loss: 0.028521 - Valid. (MSE): 0.020901 - Valid. (MAE): 0.098728\n",
      "Epoch [73/1000] - Loss: 0.026792 - Valid. (MSE): 0.019905 - Valid. (MAE): 0.099119\n",
      "Epoch [74/1000] - Loss: 0.027947 - Valid. (MSE): 0.020327 - Valid. (MAE): 0.097867\n",
      "Epoch [74/1000] - Loss: 0.028490 - Valid. (MSE): 0.020585 - Valid. (MAE): 0.098335\n",
      "Epoch [75/1000] - Loss: 0.029022 - Valid. (MSE): 0.020650 - Valid. (MAE): 0.099058\n",
      "Epoch [76/1000] - Loss: 0.027295 - Valid. (MSE): 0.019853 - Valid. (MAE): 0.097750\n",
      "Epoch [76/1000] - Loss: 0.026258 - Valid. (MSE): 0.021687 - Valid. (MAE): 0.100260\n",
      "Epoch [77/1000] - Loss: 0.028069 - Valid. (MSE): 0.020056 - Valid. (MAE): 0.099822\n",
      "Epoch [78/1000] - Loss: 0.024144 - Valid. (MSE): 0.020263 - Valid. (MAE): 0.099256\n",
      "Epoch [78/1000] - Loss: 0.027033 - Valid. (MSE): 0.021128 - Valid. (MAE): 0.098985\n",
      "Epoch [79/1000] - Loss: 0.025902 - Valid. (MSE): 0.020468 - Valid. (MAE): 0.098082\n",
      "Epoch [79/1000] - Loss: 0.026750 - Valid. (MSE): 0.020210 - Valid. (MAE): 0.097870\n",
      "Epoch [80/1000] - Loss: 0.026753 - Valid. (MSE): 0.020073 - Valid. (MAE): 0.097652\n",
      "Epoch [81/1000] - Loss: 0.025952 - Valid. (MSE): 0.020678 - Valid. (MAE): 0.098164\n",
      "Epoch [81/1000] - Loss: 0.024846 - Valid. (MSE): 0.020013 - Valid. (MAE): 0.098685\n",
      "Epoch [82/1000] - Loss: 0.026996 - Valid. (MSE): 0.021169 - Valid. (MAE): 0.098985\n",
      "Epoch [83/1000] - Loss: 0.026786 - Valid. (MSE): 0.020185 - Valid. (MAE): 0.097694\n",
      "Epoch [83/1000] - Loss: 0.025985 - Valid. (MSE): 0.019837 - Valid. (MAE): 0.099664\n",
      "Epoch [84/1000] - Loss: 0.028738 - Valid. (MSE): 0.020854 - Valid. (MAE): 0.098532\n",
      "Epoch [84/1000] - Loss: 0.027277 - Valid. (MSE): 0.020443 - Valid. (MAE): 0.097549\n",
      "Epoch [85/1000] - Loss: 0.025693 - Valid. (MSE): 0.020040 - Valid. (MAE): 0.099178\n",
      "Epoch [86/1000] - Loss: 0.027173 - Valid. (MSE): 0.020296 - Valid. (MAE): 0.097640\n",
      "Epoch [86/1000] - Loss: 0.026878 - Valid. (MSE): 0.020055 - Valid. (MAE): 0.098097\n",
      "Epoch [87/1000] - Loss: 0.027900 - Valid. (MSE): 0.020113 - Valid. (MAE): 0.097446\n",
      "Epoch [88/1000] - Loss: 0.026112 - Valid. (MSE): 0.020910 - Valid. (MAE): 0.098234\n",
      "Epoch [88/1000] - Loss: 0.026576 - Valid. (MSE): 0.019823 - Valid. (MAE): 0.097879\n",
      "Epoch [89/1000] - Loss: 0.025533 - Valid. (MSE): 0.020519 - Valid. (MAE): 0.097798\n",
      "Epoch [89/1000] - Loss: 0.028219 - Valid. (MSE): 0.020412 - Valid. (MAE): 0.097829\n",
      "Epoch [90/1000] - Loss: 0.028234 - Valid. (MSE): 0.019687 - Valid. (MAE): 0.099738\n",
      "Epoch [91/1000] - Loss: 0.025395 - Valid. (MSE): 0.020549 - Valid. (MAE): 0.097964\n",
      "Epoch [91/1000] - Loss: 0.028207 - Valid. (MSE): 0.020370 - Valid. (MAE): 0.097894\n",
      "Epoch [92/1000] - Loss: 0.026433 - Valid. (MSE): 0.019906 - Valid. (MAE): 0.097280\n",
      "Epoch [93/1000] - Loss: 0.028105 - Valid. (MSE): 0.020083 - Valid. (MAE): 0.097849\n",
      "Epoch [93/1000] - Loss: 0.026798 - Valid. (MSE): 0.019946 - Valid. (MAE): 0.098160\n",
      "Epoch [94/1000] - Loss: 0.025710 - Valid. (MSE): 0.020542 - Valid. (MAE): 0.097701\n",
      "Epoch [94/1000] - Loss: 0.026642 - Valid. (MSE): 0.020165 - Valid. (MAE): 0.098415\n",
      "Epoch [95/1000] - Loss: 0.027151 - Valid. (MSE): 0.020432 - Valid. (MAE): 0.098311\n",
      "Epoch [96/1000] - Loss: 0.025380 - Valid. (MSE): 0.019751 - Valid. (MAE): 0.097565\n",
      "Epoch [96/1000] - Loss: 0.023748 - Valid. (MSE): 0.020366 - Valid. (MAE): 0.098305\n",
      "Epoch [97/1000] - Loss: 0.026126 - Valid. (MSE): 0.020148 - Valid. (MAE): 0.097980\n",
      "Epoch [98/1000] - Loss: 0.024819 - Valid. (MSE): 0.019779 - Valid. (MAE): 0.097677\n",
      "Epoch [98/1000] - Loss: 0.027379 - Valid. (MSE): 0.020825 - Valid. (MAE): 0.098711\n",
      "Epoch [99/1000] - Loss: 0.025092 - Valid. (MSE): 0.019726 - Valid. (MAE): 0.099140\n",
      "Epoch [99/1000] - Loss: 0.026412 - Valid. (MSE): 0.020402 - Valid. (MAE): 0.097766\n",
      "Epoch [100/1000] - Loss: 0.026139 - Valid. (MSE): 0.020221 - Valid. (MAE): 0.097371\n",
      "Epoch [101/1000] - Loss: 0.026601 - Valid. (MSE): 0.019577 - Valid. (MAE): 0.097348\n",
      "Epoch [101/1000] - Loss: 0.026280 - Valid. (MSE): 0.021092 - Valid. (MAE): 0.098449\n",
      "Epoch [102/1000] - Loss: 0.025395 - Valid. (MSE): 0.019692 - Valid. (MAE): 0.098158\n",
      "Stopping early at epoch 103. Best validation MSE: 0.019756125470530673 at epoch 71.\n",
      "Seed 51 completed:\n",
      "  - Final epoch: 103\n",
      "  - Best epoch: 71\n",
      "  - Training time: 1026.92s\n",
      "  - Test MSE: 0.018331\n",
      "  - Test MAE: 0.092009\n",
      "  - MPE: 0.035989\n",
      "  - Coverage 95%: 0.9346\n",
      "\n",
      "====================================================================================================\n",
      "COMPREHENSIVE RESULTS SUMMARY\n",
      "====================================================================================================\n",
      "\n",
      "Number of seeds: 10\n",
      "Seeds used: [42, 43, 44, 45, 46, 47, 48, 49, 50, 51]\n",
      "\n",
      "Base model folder: final_pegat_california_housing_k5_ghid32_gemb32_phid128_pemb64_mat-lam0.25_bs2048_Oct29-06h24m44s\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "TRAINING METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "Final Epochs:\n",
      "  Mean ± Std: 130.3 ± 13.2\n",
      "  Range: [103, 144]\n",
      "\n",
      "Best Epochs:\n",
      "  Mean ± Std: 98.4 ± 13.3\n",
      "  Range: [71, 113]\n",
      "\n",
      "Training Time (seconds):\n",
      "  Mean ± Std: 1596.95 ± 366.54\n",
      "  Range: [1026.92, 2454.15]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "PERFORMANCE METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "Test MSE:\n",
      "  Mean ± Std: 0.017714 ± 0.000629\n",
      "  Range: [0.016690, 0.018841]\n",
      "\n",
      "Test MAE:\n",
      "  Mean ± Std: 0.093645 ± 0.002079\n",
      "  Range: [0.091407, 0.098423]\n",
      "\n",
      "Validation MSE:\n",
      "  Mean ± Std: 0.017448 ± 0.001010\n",
      "  Range: [0.016064, 0.019756]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "UNCERTAINTY QUANTIFICATION METRICS\n",
      "--------------------------------------------------------------------------------\n",
      "MPE (Mean Prediction Error):\n",
      "  Mean ± Std: 0.035425 ± 0.000859\n",
      "  Range: [0.034055, 0.037162]\n",
      "\n",
      "95% Prediction Interval Coverage:\n",
      "  Mean ± Std: 0.9298 ± 0.0066\n",
      "  Range: [0.9167, 0.9399]\n",
      "\n",
      "Calibration Score:\n",
      "  Mean ± Std: 0.413219 ± 0.107540\n",
      "  Range: [0.273127, 0.641886]\n",
      "\n",
      "MADECP (Mean Absolute Deviation from Expected Coverage Probability):\n",
      "  Mean ± Std: 0.054734 ± 0.006631\n",
      "  Range: [0.045621, 0.067450]\n",
      "\n",
      "Prediction Variance:\n",
      "  Mean ± Std: 0.017615 ± 0.001017\n",
      "  Range: [0.016165, 0.019832]\n",
      "\n",
      "====================================================================================================\n",
      "INDIVIDUAL SEED RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "Seed   Epochs   Time(s)    Test MSE     Test MAE     MPE          Coverage  \n",
      "--------------------------------------------------------------------------------\n",
      "42     120      1888.67    0.018299     0.092930     0.036022     0.9167    \n",
      "43     141      1539.05    0.017188     0.091918     0.034055     0.9268    \n",
      "44     115      1268.91    0.016690     0.091407     0.034452     0.9297    \n",
      "45     144      1588.35    0.017126     0.095175     0.035174     0.9399    \n",
      "46     140      1544.91    0.018841     0.098423     0.037162     0.9230    \n",
      "47     131      1452.89    0.017827     0.095155     0.035701     0.9312    \n",
      "48     127      1423.80    0.018000     0.093560     0.035402     0.9254    \n",
      "49     144      1781.84    0.017321     0.091598     0.034617     0.9370    \n",
      "50     138      2454.15    0.017518     0.094276     0.035678     0.9336    \n",
      "51     103      1026.92    0.018331     0.092009     0.035989     0.9346    \n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "TOTAL EXECUTION TIME: 0 days, 4 hours, 26 minutes, 17.17 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set up arguments for multi-seed training\n",
    "args = argparse.Namespace(\n",
    "    dataset=\"california_housing\",\n",
    "    model_name=\"pegat\",\n",
    "    path=\"../../\",\n",
    "    train_size=0.8,\n",
    "    val_size=0.1,\n",
    "    batched_training=True,\n",
    "    batch_size=2048,\n",
    "    max_epochs=1000,\n",
    "    patience_limit=50,\n",
    "    min_improvement=0.01,\n",
    "    train_crit=\"mse\",\n",
    "    lr=1e-3,\n",
    "    gnn_hidden_dim=32,\n",
    "    gnn_emb_dim=32,\n",
    "    pe_hidden_dim=128,\n",
    "    pe_emb_dim=64,\n",
    "    k=5,\n",
    "    p_dropout=0.5,\n",
    "    mat=True,\n",
    "    uw=False,\n",
    "    lamb=0.25,\n",
    "    save_freq=5,\n",
    "    print_progress=True,\n",
    ")\n",
    "\n",
    "# Run multi-seed training\n",
    "print(\"Starting Multi-Seed Training Experiment\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train with 10 different seeds\n",
    "all_results = train_multiple_seeds(args, num_seeds=10)\n",
    "\n",
    "end_time = time.time()\n",
    "total_execution_time = end_time - start_time\n",
    "\n",
    "# Calculate aggregated results\n",
    "results_dict = calculate_aggregated_results(all_results)\n",
    "\n",
    "# Print comprehensive results\n",
    "print_aggregated_results(all_results, results_dict)\n",
    "\n",
    "# Print total execution time\n",
    "days, remainder = divmod(total_execution_time, 60 * 60 * 24)\n",
    "hours, remainder = divmod(remainder, 60 * 60)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(\n",
    "    f\"\\nTOTAL EXECUTION TIME: {int(days)} days, {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the trained models (all seeds will be saved with the base model name)\n",
    "base_model_folder = all_results[0][\"model_folder\"].split(\"_seed\")[0]\n",
    "print(f\"Base model folder: {base_model_folder}\")\n",
    "\n",
    "# List all model folders for this experiment\n",
    "models_lst = os.listdir(f\"{args.path}trained/\")\n",
    "experiment_folders = [m for m in models_lst if base_model_folder in m]\n",
    "print(f\"Experiment folders: {experiment_folders}\")\n",
    "\n",
    "# Load the best performing model (lowest test MSE) for detailed analysis\n",
    "best_result = min(all_results, key=lambda x: x[\"test_mse\"])\n",
    "print(\n",
    "    f\"Best performing model: Seed {best_result['random_state']} with Test MSE: {best_result['test_mse']:.6f}\"\n",
    ")\n",
    "\n",
    "# Load the best model for analysis\n",
    "model_folder = best_result[\"model_folder\"]\n",
    "model_path = f\"{args.path}trained/{model_folder}/ckpts/model_state.pt\"\n",
    "\n",
    "# Set up data and model for analysis (using the same seed as best result)\n",
    "set_seed(best_result[\"random_state\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Access and process data (same as training)\n",
    "if args.dataset == \"california_housing\":\n",
    "    x, y, c = get_california_housing_data()\n",
    "\n",
    "# Split data (same as training)\n",
    "n = x.shape[0]\n",
    "indices = np.arange(n)\n",
    "_, _, _, _, idx_train, idx_val_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    indices,\n",
    "    test_size=(1 - args.train_size),\n",
    "    random_state=best_result[\"random_state\"],\n",
    ")\n",
    "idx_val, idx_test = train_test_split(\n",
    "    idx_val_test,\n",
    "    test_size=(1 - args.train_size - args.val_size) / (1 - args.train_size),\n",
    "    random_state=best_result[\"random_state\"],\n",
    ")\n",
    "\n",
    "# Separate x, y and c objects\n",
    "train_x, val_x, test_x = x[idx_train], x[idx_val], x[idx_test]\n",
    "train_y, val_y, test_y = y[idx_train], y[idx_val], y[idx_test]\n",
    "train_c, val_c, test_c = c[idx_train], c[idx_val], c[idx_test]\n",
    "\n",
    "# Create MyDataset objects\n",
    "train_dataset, val_dataset, test_dataset = (\n",
    "    MyDataset(train_x, train_y, train_c),\n",
    "    MyDataset(val_x, val_y, val_c),\n",
    "    MyDataset(test_x, test_y, test_c),\n",
    ")\n",
    "\n",
    "# Define edge indices and weights\n",
    "if args.batched_training == False:\n",
    "    batch_size = len(idx_train)\n",
    "    train_edge_index = knn_graph(train_c, k=args.k).to(device)\n",
    "    train_edge_weight = makeEdgeWeight(train_c, train_edge_index).to(device)\n",
    "    val_edge_index = knn_graph(val_c, k=args.k).to(device)\n",
    "    val_edge_weight = makeEdgeWeight(val_c, val_edge_index).to(device)\n",
    "    test_edge_index = knn_graph(test_c, k=args.k).to(device)\n",
    "    test_edge_weight = makeEdgeWeight(test_c, test_edge_index).to(device)\n",
    "    train_moran_weight_matrix = knn_to_adj(train_edge_index, batch_size)\n",
    "    with torch.enable_grad():\n",
    "        train_y_moran = lw_tensor_local_moran(\n",
    "            train_y, sparse.csr_matrix(train_moran_weight_matrix)\n",
    "        ).to(device)\n",
    "else:\n",
    "    train_edge_index = False\n",
    "    train_edge_weight = False\n",
    "    val_edge_index = False\n",
    "    val_edge_weight = False\n",
    "    test_edge_index = False\n",
    "    test_edge_weight = False\n",
    "    train_y_moran = False\n",
    "\n",
    "# Make model\n",
    "if args.model_name == \"pegcn\":\n",
    "    model = PEGCN(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "elif args.model_name == \"pegat\":\n",
    "    model = PEGAT(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "elif args.model_name == \"pegsage\":\n",
    "    model = PEGSAGE(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.float()\n",
    "\n",
    "# Model analysis\n",
    "model.eval()\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())) + \"\\\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from data import *\n",
    "from metrics import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "from spatial import *\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, coords = get_australia_data()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(coords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_seed(x, y, coords, args, random_state, model_folder_name=None):\n",
    "    \"\"\"\n",
    "    Train model with a single random seed and return comprehensive results\n",
    "    \"\"\"\n",
    "    # Get args\n",
    "    dataset = args.dataset\n",
    "    model_name = args.model_name\n",
    "    path = args.path\n",
    "    train_size = args.train_size\n",
    "    val_size = args.val_size\n",
    "    test_size = 1 - (args.train_size + args.val_size)\n",
    "    batched_training = args.batched_training\n",
    "    batch_size = args.batch_size\n",
    "    max_epochs = args.max_epochs\n",
    "    patience_limit = args.patience_limit\n",
    "    min_improvement = args.min_improvement\n",
    "    train_crit = args.train_crit\n",
    "    lr = args.lr\n",
    "    gnn_hidden_dim = args.gnn_hidden_dim\n",
    "    gnn_emb_dim = args.gnn_emb_dim\n",
    "    pe_hidden_dim = args.pe_hidden_dim\n",
    "    pe_emb_dim = args.pe_emb_dim\n",
    "    k = args.k\n",
    "    p_dropout = args.p_dropout\n",
    "    MAT = args.mat\n",
    "    uw = args.uw\n",
    "    lamb = args.lamb\n",
    "    save_freq = args.save_freq\n",
    "    print_progress = args.print_progress\n",
    "\n",
    "    # Set random seed\n",
    "    set_seed(random_state)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Access and process data\n",
    "    if dataset == \"australia\":\n",
    "        x, y, c = get_australia_data(aux=(x, y, coords))\n",
    "\n",
    "    # Split data\n",
    "    n = x.shape[0]\n",
    "    indices = np.arange(n)\n",
    "    _, _, _, _, idx_train, idx_val_test = train_test_split(\n",
    "        x, y, indices, test_size=(1 - train_size), random_state=random_state\n",
    "    )\n",
    "    idx_val, idx_test = train_test_split(\n",
    "        idx_val_test,\n",
    "        test_size=(1 - train_size - val_size) / (1 - train_size),\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Separate x, y and c objects\n",
    "    train_x, val_x, test_x = x[idx_train], x[idx_val], x[idx_test]\n",
    "    train_y, val_y, test_y = y[idx_train], y[idx_val], y[idx_test]\n",
    "    train_c, val_c, test_c = c[idx_train], c[idx_val], c[idx_test]\n",
    "\n",
    "    # Create MyDataset objects\n",
    "    train_dataset, val_dataset, test_dataset = (\n",
    "        MyDataset(train_x, train_y, train_c),\n",
    "        MyDataset(val_x, val_y, val_c),\n",
    "        MyDataset(test_x, test_y, test_c),\n",
    "    )\n",
    "\n",
    "    # Define train loader\n",
    "    if batched_training == False:\n",
    "        batch_size = len(idx_train)\n",
    "        train_edge_index = knn_graph(train_c, k=k).to(device)\n",
    "        train_edge_weight = makeEdgeWeight(train_c, train_edge_index).to(device)\n",
    "        val_edge_index = knn_graph(val_c, k=k).to(device)\n",
    "        val_edge_weight = makeEdgeWeight(val_c, val_edge_index).to(device)\n",
    "        test_edge_index = knn_graph(test_c, k=k).to(device)\n",
    "        test_edge_weight = makeEdgeWeight(test_c, test_edge_index).to(device)\n",
    "        train_moran_weight_matrix = knn_to_adj(train_edge_index, batch_size)\n",
    "        with torch.enable_grad():\n",
    "            train_y_moran = lw_tensor_local_moran(\n",
    "                train_y, sparse.csr_matrix(train_moran_weight_matrix)\n",
    "            ).to(device)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    "        )\n",
    "    else:\n",
    "        train_edge_index = False\n",
    "        train_edge_weight = False\n",
    "        val_edge_index = False\n",
    "        val_edge_weight = False\n",
    "        test_edge_index = False\n",
    "        test_edge_weight = False\n",
    "        train_y_moran = False\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "\n",
    "    # Make model\n",
    "    if model_name == \"pegcn\":\n",
    "        model = PEGCN(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    elif model_name == \"pegat\":\n",
    "        model = PEGAT(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    elif model_name == \"pegsage\":\n",
    "        model = PEGSAGE(\n",
    "            num_features_in=train_x.shape[1],\n",
    "            gnn_hidden_dim=gnn_hidden_dim,\n",
    "            gnn_emb_dim=gnn_emb_dim,\n",
    "            pe_hidden_dim=pe_hidden_dim,\n",
    "            pe_emb_dim=pe_emb_dim,\n",
    "            k=k,\n",
    "            p_dropout=p_dropout,\n",
    "            MAT=MAT,\n",
    "        ).to(device)\n",
    "    model = model.float()\n",
    "\n",
    "    # Number of tasks\n",
    "    if MAT:\n",
    "        task_num = 2\n",
    "    else:\n",
    "        task_num = 1\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    loss_wrapper = LossWrapperPEGNN(\n",
    "        model,\n",
    "        loss=train_crit,\n",
    "        k=k,\n",
    "        batch_size=batch_size,\n",
    "        task_num=task_num,\n",
    "        uw=uw,\n",
    "        lamb=lamb,\n",
    "    ).to(device)\n",
    "    optimizer = Adam(loss_wrapper.parameters(), lr=lr)\n",
    "    score1 = nn.MSELoss()\n",
    "    score2 = nn.L1Loss()\n",
    "\n",
    "    # Create model folder name if not provided\n",
    "    if model_folder_name is None:\n",
    "        test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "        test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "        test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "        test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "        test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "        if MAT:\n",
    "            if uw:\n",
    "                test_ = test_ + \"_mat-uw\"\n",
    "            else:\n",
    "                test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "        if batched_training == True:\n",
    "            test_ = test_ + \"_bs\" + str(batch_size)\n",
    "        else:\n",
    "            test_ = test_ + \"_bsn\"\n",
    "\n",
    "        now = datetime.now()\n",
    "        saved_file = \"{}_{}{}-{}h{}m{}s\".format(\n",
    "            test_,\n",
    "            now.strftime(\"%h\"),\n",
    "            now.strftime(\"%d\"),\n",
    "            now.strftime(\"%H\"),\n",
    "            now.strftime(\"%M\"),\n",
    "            now.strftime(\"%S\"),\n",
    "        )\n",
    "    else:\n",
    "        saved_file = model_folder_name\n",
    "        # Create test_ variable for logging purposes\n",
    "        test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "        test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "        test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "        test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "        test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "        if MAT:\n",
    "            if uw:\n",
    "                test_ = test_ + \"_mat-uw\"\n",
    "            else:\n",
    "                test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "        if batched_training == True:\n",
    "            test_ = test_ + \"_bs\" + str(batch_size)\n",
    "        else:\n",
    "            test_ = test_ + \"_bsn\"\n",
    "\n",
    "    log_dir = path + \"//trained//{}//log\".format(saved_file)\n",
    "\n",
    "    if not os.path.exists(path + \"//trained//{}//data\".format(saved_file)):\n",
    "        os.makedirs(path + \"//trained//{}//data\".format(saved_file))\n",
    "    if not os.path.exists(path + \"//trained//{}//images\".format(saved_file)):\n",
    "        os.makedirs(path + \"//trained//{}//images\".format(saved_file))\n",
    "    with open(path + \"//trained//{}//train_notes.txt\".format(saved_file), \"w\") as f:\n",
    "        f.write(\"Experiment notes: PE-GAT for Australia dataset \\n\\n\")\n",
    "        f.write(\"MODEL_DATA: {}\\n\".format(test_))\n",
    "        f.write(\"DATASET: {}\\n\".format(dataset))\n",
    "        f.write(\"RANDOM_STATE: {}\\n\".format(random_state))\n",
    "        f.write(\n",
    "            \"[TRAIN_SIZE, VAL_SIZE, TEST_SIZE]: [{}, {}, {}]\\n\".format(\n",
    "                train_size, val_size, test_size\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"BATCH_SIZE: {}\\nTRAIN_CRIT: {}\\nLEARNING_RATE: {}\\n\".format(\n",
    "                batch_size, train_crit, lr\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"MAX_EPOCHS: {}\\nPATIENCE_LIMIT: {}\\nMIN_IMPROVEMENT: {}\\n\".format(\n",
    "                max_epochs, patience_limit, min_improvement\n",
    "            )\n",
    "        )\n",
    "        f.write(\n",
    "            \"GNN_HIDDEN_DIM: {}\\nGNN_EMB_DIM: {}\\n\".format(gnn_hidden_dim, gnn_emb_dim)\n",
    "        )\n",
    "        f.write(\"PE_HIDDEN_DIM: {}\\nPE_EMB_DIM: {}\\n\".format(pe_hidden_dim, pe_emb_dim))\n",
    "        f.write(\"K: {}\\nP_DROPOUT: {}\\n\".format(k, p_dropout))\n",
    "        f.write(\"MAT: {}\\nUW: {}\\nLAMBDA: {}\\n\".format(MAT, uw, lamb))\n",
    "\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    it_counts = 0\n",
    "    best_val_mse = float(\"inf\")\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    found = False\n",
    "    final_epoch = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        for batch in train_loader:\n",
    "            model.train()\n",
    "            it_counts += 1\n",
    "            x = batch[0].to(device).float()\n",
    "            y = batch[1].to(device).float()\n",
    "            c = batch[2].to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if MAT == True & uw == True:\n",
    "                loss, log_vars = loss_wrapper(\n",
    "                    x, y, c, train_edge_index, train_edge_weight, train_y_moran\n",
    "                )\n",
    "            else:\n",
    "                loss = loss_wrapper(\n",
    "                    x, y, c, train_edge_index, train_edge_weight, train_y_moran\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Eval\n",
    "            if it_counts % save_freq == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    if MAT:\n",
    "                        pred_val, _ = model(\n",
    "                            val_dataset.features.clone().detach().to(device),\n",
    "                            val_dataset.coords.clone().detach().to(device),\n",
    "                            val_edge_index,\n",
    "                            val_edge_weight,\n",
    "                        )\n",
    "                    else:\n",
    "                        pred_val = model(\n",
    "                            val_dataset.features.clone().detach().to(device),\n",
    "                            val_dataset.coords.clone().detach().to(device),\n",
    "                            val_edge_index,\n",
    "                            val_edge_weight,\n",
    "                        )\n",
    "                val_score1 = score1(\n",
    "                    val_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "                    pred_val.reshape(-1),\n",
    "                )\n",
    "                val_score2 = score2(\n",
    "                    val_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "                    pred_val.reshape(-1),\n",
    "                )\n",
    "\n",
    "                # Check for improvement\n",
    "                if best_val_mse > val_score1.item() * (1 + min_improvement):\n",
    "                    best_val_mse = val_score1.item()\n",
    "                    best_epoch = epoch\n",
    "                    patience_counter = 0  # Reset patience\n",
    "                else:\n",
    "                    patience_counter += 1  # Increment patience\n",
    "\n",
    "                # Early stopping check\n",
    "                if patience_counter > patience_limit:\n",
    "                    if print_progress:\n",
    "                        print(\n",
    "                            f\"Stopping early at epoch {epoch}. Best validation MSE: {best_val_mse} at epoch {best_epoch}.\"\n",
    "                        )\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "                if print_progress:\n",
    "                    print(\n",
    "                        \"Epoch [%d/%d] - Loss: %f - Valid. (MSE): %f - Valid. (MAE): %f\"\n",
    "                        % (\n",
    "                            epoch,\n",
    "                            max_epochs,\n",
    "                            loss.item(),\n",
    "                            val_score1.item(),\n",
    "                            val_score2.item(),\n",
    "                        )\n",
    "                    )\n",
    "                save_path = path + \"//trained//{}//ckpts\".format(saved_file)\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                torch.save(model.state_dict(), save_path + \"//\" + \"model_state.pt\")\n",
    "                writer.add_scalar(\"Validation (MSE)\", val_score1.item(), it_counts)\n",
    "                writer.add_scalar(\"Validation (MAE)\", val_score2.item(), it_counts)\n",
    "            writer.add_scalar(\"Training loss\", loss.item(), it_counts)\n",
    "            writer.flush()\n",
    "        final_epoch = epoch\n",
    "        if found:\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Test eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if MAT:\n",
    "            pred_test, _ = model(\n",
    "                test_dataset.features.clone().detach().to(device),\n",
    "                test_dataset.coords.clone().detach().to(device),\n",
    "                test_edge_index,\n",
    "                test_edge_weight,\n",
    "            )\n",
    "        else:\n",
    "            pred_test = model(\n",
    "                test_dataset.features.clone().detach().to(device),\n",
    "                test_dataset.coords.clone().detach().to(device),\n",
    "                test_edge_index,\n",
    "                test_edge_weight,\n",
    "            )\n",
    "    test_mse = score1(\n",
    "        test_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "        pred_test.reshape(-1),\n",
    "    )\n",
    "    test_mae = score2(\n",
    "        test_dataset.target.clone().detach().reshape(-1).to(device),\n",
    "        pred_test.reshape(-1),\n",
    "    )\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    pred_val = pred_val.reshape(-1)\n",
    "    pred_test = pred_test.reshape(-1)\n",
    "\n",
    "    residuals = val_y - pred_val\n",
    "    variance = torch.var(residuals).item()\n",
    "\n",
    "    test_y_np = test_y.numpy()\n",
    "    pred_test_np = pred_test.numpy()\n",
    "\n",
    "    # Calculate MPE - ensure all inputs are PyTorch tensors\n",
    "    try:\n",
    "        mpe_value = mpe(test_y, pred_test, var_pred=variance)\n",
    "    except Exception as e:\n",
    "        print(f\"MPE calculation error: {e}\")\n",
    "        mpe_value = float(\"inf\")\n",
    "\n",
    "    # Calculate calibration metrics\n",
    "    try:\n",
    "        taus = np.round(np.arange(0.01, 1, 0.01), 2)\n",
    "        means = np.repeat(pred_test_np[:, np.newaxis], len(taus), axis=1)\n",
    "        std_devs = np.sqrt(variance)\n",
    "        quantiles = norm.ppf(taus, loc=means, scale=std_devs)\n",
    "\n",
    "        comparison = (test_y_np[:, np.newaxis] <= quantiles).astype(int)\n",
    "        comparison_mean = pd.DataFrame(comparison, columns=taus).mean().reset_index()\n",
    "\n",
    "        calibration = np.sum((comparison_mean[\"index\"] - comparison_mean[0]) ** 2)\n",
    "        madecp = np.mean(np.abs(comparison_mean[\"index\"] - comparison_mean[0]))\n",
    "\n",
    "        # Calculate 95% prediction interval coverage\n",
    "        tau_lower, tau_upper = 0.025, 0.975\n",
    "        q_lower = norm.ppf(tau_lower, loc=pred_test_np, scale=std_devs)\n",
    "        q_upper = norm.ppf(tau_upper, loc=pred_test_np, scale=std_devs)\n",
    "        coverage_95 = np.mean((test_y_np >= q_lower) & (test_y_np <= q_upper))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Calibration metrics calculation error: {e}\")\n",
    "        calibration = float(\"inf\")\n",
    "        madecp = float(\"inf\")\n",
    "        coverage_95 = 0.0\n",
    "\n",
    "    # Return comprehensive results\n",
    "    results = {\n",
    "        \"random_state\": random_state,\n",
    "        \"model_folder\": saved_file,\n",
    "        \"final_epoch\": final_epoch,\n",
    "        \"best_epoch\": best_epoch,\n",
    "        \"training_time\": training_time,\n",
    "        \"test_mse\": test_mse.item(),\n",
    "        \"test_mae\": test_mae.item(),\n",
    "        \"val_mse\": best_val_mse,\n",
    "        \"mpe\": mpe_value,\n",
    "        \"calibration\": calibration,\n",
    "        \"madecp\": madecp,\n",
    "        \"coverage_95\": coverage_95,\n",
    "        \"variance\": variance,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_seeds(x, y, coords, args, seeds=None, num_seeds=10):\n",
    "    \"\"\"\n",
    "    Train model with multiple random seeds and return aggregated results\n",
    "    \"\"\"\n",
    "    if seeds is None:\n",
    "        seeds = list(range(42, 42 + num_seeds))\n",
    "\n",
    "    all_results = []\n",
    "    base_model_name = None\n",
    "\n",
    "    print(f\"Starting training with {len(seeds)} different random seeds: {seeds}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, seed in enumerate(seeds):\n",
    "        print(f\"\\n--- Training with seed {seed} ({i+1}/{len(seeds)}) ---\")\n",
    "\n",
    "        # Create a consistent model folder name for the first run\n",
    "        if i == 0:\n",
    "            # Generate base model name\n",
    "            dataset = args.dataset\n",
    "            model_name = args.model_name\n",
    "            k = args.k\n",
    "            gnn_hidden_dim = args.gnn_hidden_dim\n",
    "            gnn_emb_dim = args.gnn_emb_dim\n",
    "            pe_hidden_dim = args.pe_hidden_dim\n",
    "            pe_emb_dim = args.pe_emb_dim\n",
    "            MAT = args.mat\n",
    "            uw = args.uw\n",
    "            lamb = args.lamb\n",
    "            batched_training = args.batched_training\n",
    "            batch_size = args.batch_size\n",
    "\n",
    "            test_ = \"final\" + \"_\" + model_name + \"_\" + dataset + \"_k\" + str(k)\n",
    "            test_ = test_ + \"_ghid\" + str(gnn_hidden_dim)\n",
    "            test_ = test_ + \"_gemb\" + str(gnn_emb_dim)\n",
    "            test_ = test_ + \"_phid\" + str(pe_hidden_dim)\n",
    "            test_ = test_ + \"_pemb\" + str(pe_emb_dim)\n",
    "            if MAT:\n",
    "                if uw:\n",
    "                    test_ = test_ + \"_mat-uw\"\n",
    "                else:\n",
    "                    test_ = test_ + \"_mat-lam\" + str(lamb)\n",
    "            if batched_training == True:\n",
    "                test_ = test_ + \"_bs\" + str(batch_size)\n",
    "            else:\n",
    "                test_ = test_ + \"_bsn\"\n",
    "\n",
    "            now = datetime.now()\n",
    "            base_model_name = \"{}_{}{}-{}h{}m{}s\".format(\n",
    "                test_,\n",
    "                now.strftime(\"%h\"),\n",
    "                now.strftime(\"%d\"),\n",
    "                now.strftime(\"%H\"),\n",
    "                now.strftime(\"%M\"),\n",
    "                now.strftime(\"%S\"),\n",
    "            )\n",
    "\n",
    "        # Train with current seed with timeout protection\n",
    "        try:\n",
    "            print(f\"Starting training for seed {seed}...\")\n",
    "            results = train_single_seed(\n",
    "                x,\n",
    "                y,\n",
    "                coords,\n",
    "                args,\n",
    "                seed,\n",
    "                model_folder_name=f\"{base_model_name}_seed{seed}\",\n",
    "            )\n",
    "            all_results.append(results)\n",
    "\n",
    "            print(f\"Seed {seed} completed:\")\n",
    "            print(f\"  - Final epoch: {results['final_epoch']}\")\n",
    "            print(f\"  - Best epoch: {results['best_epoch']}\")\n",
    "            print(f\"  - Training time: {results['training_time']:.2f}s\")\n",
    "            print(f\"  - Test MSE: {results['test_mse']:.6f}\")\n",
    "            print(f\"  - Test MAE: {results['test_mae']:.6f}\")\n",
    "            print(f\"  - MPE: {results['mpe']:.6f}\")\n",
    "            print(f\"  - Coverage 95%: {results['coverage_95']:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error training seed {seed}: {e}\")\n",
    "            # Create a dummy result to maintain consistency\n",
    "            dummy_result = {\n",
    "                \"random_state\": seed,\n",
    "                \"model_folder\": f\"{base_model_name}_seed{seed}\",\n",
    "                \"final_epoch\": 0,\n",
    "                \"best_epoch\": 0,\n",
    "                \"training_time\": 0.0,\n",
    "                \"test_mse\": float(\"inf\"),\n",
    "                \"test_mae\": float(\"inf\"),\n",
    "                \"val_mse\": float(\"inf\"),\n",
    "                \"mpe\": float(\"inf\"),\n",
    "                \"calibration\": float(\"inf\"),\n",
    "                \"madecp\": float(\"inf\"),\n",
    "                \"coverage_95\": 0.0,\n",
    "                \"variance\": 0.0,\n",
    "            }\n",
    "            all_results.append(dummy_result)\n",
    "            print(f\"Added dummy result for failed seed {seed}\")\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aggregated_results(all_results):\n",
    "    \"\"\"\n",
    "    Calculate mean and standard deviation for all metrics across seeds\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract all metrics\n",
    "    metrics = [\n",
    "        \"final_epoch\",\n",
    "        \"best_epoch\",\n",
    "        \"training_time\",\n",
    "        \"test_mse\",\n",
    "        \"test_mae\",\n",
    "        \"val_mse\",\n",
    "        \"mpe\",\n",
    "        \"calibration\",\n",
    "        \"madecp\",\n",
    "        \"coverage_95\",\n",
    "        \"variance\",\n",
    "    ]\n",
    "\n",
    "    results_dict = {}\n",
    "    for metric in metrics:\n",
    "        values = [result[metric] for result in all_results]\n",
    "        results_dict[metric] = {\n",
    "            \"mean\": np.mean(values),\n",
    "            \"std\": np.std(values),\n",
    "            \"min\": np.min(values),\n",
    "            \"max\": np.max(values),\n",
    "        }\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def print_aggregated_results(all_results, results_dict):\n",
    "    \"\"\"\n",
    "    Print comprehensive results summary\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    print(f\"\\nNumber of seeds: {len(all_results)}\")\n",
    "    print(f\"Seeds used: {[r['random_state'] for r in all_results]}\")\n",
    "\n",
    "    print(f\"\\nBase model folder: {all_results[0]['model_folder'].split('_seed')[0]}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"TRAINING METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Training metrics\n",
    "    print(f\"Final Epochs:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['final_epoch']['mean']:.1f} ± {results_dict['final_epoch']['std']:.1f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['final_epoch']['min']:.0f}, {results_dict['final_epoch']['max']:.0f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest Epochs:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['best_epoch']['mean']:.1f} ± {results_dict['best_epoch']['std']:.1f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['best_epoch']['min']:.0f}, {results_dict['best_epoch']['max']:.0f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining Time (seconds):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['training_time']['mean']:.2f} ± {results_dict['training_time']['std']:.2f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['training_time']['min']:.2f}, {results_dict['training_time']['max']:.2f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Performance metrics\n",
    "    print(f\"Test MSE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['test_mse']['mean']:.6f} ± {results_dict['test_mse']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['test_mse']['min']:.6f}, {results_dict['test_mse']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTest MAE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['test_mae']['mean']:.6f} ± {results_dict['test_mae']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['test_mae']['min']:.6f}, {results_dict['test_mae']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nValidation MSE:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['val_mse']['mean']:.6f} ± {results_dict['val_mse']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['val_mse']['min']:.6f}, {results_dict['val_mse']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"UNCERTAINTY QUANTIFICATION METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Uncertainty metrics\n",
    "    print(f\"MPE (Mean Prediction Error):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['mpe']['mean']:.6f} ± {results_dict['mpe']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['mpe']['min']:.6f}, {results_dict['mpe']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n95% Prediction Interval Coverage:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['coverage_95']['mean']:.4f} ± {results_dict['coverage_95']['std']:.4f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['coverage_95']['min']:.4f}, {results_dict['coverage_95']['max']:.4f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nCalibration Score:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['calibration']['mean']:.6f} ± {results_dict['calibration']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['calibration']['min']:.6f}, {results_dict['calibration']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nMADECP (Mean Absolute Deviation from Expected Coverage Probability):\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['madecp']['mean']:.6f} ± {results_dict['madecp']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['madecp']['min']:.6f}, {results_dict['madecp']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nPrediction Variance:\")\n",
    "    print(\n",
    "        f\"  Mean ± Std: {results_dict['variance']['mean']:.6f} ± {results_dict['variance']['std']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  Range: [{results_dict['variance']['min']:.6f}, {results_dict['variance']['max']:.6f}]\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"INDIVIDUAL SEED RESULTS\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    # Individual results table\n",
    "    print(\n",
    "        f\"\\n{'Seed':<6} {'Epochs':<8} {'Time(s)':<10} {'Test MSE':<12} {'Test MAE':<12} {'MPE':<12} {'Coverage':<10}\"\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "    for result in all_results:\n",
    "        print(\n",
    "            f\"{result['random_state']:<6} {result['final_epoch']:<8} {result['training_time']:<10.2f} \"\n",
    "            f\"{result['test_mse']:<12.6f} {result['test_mae']:<12.6f} {result['mpe']:<12.6f} \"\n",
    "            f\"{result['coverage_95']:<10.4f}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up arguments for multi-seed training\n",
    "args = argparse.Namespace(\n",
    "    dataset=\"australia\",\n",
    "    model_name=\"pegat\",\n",
    "    path=\"../../\",\n",
    "    train_size=0.8,\n",
    "    val_size=0.1,\n",
    "    batched_training=True,\n",
    "    batch_size=2048,\n",
    "    max_epochs=1000,\n",
    "    patience_limit=50,\n",
    "    min_improvement=0.01,\n",
    "    train_crit=\"mse\",\n",
    "    lr=1e-3,\n",
    "    gnn_hidden_dim=32,\n",
    "    gnn_emb_dim=32,\n",
    "    pe_hidden_dim=128,\n",
    "    pe_emb_dim=64,\n",
    "    k=5,\n",
    "    p_dropout=0.5,\n",
    "    mat=True,\n",
    "    uw=False,\n",
    "    lamb=0.25,\n",
    "    save_freq=5,\n",
    "    print_progress=True,\n",
    ")\n",
    "\n",
    "# Run multi-seed training\n",
    "print(\"Starting Multi-Seed Training Experiment\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train with 10 different seeds\n",
    "all_results = train_multiple_seeds(x, y, coords, args, num_seeds=10)\n",
    "\n",
    "end_time = time.time()\n",
    "total_execution_time = end_time - start_time\n",
    "\n",
    "# Calculate aggregated results\n",
    "results_dict = calculate_aggregated_results(all_results)\n",
    "\n",
    "# Print comprehensive results\n",
    "print_aggregated_results(all_results, results_dict)\n",
    "\n",
    "# Print total execution time\n",
    "days, remainder = divmod(total_execution_time, 60 * 60 * 24)\n",
    "hours, remainder = divmod(remainder, 60 * 60)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(\n",
    "    f\"\\nTOTAL EXECUTION TIME: {int(days)} days, {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the trained models (all seeds will be saved with the base model name)\n",
    "base_model_folder = all_results[0][\"model_folder\"].split(\"_seed\")[0]\n",
    "print(f\"Base model folder: {base_model_folder}\")\n",
    "\n",
    "# List all model folders for this experiment\n",
    "models_lst = os.listdir(f\"{args.path}trained/\")\n",
    "experiment_folders = [m for m in models_lst if base_model_folder in m]\n",
    "print(f\"Experiment folders: {experiment_folders}\")\n",
    "\n",
    "# Load the best performing model (lowest test MSE) for detailed analysis\n",
    "best_result = min(all_results, key=lambda x: x[\"test_mse\"])\n",
    "print(\n",
    "    f\"Best performing model: Seed {best_result['random_state']} with Test MSE: {best_result['test_mse']:.6f}\"\n",
    ")\n",
    "\n",
    "# Load the best model for analysis\n",
    "model_folder = best_result[\"model_folder\"]\n",
    "model_path = f\"{args.path}trained/{model_folder}/ckpts/model_state.pt\"\n",
    "\n",
    "# Set up data and model for analysis (using the same seed as best result)\n",
    "set_seed(best_result[\"random_state\"])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Access and process data (same as training)\n",
    "if args.dataset == \"australia\":\n",
    "    x, y, c = get_australia_data(aux=(x, y, coords))\n",
    "\n",
    "# Split data (same as training)\n",
    "n = x.shape[0]\n",
    "indices = np.arange(n)\n",
    "_, _, _, _, idx_train, idx_val_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    indices,\n",
    "    test_size=(1 - args.train_size),\n",
    "    random_state=best_result[\"random_state\"],\n",
    ")\n",
    "idx_val, idx_test = train_test_split(\n",
    "    idx_val_test,\n",
    "    test_size=(1 - args.train_size - args.val_size) / (1 - args.train_size),\n",
    "    random_state=best_result[\"random_state\"],\n",
    ")\n",
    "\n",
    "# Separate x, y and c objects\n",
    "train_x, val_x, test_x = x[idx_train], x[idx_val], x[idx_test]\n",
    "train_y, val_y, test_y = y[idx_train], y[idx_val], y[idx_test]\n",
    "train_c, val_c, test_c = c[idx_train], c[idx_val], c[idx_test]\n",
    "\n",
    "# Create MyDataset objects\n",
    "train_dataset, val_dataset, test_dataset = (\n",
    "    MyDataset(train_x, train_y, train_c),\n",
    "    MyDataset(val_x, val_y, val_c),\n",
    "    MyDataset(test_x, test_y, test_c),\n",
    ")\n",
    "\n",
    "# Define edge indices and weights\n",
    "if args.batched_training == False:\n",
    "    batch_size = len(idx_train)\n",
    "    train_edge_index = knn_graph(train_c, k=args.k).to(device)\n",
    "    train_edge_weight = makeEdgeWeight(train_c, train_edge_index).to(device)\n",
    "    val_edge_index = knn_graph(val_c, k=args.k).to(device)\n",
    "    val_edge_weight = makeEdgeWeight(val_c, val_edge_index).to(device)\n",
    "    test_edge_index = knn_graph(test_c, k=args.k).to(device)\n",
    "    test_edge_weight = makeEdgeWeight(test_c, test_edge_index).to(device)\n",
    "    train_moran_weight_matrix = knn_to_adj(train_edge_index, batch_size)\n",
    "    with torch.enable_grad():\n",
    "        train_y_moran = lw_tensor_local_moran(\n",
    "            train_y, sparse.csr_matrix(train_moran_weight_matrix)\n",
    "        ).to(device)\n",
    "else:\n",
    "    train_edge_index = False\n",
    "    train_edge_weight = False\n",
    "    val_edge_index = False\n",
    "    val_edge_weight = False\n",
    "    test_edge_index = False\n",
    "    test_edge_weight = False\n",
    "    train_y_moran = False\n",
    "\n",
    "# Make model\n",
    "if args.model_name == \"pegcn\":\n",
    "    model = PEGCN(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "elif args.model_name == \"pegat\":\n",
    "    model = PEGAT(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "elif args.model_name == \"pegsage\":\n",
    "    model = PEGSAGE(\n",
    "        num_features_in=train_x.shape[1],\n",
    "        gnn_hidden_dim=args.gnn_hidden_dim,\n",
    "        gnn_emb_dim=args.gnn_emb_dim,\n",
    "        pe_hidden_dim=args.pe_hidden_dim,\n",
    "        pe_emb_dim=args.pe_emb_dim,\n",
    "        k=args.k,\n",
    "        p_dropout=args.p_dropout,\n",
    "        MAT=args.mat,\n",
    "    ).to(device)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.float()\n",
    "\n",
    "# Model analysis\n",
    "model.eval()\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
